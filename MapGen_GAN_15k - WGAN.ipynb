{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Map Generalization for Polygons using Pix2Pix strucutures - 15k\n",
    "## \n",
    "## Author: Yu Feng, yuzz.feng@gmail.com\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from data_helper import predict_15k, save_hist, save_model\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Add, Lambda\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def lambda_output(input_shape):\n",
    "    return input_shape[:2]\n",
    "\n",
    "def minb_disc(x):\n",
    "    diffs = K.expand_dims(x, 3) - K.expand_dims(K.permute_dimensions(x, [1, 2, 0]), 0)\n",
    "    abs_diffs = K.sum(K.abs(diffs), 2)\n",
    "    x = K.sum(K.exp(-abs_diffs), 2)\n",
    "\n",
    "    return x\n",
    "\n",
    "def generate_patch_gan_loss(last_disc_conv_layer, patch_dim, input_layer, nb_patches):\n",
    "\n",
    "    # generate a list of inputs for the different patches to the network\n",
    "    list_input = [Input(shape=patch_dim, name=\"patch_gan_input_%s\" % i) for i in range(nb_patches)]\n",
    "\n",
    "    # get an activation\n",
    "    x_flat = Flatten()(last_disc_conv_layer)\n",
    "    x = Dense(2, activation='softmax', name=\"disc_dense\")(x_flat)\n",
    "\n",
    "    patch_gan = Model(inputs=[input_layer], outputs=[x, x_flat], name=\"patch_gan\")\n",
    "\n",
    "    # generate individual losses for each patch\n",
    "    x = [patch_gan(patch)[0] for patch in list_input]\n",
    "    x_mbd = [patch_gan(patch)[1] for patch in list_input]\n",
    "\n",
    "    # merge layers if have multiple patches (aka perceptual loss)\n",
    "    if len(x) > 1:\n",
    "        #x = merge(x, mode=\"concat\", name=\"merged_features\")\n",
    "        x = Concatenate(name=\"merged_features\")(x)\n",
    "    else:\n",
    "        x = x[0]\n",
    "\n",
    "    # merge mbd if needed\n",
    "    # mbd = mini batch discrimination\n",
    "    # https://arxiv.org/pdf/1606.03498.pdf\n",
    "    if len(x_mbd) > 1:\n",
    "        #x_mbd = merge(x_mbd, mode=\"concat\", name=\"merged_feature_mbd\")\n",
    "        x_mbd = Concatenate(name=\"merged_feature_mbd\")(x_mbd)\n",
    "    else:\n",
    "        x_mbd = x_mbd[0]\n",
    "\n",
    "    num_kernels = 100\n",
    "    dim_per_kernel = 5\n",
    "\n",
    "    M = Dense(num_kernels * dim_per_kernel, use_bias=False, activation=None)\n",
    "    MBD = Lambda(minb_disc, output_shape=lambda_output)\n",
    "\n",
    "    x_mbd = M(x_mbd)\n",
    "    x_mbd = Reshape((num_kernels, dim_per_kernel))(x_mbd)\n",
    "    x_mbd = MBD(x_mbd)\n",
    "    \n",
    "    #x = merge([x, x_mbd], mode='concat')\n",
    "    x = Concatenate()([x, x_mbd])\n",
    "\n",
    "    x_out = Dense(2, activation=\"softmax\", name=\"disc_output\")(x)\n",
    "\n",
    "    discriminator = Model(inputs=list_input, outputs=[x_out], name='discriminator_nn')\n",
    "    return discriminator\n",
    "\n",
    "def res_block(x, nb_filters, strides, increase = False):\n",
    "    # This implementation used the double 3x3 structure and followed the Identity Mappings\n",
    "    res_path = BatchNormalization()(x)\n",
    "    res_path = Activation(activation='relu')(res_path)\n",
    "    \n",
    "    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same', strides=strides[0])(res_path)\n",
    "    res_path = BatchNormalization()(res_path)\n",
    "    res_path = Activation(activation='relu')(res_path)\n",
    "    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same', strides=strides[1])(res_path)\n",
    "    \n",
    "    if increase:\n",
    "        shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1), strides=strides[0])(x)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = x\n",
    "\n",
    "    res_path = Add()([shortcut, res_path])\n",
    "    return res_path\n",
    "\n",
    "def decoder(x, from_encoder):\n",
    "    main_path = UpSampling2D(size=(2, 2))(x)\n",
    "    main_path = Concatenate(axis=3)([main_path, from_encoder[2]])\n",
    "    main_path = res_block(main_path, [128, 128], [(1, 1), (1, 1)], increase = True)\n",
    "\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path) \n",
    "    main_path = Concatenate(axis=3)([main_path, from_encoder[1]])\n",
    "    main_path = res_block(main_path, [64, 64], [(1, 1), (1, 1)], increase = True)\n",
    "\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    main_path = Concatenate(axis=3)([main_path, from_encoder[0]])\n",
    "    main_path = res_block(main_path, [32, 32], [(1, 1), (1, 1)], increase = True)\n",
    "\n",
    "    return main_path\n",
    "\n",
    "def encoder(x):\n",
    "    to_decoder = []\n",
    "\n",
    "    main_path = Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n",
    "    main_path = BatchNormalization()(main_path)\n",
    "    main_path = Activation(activation='relu')(main_path)\n",
    "    main_path = Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1, 1))(main_path)\n",
    "\n",
    "    shortcut = Conv2D(filters=32, kernel_size=(1, 1), strides=(1, 1))(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    main_path = Add()([shortcut, main_path])\n",
    "    # first branching to decoder\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    main_path = res_block(main_path, [64, 64], [(2, 2), (1, 1)], increase = True)\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    main_path = res_block(main_path, [128, 128], [(2, 2), (1, 1)], increase = True)\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    return to_decoder\n",
    "\n",
    "def build_res_unet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    to_decoder = encoder(inputs)\n",
    "\n",
    "    path = res_block(to_decoder[2], [256, 256], [(2, 2), (1, 1)]) # 3x\n",
    "    \n",
    "    path = res_block(path, [256, 256], [(1, 1), (1, 1)]) # Yu.add - in 2018-12-02 16-09-04_15 only once\n",
    "\n",
    "    path = decoder(path, from_encoder=to_decoder)\n",
    "    \n",
    "    path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path) \n",
    "\n",
    "    return Model(input=inputs, output=path)\n",
    "\n",
    "class EL_GAN(): # Based on pix2pix\n",
    "    def __init__(self):\n",
    "\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        self.clip_value = 0.01\n",
    "        \n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'mapgen'\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN) better version\n",
    "        self.patch_size = 32\n",
    "        self.nb_patches = int((self.img_rows / self.patch_size) * (self.img_cols / self.patch_size))\n",
    "        self.patch_gan_dim = (self.patch_size, self.patch_size, self.channels)\n",
    "        \n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        self.df = 64\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5) # Original\n",
    "        #optimizer = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # An old version of Pix2pix\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        #self.generator = self.build_generator() # Old generator from \n",
    "        self.generator = self.build_res_unet_generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        #img_A = Input(shape=self.img_shape) # Target\n",
    "        img_B = Input(shape=self.img_shape) # Input\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        fake_A = self.generator(img_B)\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        #valid = self.discriminator([fake_A, img_B])\n",
    "        valid = self.discriminator([fake_A])\n",
    "\n",
    "        #self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "        self.combined = Model(inputs= img_B, outputs=[valid, fake_A])\n",
    "        \n",
    "        # Original Pix2Pix - low weight for discriminator\n",
    "        self.combined.compile(loss=['mse', 'mae'],\n",
    "                              loss_weights=[1, 100], # 20190117: original [1, 100]\n",
    "                              optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    def build_res_unet_generator(self):\n",
    "        \"\"\"Residual U-Net Generator\"\"\"\n",
    "        \n",
    "        inputs = Input(shape=self.img_shape)\n",
    "        to_decoder = encoder(inputs)\n",
    "        path = res_block(to_decoder[2], [256, 256], [(2, 2), (1, 1)], increase = True) # 3x\n",
    "        path = res_block(path, [256, 256], [(1, 1), (1, 1)]) # Number of block of bottleneck = 1\n",
    "        path = res_block(path, [256, 256], [(1, 1), (1, 1)]) # Try to add one 2019.01.14, achieved best result ever\n",
    "        path = res_block(path, [256, 256], [(1, 1), (1, 1)]) # Try to add one 2019.01.15\n",
    "        path = decoder(path, from_encoder=to_decoder)\n",
    "        path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path) \n",
    "        #path = Conv2D(filters=1, kernel_size=(1, 1))(path) \n",
    "\n",
    "        return Model(input=inputs, output=path)\n",
    "        \n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, self.gf*8)\n",
    "        u2 = deconv2d(u1, d5, self.gf*8)\n",
    "        u3 = deconv2d(u2, d4, self.gf*8)\n",
    "        u4 = deconv2d(u3, d3, self.gf*4)\n",
    "        u5 = deconv2d(u4, d2, self.gf*2)\n",
    "        u6 = deconv2d(u5, d1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "    \n",
    "    def build_PatchGanDiscriminator(self):\n",
    "        \"\"\"\n",
    "        Creates the generator according to the specs in the paper below.\n",
    "        [https://arxiv.org/pdf/1611.07004v1.pdf][5. Appendix]\n",
    "\n",
    "        PatchGAN only penalizes structure at the scale of patches. This\n",
    "        discriminator tries to classify if each N x N patch in an\n",
    "        image is real or fake. We run this discriminator convolutationally\n",
    "        across the image, averaging all responses to provide\n",
    "        the ultimate output of D.\n",
    "\n",
    "        The discriminator has two parts. First part is the actual discriminator\n",
    "        seconds part we make it a PatchGAN by running each image patch through the model\n",
    "        and then we average the responses\n",
    "\n",
    "        Discriminator does the following:\n",
    "        1. Runs many pieces of the image through the network\n",
    "        2. Calculates the cost for each patch\n",
    "        3. Returns the avg of the costs as the output of the network\n",
    "\n",
    "        :param patch_dim: (channels, width, height) T\n",
    "        :param nb_patches:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # -------------------------------\n",
    "        # DISCRIMINATOR\n",
    "        # C64-C128-C256-C512-C512-C512 (for 256x256)\n",
    "        # otherwise, it scales from 64\n",
    "        # 1 layer block = Conv - BN - LeakyRelu\n",
    "        # -------------------------------\n",
    "        \n",
    "        output_img_dim = self.img_shape\n",
    "        patch_dim = self.patch_gan_dim\n",
    "        input_layer = Input(shape=patch_dim)\n",
    "        \n",
    "        # We have to build the discriminator dinamically because\n",
    "        # the size of the disc patches is dynamic\n",
    "        num_filters_start = self.gf\n",
    "        nb_conv = int(np.floor(np.log(output_img_dim[1]) / np.log(2)))\n",
    "        filters_list = [num_filters_start * min(8, (2 ** i)) for i in range(nb_conv)]\n",
    "        \n",
    "        # CONV 1\n",
    "        # Do first conv bc it is different from the rest\n",
    "        # paper skips batch norm for first layer\n",
    "        disc_out = Conv2D(filters=64, kernel_size=(4, 4), padding='same', strides=(2, 2), name='disc_conv_1')(input_layer)\n",
    "        disc_out = LeakyReLU(alpha=0.2)(disc_out)\n",
    "        \n",
    "        # CONV 2 - CONV N\n",
    "        # do the rest of the convs based on the sizes from the filters\n",
    "        for i, filter_size in enumerate(filters_list[1:]):\n",
    "            name = 'disc_conv_{}'.format(i+2)\n",
    "\n",
    "            disc_out = Conv2D(filters=filter_size, kernel_size=(4, 4), padding='same', strides=(2, 2), name=name)(disc_out)\n",
    "            disc_out = BatchNormalization(name=name + '_bn')(disc_out)\n",
    "            disc_out = LeakyReLU(alpha=0.2)(disc_out)\n",
    "        \n",
    "        # ------------------------\n",
    "        # BUILD PATCH GAN\n",
    "        # this is where we evaluate the loss over each sublayer of the input\n",
    "        # ------------------------\n",
    "        patch_gan_discriminator = generate_patch_gan_loss(last_disc_conv_layer=disc_out,\n",
    "                                                          patch_dim=patch_dim,\n",
    "                                                          input_layer=input_layer,\n",
    "                                                          nb_patches=nb_patches)\n",
    "        return patch_gan_discriminator\n",
    "    \n",
    "    def build_2head_discriminator(self):\n",
    "        \n",
    "        def d_layer(layer_input, filters, f_size=3, bn=True): # Chnaged here for the order of bn and activation\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            conv = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')\n",
    "            d = conv(layer_input)\n",
    "            e = conv(layer_input2)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Activation(activation='relu')(d)\n",
    "            #d = LeakyReLU(alpha=0.2)(d)\n",
    "            return d\n",
    "        \n",
    "        def d_layers(img_A):\n",
    "            d1 = d_layer(img_A, self.df, bn=False)\n",
    "            d2 = d_layer(d1, self.df*2)\n",
    "            d3 = d_layer(d2, self.df*4)\n",
    "            d4 = d_layer(d3, self.df*8)\n",
    "            d5 = Flatten()(d4)\n",
    "            d6 = Dense(128, activation='softmax')(d5)\n",
    "            \n",
    "            return Model(img_A, d6)\n",
    "        \n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "        \n",
    "        encoded_a = d_layers(img_A)\n",
    "        encoded_b = d_layers(img_B)\n",
    "        \n",
    "        # We can then concatenate the two vectors:\n",
    "        #merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=-1)\n",
    "        \n",
    "        return Model([img_A, img_B], validity)\n",
    "        \n",
    "    \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=3, bn=True): # Chnaged here for the order of bn and activation\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Activation(activation='relu')(d)\n",
    "            #d = LeakyReLU(alpha=0.2)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        #img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        ## Concatenate image and conditioning image by channels to produce input\n",
    "        #combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        #d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        \n",
    "        d1 = d_layer(img_A, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A], validity)\n",
    "    \n",
    "    def train_generator_only(self, x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath):\n",
    "        \n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        data_gen_args = dict(rotation_range=180.)\n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        \n",
    "        seed = 1\n",
    "        BATCH_SIZE = 16\n",
    "        result_generator = zip(image_datagen.flow(x_train_sim, batch_size=BATCH_SIZE, seed=seed), \n",
    "                               mask_datagen.flow(y_train_sim, batch_size=BATCH_SIZE, seed=seed))\n",
    "        \n",
    "        History1 = History()\n",
    "        hist1 = self.generator.fit_generator( result_generator,\n",
    "                                              epochs = 100,\n",
    "                                              steps_per_epoch=2000,\n",
    "                                              verbose=1,\n",
    "                                              shuffle=True,\n",
    "                                              callbacks=[History1, \n",
    "                                                         EarlyStopping(patience=5), \n",
    "                                                         ReduceLROnPlateau(patience = 3, verbose = 0),\n",
    "                                                         ModelCheckpoint(outPath + \"weights.hdf5\", \n",
    "                                                                         save_best_only = True, \n",
    "                                                                         save_weights_only = False)],\n",
    "                                              validation_data=(x_test_sim, y_test_sim))\n",
    "        save_hist(History1, outPath)\n",
    "        \n",
    "    \n",
    "    def train(self, x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        \n",
    "        total_samples = len(x_train_sim)\n",
    "        ids = np.arange(total_samples)\n",
    "        np.random.shuffle(ids)\n",
    "        n_batches = int(total_samples / batch_size)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(load_batch(x_train_sim, y_train_sim, batch_size)):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Condition on B and generate a translated version\n",
    "                fake_A = self.generator.predict(imgs_B)\n",
    "                \n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                #d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                #d_loss_fake = self.discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs_A], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([fake_A], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                \n",
    "                # Clip critic weights\n",
    "                for l in self.discriminator.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                # Train the generators\n",
    "                #g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "                g_loss = self.combined.train_on_batch(imgs_B, [valid, imgs_A])\n",
    "                \n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "                # Plot the progress\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    \n",
    "                    valid_test = np.ones((len(x_test_sim),) + self.disc_patch)\n",
    "                    #t_loss = self.combined.evaluate([y_test_sim, x_test_sim], [valid_test, y_test_sim], verbose=0)\n",
    "                    t_loss = self.combined.evaluate(x_test_sim, [valid_test, y_test_sim], verbose=0)\n",
    "                    \n",
    "                    print (\"[Epoch %d/%d-%d/%d] [D loss&acc: %.3f, %.3f%%] [G loss&accA&accB: %.3f, %.3f%%, %.3f%%] [Test loss&acc: %.3f, %.3f%%, %.3f%%] time: %s\" % (epoch, epochs,\n",
    "                                                                                batch_i, n_batches,\n",
    "                                                                                d_loss[0], 100*d_loss[1],\n",
    "                                                                                100*g_loss[2], 100*g_loss[3], 100*g_loss[4],\n",
    "                                                                                100*t_loss[2], 100*t_loss[3], 100*t_loss[4],\n",
    "                                                                                elapsed_time))                 \n",
    "            if epoch > 10:\n",
    "                self.generator.save(outPath + 'model_epoch'+ str(epoch) +'.h5')\n",
    "                        \n",
    "                ## If at save interval => save generated image samples\n",
    "                #if batch_i % sample_interval == 0:\n",
    "                #    self.sample_images(outPath, epoch, batch_i)\n",
    "\n",
    "\n",
    "    def sample_images(self, outPath, epoch, batch_i, examples = [0, 77, 34]):\n",
    "        \n",
    "        r, c = 3, 3\n",
    "        p_size_1 = 128\n",
    "        \n",
    "        imgs_A = y_test_sim[examples]\n",
    "        imgs_B = x_test_sim[examples]\n",
    "        \n",
    "        fake_A = gan.generator.predict(imgs_B)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Input', 'Generated', 'Target']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                gen = np.reshape(gen_imgs[cnt], (p_size_1,p_size_1))\n",
    "                axs[i,j].imshow(gen)\n",
    "                \n",
    "                #axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(outPath + \"%d_%d.png\" % (epoch, batch_i),\n",
    "                   format='png', transparent=True, dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape of the trains (32289, 128, 128, 1)\n",
      "Input Shape of the tests (3587, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Order the image dimension acc. to TensorFlow (batc_hsize, rows, cols, channels)\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "scale = 15\n",
    "p_size_1 = 128 # Compared with 256, which larger may generate round corners\n",
    "trainPath = r\"../tmp_data/data_feng/geb\" + str(scale) +  \"/\"\n",
    "\n",
    "# save image patch arrays\n",
    "x_train_sim = np.load(trainPath + \"x_train_sim.npy\")\n",
    "y_train_sim = np.load(trainPath + \"y_train_sim.npy\")\n",
    "x_test_sim = np.load(trainPath + \"x_test_sim.npy\")\n",
    "y_test_sim = np.load(trainPath + \"y_test_sim.npy\")\n",
    "\n",
    "input_shape1 = (None, None, 1) #x_train_sim[0].shape\n",
    "print('Input Shape of the trains', x_train_sim.shape)\n",
    "print('Input Shape of the tests', x_test_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper import readImg, readImgInv, imagePatches, removeBlackImg, removeCorrespondence, check_and_create\n",
    "\n",
    "from time import gmtime, strftime\n",
    "timestr = strftime(\"%Y-%m-%d %H-%M-%S\", gmtime())\n",
    "\n",
    "############ Path Setting ##############\n",
    "outPath = r\"../tmp_results/predictions/\"\n",
    "outPath = outPath + timestr + '_' + str(scale)+ \"/\"\n",
    "check_and_create(outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(x_train_sim, y_train_sim, batch_size):\n",
    "    total_samples = len(x_train_sim)\n",
    "    ids = np.arange(total_samples)\n",
    "    np.random.shuffle(ids)\n",
    "    n_batches = int(total_samples / batch_size)\n",
    "    for i in range(n_batches-1):\n",
    "        batch_idx = ids[i*batch_size:(i+1)*batch_size]\n",
    "        imgs_A = x_train_sim[batch_idx]\n",
    "        imgs_B = y_train_sim[batch_idx]\n",
    "        yield imgs_B, imgs_A     \n",
    "        \n",
    "def load_data(x_test_sim, y_test_sim, batch_size=1):\n",
    "    return x_test_sim  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:221: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/26-0/1009] [D loss&acc: 1.341, 23.657%] [G loss&accA&accB: 52.670, 0.000%, 30.571%] [Test loss&acc: 53.389, 0.000%, 51.569%] time: 0:00:13.850964\n",
      "[Epoch 0/26-500/1009] [D loss&acc: 0.342, 50.000%] [G loss&accA&accB: 1.268, 0.000%, 98.738%] [Test loss&acc: 1.045, 0.000%, 98.969%] time: 0:03:39.600153\n",
      "[Epoch 0/26-1000/1009] [D loss&acc: 0.341, 50.000%] [G loss&accA&accB: 0.655, 0.000%, 99.348%] [Test loss&acc: 1.022, 0.000%, 98.983%] time: 0:07:04.387559\n",
      "[Epoch 1/26-0/1009] [D loss&acc: 0.341, 50.000%] [G loss&accA&accB: 1.091, 0.000%, 98.914%] [Test loss&acc: 1.063, 0.000%, 98.951%] time: 0:07:17.848062\n",
      "[Epoch 1/26-500/1009] [D loss&acc: 0.340, 50.000%] [G loss&accA&accB: 0.720, 0.000%, 99.284%] [Test loss&acc: 1.008, 0.000%, 98.995%] time: 0:10:41.196455\n",
      "[Epoch 1/26-1000/1009] [D loss&acc: 0.339, 50.000%] [G loss&accA&accB: 0.816, 0.000%, 99.187%] [Test loss&acc: 1.005, 0.000%, 98.997%] time: 0:14:05.151833\n",
      "[Epoch 2/26-0/1009] [D loss&acc: 0.339, 50.000%] [G loss&accA&accB: 0.858, 0.000%, 99.155%] [Test loss&acc: 1.065, 0.000%, 98.949%] time: 0:14:18.592995\n",
      "[Epoch 2/26-500/1009] [D loss&acc: 0.338, 50.000%] [G loss&accA&accB: 0.872, 0.000%, 99.129%] [Test loss&acc: 0.986, 0.000%, 99.015%] time: 0:17:42.094603\n",
      "[Epoch 2/26-1000/1009] [D loss&acc: 0.335, 50.000%] [G loss&accA&accB: 0.722, 0.000%, 99.280%] [Test loss&acc: 0.973, 0.000%, 99.029%] time: 0:21:05.428078\n",
      "[Epoch 3/26-0/1009] [D loss&acc: 0.334, 50.000%] [G loss&accA&accB: 1.506, 0.000%, 98.495%] [Test loss&acc: 0.981, 0.000%, 99.022%] time: 0:21:18.854903\n",
      "[Epoch 3/26-500/1009] [D loss&acc: 0.329, 50.000%] [G loss&accA&accB: 1.139, 0.000%, 98.861%] [Test loss&acc: 0.956, 0.000%, 99.045%] time: 0:24:42.043248\n",
      "[Epoch 3/26-1000/1009] [D loss&acc: 0.328, 50.000%] [G loss&accA&accB: 0.603, 0.000%, 99.399%] [Test loss&acc: 0.954, 0.000%, 99.046%] time: 0:28:05.687296\n",
      "[Epoch 4/26-0/1009] [D loss&acc: 0.328, 50.000%] [G loss&accA&accB: 0.656, 0.000%, 99.346%] [Test loss&acc: 0.944, 0.000%, 99.057%] time: 0:28:19.108346\n",
      "[Epoch 4/26-500/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.857, 0.000%, 99.146%] [Test loss&acc: 0.990, 0.000%, 99.016%] time: 0:31:42.751271\n",
      "[Epoch 4/26-1000/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 1.192, 0.000%, 98.811%] [Test loss&acc: 0.874, 0.000%, 99.129%] time: 0:35:06.515099\n",
      "[Epoch 5/26-0/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.799, 0.000%, 99.203%] [Test loss&acc: 0.861, 0.000%, 99.142%] time: 0:35:20.003788\n",
      "[Epoch 5/26-500/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.704, 0.000%, 99.299%] [Test loss&acc: 0.817, 0.000%, 99.184%] time: 0:38:43.634039\n",
      "[Epoch 5/26-1000/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.553, 0.000%, 99.447%] [Test loss&acc: 0.979, 0.000%, 99.168%] time: 0:42:07.344727\n",
      "[Epoch 6/26-0/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 1.103, 0.000%, 98.897%] [Test loss&acc: 0.837, 0.000%, 99.185%] time: 0:42:20.769143\n",
      "[Epoch 6/26-500/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.650, 0.000%, 99.350%] [Test loss&acc: 0.761, 0.000%, 99.240%] time: 0:45:43.774543\n",
      "[Epoch 6/26-1000/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.752, 0.000%, 99.252%] [Test loss&acc: 0.743, 0.000%, 99.258%] time: 0:49:06.660364\n",
      "[Epoch 7/26-0/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.708, 0.000%, 99.292%] [Test loss&acc: 0.754, 0.000%, 99.247%] time: 0:49:20.063191\n",
      "[Epoch 7/26-500/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.879, 0.000%, 99.121%] [Test loss&acc: 0.754, 0.000%, 99.247%] time: 0:52:42.428908\n",
      "[Epoch 7/26-1000/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.314, 0.000%, 99.686%] [Test loss&acc: 0.748, 0.000%, 99.252%] time: 0:56:05.105956\n",
      "[Epoch 8/26-0/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.790, 0.000%, 99.211%] [Test loss&acc: 0.742, 0.000%, 99.259%] time: 0:56:18.521161\n",
      "[Epoch 8/26-500/1009] [D loss&acc: 0.327, 50.000%] [G loss&accA&accB: 0.884, 0.000%, 99.116%] [Test loss&acc: 0.756, 0.000%, 99.246%] time: 0:59:40.733215\n",
      "[Epoch 8/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.512, 0.000%, 99.489%] [Test loss&acc: 0.708, 0.000%, 99.292%] time: 1:03:02.761625\n",
      "[Epoch 9/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.670, 0.000%, 99.331%] [Test loss&acc: 0.712, 0.000%, 99.288%] time: 1:03:16.194830\n",
      "[Epoch 9/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.690, 0.000%, 99.312%] [Test loss&acc: 0.702, 0.000%, 99.298%] time: 1:06:37.678428\n",
      "[Epoch 9/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.626, 0.000%, 99.374%] [Test loss&acc: 0.710, 0.000%, 99.290%] time: 1:09:59.005173\n",
      "[Epoch 10/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.596, 0.000%, 99.405%] [Test loss&acc: 0.697, 0.000%, 99.303%] time: 1:10:12.418085\n",
      "[Epoch 10/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.530, 0.000%, 99.470%] [Test loss&acc: 0.698, 0.000%, 99.302%] time: 1:13:33.605800\n",
      "[Epoch 10/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.731, 0.000%, 99.268%] [Test loss&acc: 0.700, 0.000%, 99.300%] time: 1:16:55.252310\n",
      "[Epoch 11/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.645, 0.000%, 99.354%] [Test loss&acc: 0.715, 0.000%, 99.285%] time: 1:17:08.704546\n",
      "[Epoch 11/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.769, 0.000%, 99.230%] [Test loss&acc: 0.694, 0.000%, 99.307%] time: 1:20:30.023666\n",
      "[Epoch 11/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.527, 0.000%, 99.473%] [Test loss&acc: 0.692, 0.000%, 99.308%] time: 1:23:51.131416\n",
      "[Epoch 12/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.702, 0.000%, 99.299%] [Test loss&acc: 0.698, 0.000%, 99.302%] time: 1:24:08.882153\n",
      "[Epoch 12/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.634, 0.000%, 99.366%] [Test loss&acc: 0.692, 0.000%, 99.308%] time: 1:27:29.421241\n",
      "[Epoch 12/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.713, 0.000%, 99.288%] [Test loss&acc: 0.701, 0.000%, 99.299%] time: 1:30:50.560065\n",
      "[Epoch 13/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.340, 0.000%, 99.659%] [Test loss&acc: 0.699, 0.000%, 99.301%] time: 1:31:04.425688\n",
      "[Epoch 13/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.467, 0.000%, 99.532%] [Test loss&acc: 0.696, 0.000%, 99.304%] time: 1:34:25.231062\n",
      "[Epoch 13/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.510, 0.000%, 99.491%] [Test loss&acc: 0.686, 0.000%, 99.315%] time: 1:37:46.084613\n",
      "[Epoch 14/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.948, 0.000%, 99.051%] [Test loss&acc: 0.688, 0.000%, 99.312%] time: 1:37:59.915577\n",
      "[Epoch 14/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.415, 0.000%, 99.586%] [Test loss&acc: 0.689, 0.000%, 99.311%] time: 1:41:20.517291\n",
      "[Epoch 14/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.614, 0.000%, 99.385%] [Test loss&acc: 0.693, 0.000%, 99.307%] time: 1:44:40.778079\n",
      "[Epoch 15/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.577, 0.000%, 99.424%] [Test loss&acc: 0.694, 0.000%, 99.306%] time: 1:44:54.595389\n",
      "[Epoch 15/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.402, 0.000%, 99.598%] [Test loss&acc: 0.690, 0.000%, 99.310%] time: 1:48:14.473806\n",
      "[Epoch 15/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.478, 0.000%, 99.522%] [Test loss&acc: 0.691, 0.000%, 99.309%] time: 1:51:34.219596\n",
      "[Epoch 16/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 1.042, 0.000%, 98.958%] [Test loss&acc: 0.697, 0.000%, 99.303%] time: 1:51:47.999792\n",
      "[Epoch 16/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.662, 0.000%, 99.338%] [Test loss&acc: 0.684, 0.000%, 99.316%] time: 1:55:07.379332\n",
      "[Epoch 16/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.548, 0.000%, 99.453%] [Test loss&acc: 0.673, 0.000%, 99.328%] time: 1:58:26.892161\n",
      "[Epoch 17/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.620, 0.000%, 99.379%] [Test loss&acc: 0.682, 0.000%, 99.319%] time: 1:58:40.513699\n",
      "[Epoch 17/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.427, 0.000%, 99.573%] [Test loss&acc: 0.685, 0.000%, 99.315%] time: 2:01:59.835793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.317, 0.000%, 99.683%] [Test loss&acc: 0.679, 0.000%, 99.321%] time: 2:05:18.973909\n",
      "[Epoch 18/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.253, 0.000%, 99.748%] [Test loss&acc: 0.682, 0.000%, 99.318%] time: 2:05:32.579771\n",
      "[Epoch 18/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.587, 0.000%, 99.414%] [Test loss&acc: 0.688, 0.000%, 99.312%] time: 2:08:51.660721\n",
      "[Epoch 18/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.543, 0.000%, 99.456%] [Test loss&acc: 0.684, 0.000%, 99.316%] time: 2:12:10.990002\n",
      "[Epoch 19/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.468, 0.000%, 99.533%] [Test loss&acc: 0.684, 0.000%, 99.316%] time: 2:12:24.613444\n",
      "[Epoch 19/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.459, 0.000%, 99.542%] [Test loss&acc: 0.683, 0.000%, 99.317%] time: 2:15:43.864535\n",
      "[Epoch 19/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.447, 0.000%, 99.553%] [Test loss&acc: 0.690, 0.000%, 99.310%] time: 2:19:02.873110\n",
      "[Epoch 20/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.459, 0.000%, 99.540%] [Test loss&acc: 0.684, 0.000%, 99.316%] time: 2:19:16.455606\n",
      "[Epoch 20/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.638, 0.000%, 99.364%] [Test loss&acc: 0.672, 0.000%, 99.328%] time: 2:22:35.282697\n",
      "[Epoch 20/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.410, 0.000%, 99.591%] [Test loss&acc: 0.677, 0.000%, 99.323%] time: 2:25:53.654448\n",
      "[Epoch 21/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.302, 0.000%, 99.698%] [Test loss&acc: 0.671, 0.000%, 99.329%] time: 2:26:07.335385\n",
      "[Epoch 21/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.544, 0.000%, 99.456%] [Test loss&acc: 0.676, 0.000%, 99.324%] time: 2:29:25.784802\n",
      "[Epoch 21/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.524, 0.000%, 99.476%] [Test loss&acc: 0.691, 0.000%, 99.309%] time: 2:32:44.349439\n",
      "[Epoch 22/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.336, 0.000%, 99.664%] [Test loss&acc: 0.684, 0.000%, 99.316%] time: 2:32:57.984186\n",
      "[Epoch 22/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.462, 0.000%, 99.538%] [Test loss&acc: 0.673, 0.000%, 99.327%] time: 2:36:16.827052\n",
      "[Epoch 22/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.485, 0.000%, 99.516%] [Test loss&acc: 0.673, 0.000%, 99.327%] time: 2:39:35.479866\n",
      "[Epoch 23/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 2.464, 0.000%, 97.536%] [Test loss&acc: 0.672, 0.000%, 99.328%] time: 2:39:49.098477\n",
      "[Epoch 23/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.375, 0.000%, 99.626%] [Test loss&acc: 0.685, 0.000%, 99.315%] time: 2:43:07.485182\n",
      "[Epoch 23/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.267, 0.000%, 99.733%] [Test loss&acc: 0.690, 0.000%, 99.310%] time: 2:46:25.848817\n",
      "[Epoch 24/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.414, 0.000%, 99.585%] [Test loss&acc: 0.682, 0.000%, 99.318%] time: 2:46:39.429964\n",
      "[Epoch 24/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.365, 0.000%, 99.635%] [Test loss&acc: 0.684, 0.000%, 99.316%] time: 2:49:57.675843\n",
      "[Epoch 24/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.458, 0.000%, 99.542%] [Test loss&acc: 0.678, 0.000%, 99.322%] time: 2:53:15.859565\n",
      "[Epoch 25/26-0/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.379, 0.000%, 99.622%] [Test loss&acc: 0.679, 0.000%, 99.321%] time: 2:53:29.565020\n",
      "[Epoch 25/26-500/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.513, 0.000%, 99.488%] [Test loss&acc: 0.682, 0.000%, 99.318%] time: 2:56:47.755136\n",
      "[Epoch 25/26-1000/1009] [D loss&acc: 0.326, 50.000%] [G loss&accA&accB: 0.808, 0.000%, 99.192%] [Test loss&acc: 0.677, 0.000%, 99.323%] time: 3:00:06.229423\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = EL_GAN() # 26 Epochs, 32 \n",
    "    gan.train(x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath, epochs=26, batch_size=32, sample_interval=500)\n",
    "    #gan.train_generator_only(x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tmp_results/predictions/2019-01-23 16-58-02_15/\n"
     ]
    }
   ],
   "source": [
    "print(outPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    def IoUcheck(img_input, img_output):\n",
    "\n",
    "        logic_and = np.sum(np.logical_and(img_output, img_input))\n",
    "        logic_or = np.sum(np.logical_or(img_output, img_input))\n",
    "\n",
    "        return logic_and/logic_or\n",
    "    \n",
    "    def rescaleImg(image_arr):\n",
    "    \n",
    "        if image_arr.shape[0] % 8 != 0:\n",
    "            n = image_arr.shape[0] % 8\n",
    "            new_x = image_arr.shape[0] - n\n",
    "        else:\n",
    "            new_x = image_arr.shape[0]\n",
    "\n",
    "        if image_arr.shape[1] % 8 != 0:\n",
    "            n = image_arr.shape[1] % 8\n",
    "            new_y = image_arr.shape[1] - n\n",
    "        else:\n",
    "            new_y = image_arr.shape[1]\n",
    "\n",
    "        image_arr = image_arr[:new_x, :new_y]\n",
    "\n",
    "        return image_arr\n",
    "    \n",
    "    def update_model_to_any_size(old_model):\n",
    "    \n",
    "        old_model.layers.pop(0)\n",
    "        \n",
    "        newInput = Input(shape=(None, None, 1)) # New image input\n",
    "        newOutputs = old_model(newInput)\n",
    "        newModel = Model(newInput, newOutputs)\n",
    "        #newModel.summary()\n",
    "\n",
    "        return newModel\n",
    "    \n",
    "    def evaluate(image_arrA, image_arrB):\n",
    "        \n",
    "        y_true = image_arrB.flatten().astype(bool) \n",
    "        y_pred = image_arrA.flatten().astype(bool)\n",
    "        \n",
    "        Accuracy = accuracy_score(image_arrB.flatten().astype(bool), \n",
    "                                  image_arrA.flatten().astype(bool))\n",
    "\n",
    "        IntOverUnion = IoUcheck(image_arrB.flatten().astype(bool), \n",
    "                                image_arrA.flatten().astype(bool))\n",
    "        \n",
    "        conf = confusion_matrix(image_arrB.flatten().astype(bool), \n",
    "                                image_arrA.flatten().astype(bool))\n",
    "        print('aAcc:', Accuracy)\n",
    "        print('Error:', 1 - Accuracy)\n",
    "        print('IoU:', IntOverUnion)\n",
    "        print('Confusion:', conf)\n",
    "        \n",
    "        target_names = ['0', '1']\n",
    "        print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "        \n",
    "        return Accuracy, IntOverUnion\n",
    "        \n",
    "    def model_predict(newModel, input_image, num_runs):\n",
    "        m,n = input_image.shape\n",
    "        \n",
    "        for i in range(num_runs):\n",
    "            input_image = np.reshape(input_image, (1, m, n, 1))\n",
    "            conc2 = newModel.predict([input_image])\n",
    "            input_image = np.reshape(conc2,(m, n))\n",
    "\n",
    "        return input_image\n",
    "    \n",
    "    def save_prediction(output_image, fn_input, subfix):\n",
    "        fig = plt.figure(figsize=(output_image.shape[1] / 1000, output_image.shape[0] / 1000), dpi=100, frameon=False)\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "\n",
    "        plt.imshow(output_image, cmap='gray')\n",
    "        #plt.imshow(output_image)\n",
    "        fig.savefig(outPath + fn_input[:-4] + subfix, dpi=1000)\n",
    "\n",
    "    def predict_15k_examples(testPath, fn_input, fn_target, nr = 1):\n",
    "    \n",
    "        image_arrA = readImg(testPath + fn_input)\n",
    "        image_arrB = readImg(testPath + fn_target)\n",
    "\n",
    "        print(\"15k\", 'Example: ')\n",
    "        acc_orig, iou_orig = evaluate(image_arrA, image_arrB)\n",
    "\n",
    "        image_arr = readImg(testPath + fn_input)\n",
    "        image_arr = rescaleImg(image_arr)\n",
    "\n",
    "        image_tar = readImg(testPath + fn_target)\n",
    "        image_tar = rescaleImg(image_tar)\n",
    "\n",
    "        newModel = update_model_to_any_size(gan.generator)\n",
    "        output_image = model_predict(newModel, image_arr, num_runs = nr)\n",
    "\n",
    "        print(\"- 15k\", 'Prediction: ')\n",
    "        acc_pred, iou_pred = evaluate(output_image > 0.5, image_tar)\n",
    "\n",
    "        save_prediction(output_image, fn_input, '_' + str(nr) + '_out.png')\n",
    "\n",
    "        return [[acc_orig, iou_orig], [acc_pred, iou_pred]]\n",
    "    \n",
    "    def predict_15k_only(testPath, fn_input, nr = 1):\n",
    "    \n",
    "        print(\"15k\", 'Example: ')\n",
    "        image_arr = readImg(testPath + fn_input)\n",
    "        image_arr = rescaleImg(image_arr)\n",
    "\n",
    "        newModel = update_model_to_any_size(gan.generator)\n",
    "        output_image = model_predict(newModel, image_arr, num_runs = nr)\n",
    "\n",
    "        print(\"- 15k\", 'Prediction: ')\n",
    "        acc_pred, iou_pred = evaluate(output_image > 0.5, image_tar)\n",
    "\n",
    "        save_prediction(output_image, fn_input, '_' + str(nr) + '_out.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testPath = r\"../tmp_data/Data/Testing/\"\n",
    "all_records = []\n",
    "    \n",
    "records = predict_15k_examples(testPath, r\"FTest1_input_inv.png\", r\"FTest1_output_inv.png\", nr = 1)\n",
    "all_records.extend(records)\n",
    "    \n",
    "records = predict_15k_examples(testPath, r\"FTest2_input_inv.png\", r\"FTest2_output_inv.png\", nr = 1)\n",
    "all_records.extend(records)\n",
    "\n",
    "records = predict_15k_examples(testPath, r\"FTest1_input_inv.png\", r\"FTest1_output_inv.png\", nr = 10)\n",
    "all_records.extend(records)\n",
    "    \n",
    "records = predict_15k_examples(testPath, r\"FTest2_input_inv.png\", r\"FTest2_output_inv.png\", nr = 10)\n",
    "all_records.extend(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(np.transpose(all_records))\n",
    "df.columns = [\"Input vs Target (Test1)\", \"Prediction vs Target (Test1 - 1)\", \n",
    "              \"Input vs Target (Test2)\", \"Prediction vs Target (Test2 - 1)\",\n",
    "              \"Input vs Target (Test1)\", \"Prediction vs Target (Test1 - 10)\", \n",
    "              \"Input vs Target (Test2)\", \"Prediction vs Target (Test2 - 10)\"]\n",
    "\n",
    "df = df.rename({0: \"Accuracy\", 1: 'IoU'})\n",
    "df.index.name = 'Metrics'\n",
    "\n",
    "df[[\"Input vs Target (Test1)\", \"Prediction vs Target (Test1 - 1)\", \"Prediction vs Target (Test1 - 10)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[[\"Input vs Target (Test2)\", \"Prediction vs Target (Test2 - 1)\", \"Prediction vs Target (Test2 - 10)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gan.generator.summary()\n",
    "gan.discriminator.summary()\n",
    "gan.combined.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testPath = r\"../tmp_data/Data/Testing_large/4270/\"\n",
    "all_records = []\n",
    "\n",
    "records = predict_15k_examples(testPath, r\"geb_clip_4270.png\", r\"geb15_clip_4270.png\", nr = 1)\n",
    "all_records.extend(records)\n",
    "    \n",
    "records = predict_15k_examples(testPath, r\"geb_clip_4270.png\", r\"geb15_clip_4270.png\", nr = 10)\n",
    "all_records.extend(records)\n",
    "\n",
    "df = pd.DataFrame(np.transpose(all_records))\n",
    "df.columns = [\"Input vs Target (4270)\", \"Prediction vs Target (4270 - 1)\", \n",
    "              \"Input vs Target (4270)\", \"Prediction vs Target (4270 - 1)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fn_input, fn_target = r\"geb_clip_4270.png\", r\"geb15_clip_4270.png\"\n",
    "image_arrA = readImg(testPath + fn_input)\n",
    "image_arrB = readImg(testPath + fn_target)\n",
    "\n",
    "print(\"15k\", 'Example: ')\n",
    "acc_orig, iou_orig = evaluate(image_arrA, image_arrB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_arr = readImg(testPath + fn_input)\n",
    "image_arr = rescaleImg(image_arr)[:2400, :2400]\n",
    "\n",
    "image_tar = readImg(testPath + fn_target)\n",
    "image_tar = rescaleImg(image_tar)[:2400, :2400]\n",
    "print(image_tar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "newModel = update_model_to_any_size(gan.generator)\n",
    "output_image = model_predict(newModel, image_arr, num_runs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"- 15k\", 'Prediction: ')\n",
    "acc_pred, iou_pred = evaluate(output_image > 0.5, image_tar)\n",
    "nr = 1\n",
    "save_prediction(output_image, fn_input, '_' + str(nr) + '_out.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "newModel = update_model_to_any_size(gan.generator)\n",
    "newModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
