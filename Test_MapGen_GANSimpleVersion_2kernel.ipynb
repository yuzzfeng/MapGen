{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Add, Lambda\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop, Adadelta\n",
    "from keras.applications import VGG19\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from data_helper import predict_15k, save_hist, save_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, History\n",
    "\n",
    "from time import gmtime, strftime\n",
    "from data_helper import readImg, readImgInv, imagePatches, removeBlackImg, removeCorrespondence, check_and_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapgenlib.losses_extend import dice_coef_loss, iou_loss, wasserstein_loss\n",
    "from mapgenlib.res_unit import res_block, decoder, encoder, build_res_unet\n",
    "from mapgenlib.discrimnator import build_discriminator_simple_dc, build_discriminator_critic\n",
    "from mapgenlib.discrimnator import build_discriminator_patchgan_srgan, build_discriminator_patchgan_cycle\n",
    "\n",
    "from functools import partial\n",
    "from keras.layers.merge import _Merge\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    \"\"\"Citation: https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan_gp/wgan_gp.py#L110\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((32, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN4MapGen(): # Based on u-net, residual u-net and pix2pix\n",
    "    # Reference: https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py\n",
    "    \n",
    "    def __init__(self, method, batch_size=16):\n",
    "\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        #self.clip_value = 0.01\n",
    "\n",
    "        ## Calculate output shape of D (PatchGAN) better version\n",
    "        #self.patch_size = 32\n",
    "        #self.nb_patches = int((self.img_rows / self.patch_size) * (self.img_cols / self.patch_size))\n",
    "        #self.patch_gan_dim = (self.patch_size, self.patch_size, self.channels)\n",
    "        \n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        self.df = 64\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.method = method\n",
    "        \n",
    "        if method == \"dc\":\n",
    "            self.initial_dc()\n",
    "            self.train_cell = self.train_cell_dc\n",
    "            self.valid_cell = self.valid_cell_dc\n",
    "            \n",
    "            # Adversarial ground truths\n",
    "            self.valid = np.ones((batch_size, 1))\n",
    "            self.fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        if method == \"wgangp\":\n",
    "            self.initial_wgangp()\n",
    "            self.train_cell = self.train_cell_wgangp\n",
    "            self.valid_cell = self.valid_cell_wgangp\n",
    "            \n",
    "            # Adversarial ground truths\n",
    "            self.valid = -np.ones((batch_size, 1))\n",
    "            self.fake =  np.ones((batch_size, 1))\n",
    "        \n",
    "        if method == \"srgan\":\n",
    "            # Calculate output shape of D (PatchGAN)\n",
    "            patch = int(self.img_rows / 2**4)\n",
    "            self.disc_patch = (patch, patch, 1)\n",
    "            \n",
    "            self.initial_srgan()\n",
    "            self.train_cell = self.train_cell_srgan\n",
    "            self.valid_cell = self.valid_cell_srgan\n",
    "            \n",
    "            self.valid = np.ones((batch_size,) + self.disc_patch)\n",
    "            self.fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        \n",
    "        if method == \"p2p\":\n",
    "            # Calculate output shape of D (PatchGAN)\n",
    "            patch = int(self.img_rows / 2**4)\n",
    "            self.disc_patch = (patch, patch, 1)\n",
    "            \n",
    "            self.initial_p2p()\n",
    "            self.train_cell = self.train_cell_p2p\n",
    "            self.valid_cell = self.valid_cell_p2p\n",
    "            \n",
    "            self.valid = np.ones((batch_size,) + self.disc_patch)\n",
    "            self.fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        \n",
    "        \"\"\"\n",
    "        #optimizer = Adam(0.0002, 0.5) # Original\n",
    "        #optimizer = Adam(0.0001, 0.5) # Original # Latest achieved by 0.00008\n",
    "        #optimizer = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # An old version of Pix2pix\n",
    "        optimizer = Adam(0.0004)\n",
    "        \n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        #self.generator = self.build_generator() # Old generator from \n",
    "        self.generator = self.build_res_unet_generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        #img_A = Input(shape=self.img_shape) # Target\n",
    "        img_B = Input(shape=self.img_shape) # Input\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        fake_A = self.generator(img_B)\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = build_discriminator_simple_dc(self.img_shape)\n",
    "        \n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "        #self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        #valid = self.discriminator([fake_A, img_B])\n",
    "        #self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "        \n",
    "        valid = self.discriminator(fake_A)\n",
    "        self.combined = Model(inputs= img_B, outputs=[valid, fake_A])\n",
    "        \n",
    "        # Original Pix2Pix - low weight for discriminator\n",
    "        self.combined.compile(loss=['mse', 'mae'], #['mse', 'mae'] original\n",
    "                              loss_weights=[1, 100], # [1, 100] original\n",
    "                              optimizer=optimizer, metrics=['accuracy'])\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\" WGAN_GP \"\"\"\n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "    \n",
    "    def initial_wgangp(self):\n",
    "        \n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build the generator and critic\n",
    "        self.generator = build_res_unet(self.img_shape)\n",
    "        self.critic = build_discriminator_critic(self.img_shape)\n",
    "        \n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "        \n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "        \n",
    "        # Input images and generate imgs\n",
    "        src_img = Input(shape=self.img_shape)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "        fake_img = self.generator(src_img)\n",
    "        \n",
    "        # Discriminator determines validity of the real and fake images\n",
    "        fake = self.critic(fake_img)\n",
    "        valid = self.critic(real_img)\n",
    "        \n",
    "        # Construct weighted average between real and fake images\n",
    "        interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
    "        # Determine validity of weighted sample\n",
    "        validity_interpolated = self.critic(interpolated_img)\n",
    "        \n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss, averaged_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_img, src_img], outputs=[valid, fake, validity_interpolated])\n",
    "        self.critic_model.compile(loss=[wasserstein_loss, wasserstein_loss, partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, 10])\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Generate images based of noise\n",
    "        fake_img = self.generator(src_img)\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(fake_img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(src_img, [valid, fake_img])\n",
    "        self.generator_model.compile(loss=[wasserstein_loss, \"mse\"], optimizer=optimizer)\n",
    "        \n",
    "    def train_cell_wgangp(self, imgs_A, imgs_B, valid, fake):\n",
    "        \n",
    "        dummy = np.zeros((self.batch_size, 1)) # Dummy gt for gradient penalty\n",
    "        \n",
    "        for _ in range(self.n_critic):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            # Train the critic\n",
    "            d_loss = self.critic_model.train_on_batch([imgs_A, imgs_B], [valid, fake, dummy])\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        g_loss = self.generator_model.train_on_batch(imgs_B, valid)\n",
    "        return d_loss, g_loss\n",
    "    \n",
    "    def valid_cell_wgangp(self, x_test_sim, y_test_sim):\n",
    "        num_test = len(x_test_sim)\n",
    "        valid_test = np.ones((num_test,1))\n",
    "        t_loss = self.generator_model.evaluate(x_test_sim, [valid_test, y_test_sim], verbose=0)\n",
    "        return t_loss\n",
    "    \"\"\" WGAN_GP ends\"\"\" \n",
    "    \n",
    "    \n",
    "    \"\"\" Pix2Pix \"\"\"\n",
    "    def initial_p2p(self):\n",
    "        \n",
    "        optimizer = Adam(0.0004)\n",
    "        \n",
    "        # Build the generator\n",
    "        self.generator = build_res_unet(self.img_shape)\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = build_discriminator_patchgan_cycle(self.img_shape, self.df)\n",
    "        #self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # Input images and generate imgs\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "        fake_A = self.generator(img_B)\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(fake_A)\n",
    "        \n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(inputs=img_B, outputs=[valid, fake_A])\n",
    "        #self.combined.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1, 100], \n",
    "        #                      optimizer=optimizer, metrics=['accuracy'])\n",
    "        #self.combined.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1, 10], \n",
    "        #                      optimizer=optimizer, metrics=['accuracy'])\n",
    "        #self.combined.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1, 100], \n",
    "        #                      optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        self.combined.compile(loss=['mse', 'mae'], # Oroginal pix2pix\n",
    "                              loss_weights=[1, 100], \n",
    "                              optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "    def train_cell_p2p(self, imgs_A, imgs_B, valid, fake):\n",
    "        # Condition on B and generate a translated version\n",
    "        fake_A = self.generator.predict(imgs_B)\n",
    "                \n",
    "        # Train the discriminators (original images = real / generated = Fake)\n",
    "        d_loss_real = self.discriminator.train_on_batch(imgs_A, valid)\n",
    "        d_loss_fake = self.discriminator.train_on_batch(fake_A, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # Train the generators\n",
    "        g_loss = self.combined.train_on_batch(imgs_B, [valid, imgs_A])\n",
    "        return d_loss, g_loss\n",
    "    \n",
    "    def valid_cell_p2p(self, x_test_sim, y_test_sim):\n",
    "        num_test = len(x_test_sim)\n",
    "        valid_test = np.ones((num_test,) + self.disc_patch)\n",
    "        t_loss = self.combined.evaluate(x_test_sim, [valid_test, y_test_sim], verbose=0)\n",
    "        return t_loss\n",
    "    \"\"\" Pix2Pix ends\"\"\" \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\" SRGAN \"\"\"\n",
    "    def initial_srgan(self):\n",
    "        optimizer = Adam(0.0004)\n",
    "        \n",
    "        # We use a pre-trained VGG19 model to extract image features from the high resolution\n",
    "        # and the generated high resolution images and minimize the mse between them\n",
    "        self.vgg = self.build_vgg()\n",
    "        self.vgg.trainable = False\n",
    "        self.vgg.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = build_discriminator_patchgan_srgan(self.img_shape, self.df)\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # Build the generator\n",
    "        self.generator = build_res_unet(self.img_shape)\n",
    "        self.generator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Input images and generate imgs\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "        \n",
    "        # Generate image\n",
    "        fake_A = self.generator(img_B)\n",
    "        \n",
    "        # Extract image features of the generated img\n",
    "        fake_features = self.vgg(fake_A)\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(fake_A)\n",
    "        \n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(inputs=[img_B, img_A], outputs=[valid, fake_features])\n",
    "        self.combined.compile(loss=['binary_crossentropy', 'mse'], \n",
    "                              loss_weights=[1, 10], optimizer=optimizer, metrics=['mae'])\n",
    "    \n",
    "    def train_cell_srgan(self, imgs_A, imgs_B, valid, fake):\n",
    "        # Condition on B and generate a translated version\n",
    "        fake_A = self.generator.predict(imgs_B)\n",
    "                \n",
    "        # Train the discriminators (original images = real / generated = Fake)\n",
    "        d_loss_real = self.discriminator.train_on_batch(imgs_A, valid)\n",
    "        d_loss_fake = self.discriminator.train_on_batch(fake_A, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        valid = np.ones((self.batch_size,) + self.disc_patch)\n",
    "        \n",
    "        image_features = self.vgg.predict(imgs_A)\n",
    "        \n",
    "        # Train the generators\n",
    "        g_loss = self.combined.train_on_batch([imgs_B, imgs_A], [valid, image_features])\n",
    "        return d_loss, g_loss\n",
    "    \n",
    "    def valid_cell_srgan(self, x_test_sim, y_test_sim):\n",
    "        num_test = len(x_test_sim)\n",
    "        valid_test = np.ones((num_test,) + self.disc_patch)\n",
    "        t_loss = self.generator.evaluate(x_test_sim, y_test_sim, verbose=0)\n",
    "        return t_loss\n",
    "    \"\"\" SRGAN ends\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\" DCGAN \"\"\"\n",
    "    def initial_dc(self):\n",
    "        \n",
    "        optimizer = Adam(0.0004)\n",
    "        \n",
    "        # Build the generator\n",
    "        self.generator = build_res_unet(self.img_shape)\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = build_discriminator_simple_dc(self.img_shape)\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # Input images and generate imgs\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "        fake_A = self.generator(img_B)\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(fake_A)\n",
    "        \n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(inputs=img_B, outputs=[valid, fake_A])\n",
    "        self.combined.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1, 100], optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "    def train_cell_dc(self, imgs_A, imgs_B, valid, fake):\n",
    "        # Condition on B and generate a translated version\n",
    "        fake_A = self.generator.predict(imgs_B)\n",
    "                \n",
    "        # Train the discriminators (original images = real / generated = Fake)\n",
    "        d_loss_real = self.discriminator.train_on_batch(imgs_A, valid)\n",
    "        d_loss_fake = self.discriminator.train_on_batch(fake_A, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # Train the generators\n",
    "        g_loss = self.combined.train_on_batch(imgs_B, [valid, imgs_A])\n",
    "        return d_loss, g_loss\n",
    "    \n",
    "    def valid_cell_dc(self, x_test_sim, y_test_sim):\n",
    "        num_test = len(x_test_sim)\n",
    "        valid_test = np.ones((num_test,1))\n",
    "        t_loss = self.combined.evaluate(x_test_sim, [valid_test, y_test_sim], verbose=0)\n",
    "        return t_loss\n",
    "    \"\"\" DC ends\"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def train(self, x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath, epochs, sample_interval=50, patience = 5):\n",
    "    \n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        valid = self.valid\n",
    "        fake  = self.fake\n",
    "        \n",
    "        total_samples = len(x_train_sim)\n",
    "        ids = np.arange(total_samples)\n",
    "        np.random.shuffle(ids)\n",
    "        n_batches = int(total_samples / self.batch_size)\n",
    "        \n",
    "        train_acc = []\n",
    "        train_loss = []\n",
    "        valid_acc = []\n",
    "        valid_loss = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(load_batch(x_train_sim, y_train_sim, self.batch_size)):\n",
    "            \n",
    "                d_loss, g_loss = self.train_cell(imgs_A, imgs_B, valid, fake)\n",
    "            \n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.train_log(start_time, epoch, epochs, batch_i, n_batches, d_loss, g_loss)\n",
    "                    print(g_loss)\n",
    "            \n",
    "            if epoch >= 0:\n",
    "                t_loss = self.valid_cell(x_test_sim, y_test_sim)\n",
    "                \n",
    "                if self.method == \"srgan\":\n",
    "                    self.valid_log_sr(start_time, epoch, epochs, batch_i, n_batches, d_loss, g_loss, t_loss)\n",
    "                    valid_loss.append(t_loss[0])\n",
    "                    valid_acc.append(t_loss[1])\n",
    "                else:\n",
    "                    self.valid_log(start_time, epoch, epochs, batch_i, n_batches, d_loss, g_loss, t_loss)\n",
    "                    valid_loss.append(t_loss[2])\n",
    "                    valid_acc.append(t_loss[4])\n",
    "                \n",
    "                train_loss.append(g_loss[2])\n",
    "                train_acc.append(g_loss[4])\n",
    "                \n",
    "                waited = len(valid_loss) - 1 - np.argmin(valid_loss)\n",
    "                print('waited for', waited, valid_loss)\n",
    "                    \n",
    "                if waited == 0:\n",
    "                    self.generator.save(outPath + 'model_epoch'+ str(epoch) +'.h5')   \n",
    "                        \n",
    "                if waited > patience:\n",
    "                    break\n",
    "            \n",
    "        return train_acc, train_loss, valid_acc, valid_loss\n",
    "    \n",
    "    def build_vgg(self):\n",
    "        \"\"\"\n",
    "        Builds a pre-trained VGG19 model that outputs image features extracted at the\n",
    "        third block of the model\n",
    "        \"\"\"\n",
    "        vgg = VGG19(weights=\"imagenet\")\n",
    "        # Set outputs to outputs of last conv. layer in block 3\n",
    "        # See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n",
    "        vgg.outputs = [vgg.layers[9].output]\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        imgc = Concatenate()([img, img, img]) \n",
    "\n",
    "        # Extract image features\n",
    "        img_features = vgg(imgc)\n",
    "\n",
    "        return Model(img, img_features)\n",
    "\n",
    "    \n",
    "    def train_log(self, start_time, epoch, epochs, batch_i, n_batches, d_loss, g_loss):\n",
    "        elapsed_time = datetime.datetime.now() - start_time\n",
    "        print (\"[Epoch %d/%d-%d/%d] [D loss&acc: %.3f, %.3f%%] [G loss&accA&accB: %.3f, %.3f%%, %.3f%%] time: %s\" % (epoch, epochs,\n",
    "                                                                                batch_i, n_batches,\n",
    "                                                                                d_loss[0], 100*d_loss[1],\n",
    "                                                                                100*g_loss[2], 100*g_loss[3], 100*g_loss[4],\n",
    "                                                                                elapsed_time))    \n",
    "    \n",
    "    def valid_log_sr(self, start_time, epoch, epochs, batch_i, n_batches, d_loss, g_loss, t_loss):\n",
    "        elapsed_time = datetime.datetime.now() - start_time\n",
    "        print (\"[Epoch %d/%d-%d/%d] [D loss&acc: %.3f, %.3f%%] [G loss&accA&accB: %.3f, %.3f%%, %.3f%%] time: %s\" % (epoch, epochs,\n",
    "                                                                                batch_i, n_batches,\n",
    "                                                                                d_loss[0], 100*d_loss[1],\n",
    "                                                                                100*g_loss[2], 100*g_loss[3], 100*g_loss[4],\n",
    "                                                                                elapsed_time))   \n",
    "        print(t_loss)\n",
    "    \n",
    "    def valid_log(self, start_time, epoch, epochs, batch_i, n_batches, d_loss, g_loss, t_loss):\n",
    "        elapsed_time = datetime.datetime.now() - start_time\n",
    "        print (\"[Epoch %d/%d-%d/%d] [D loss&acc: %.3f, %.3f%%] [G loss&accA&accB: %.3f, %.3f%%, %.3f%%] [Test loss&acc: %.3f, %.3f%%, %.3f%%] time: %s\" % (epoch, epochs,\n",
    "                                                                                batch_i, n_batches,\n",
    "                                                                                d_loss[0], 100*d_loss[1],\n",
    "                                                                                100*g_loss[2], 100*g_loss[3], 100*g_loss[4],\n",
    "                                                                                100*t_loss[2], 100*t_loss[3], 100*t_loss[4],\n",
    "                                                                                elapsed_time))    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gan = GAN4MapGen(\"p2p\", batch_size = 16)\n",
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the image dimension acc. to TensorFlow (batc_hsize, rows, cols, channels)\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "scale = 25\n",
    "p_size_1 = 128 # Compared with 256, which larger may generate round corners\n",
    "trainPath = r\"../tmp_data/data_feng_/geb\" + str(scale) +  \"/\"\n",
    "\n",
    "# save image patch arrays\n",
    "x_train_sim = np.load(trainPath + \"x_train_sim.npy\")\n",
    "y_train_sim = np.load(trainPath + \"y_train_sim.npy\")\n",
    "x_test_sim = np.load(trainPath + \"x_test_sim.npy\")\n",
    "y_test_sim = np.load(trainPath + \"y_test_sim.npy\")\n",
    "\n",
    "input_shape1 = (None, None, 1) #x_train_sim[0].shape\n",
    "print('Input Shape of the trains', x_train_sim.shape)\n",
    "print('Input Shape of the tests', x_test_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(x_train_sim, y_train_sim, batch_size):\n",
    "    total_samples = len(x_train_sim)\n",
    "    ids = np.arange(total_samples)\n",
    "    np.random.shuffle(ids)\n",
    "    n_batches = int(total_samples / batch_size)\n",
    "    for i in range(n_batches-1):\n",
    "        batch_idx = ids[i*batch_size:(i+1)*batch_size]\n",
    "        imgs_A = x_train_sim[batch_idx]\n",
    "        imgs_B = y_train_sim[batch_idx]\n",
    "        yield imgs_B, imgs_A     \n",
    "        \n",
    "def load_data(x_test_sim, y_test_sim, batch_size=1):\n",
    "    return x_test_sim  \n",
    "\n",
    "def save_hist_local(train_acc, train_loss, valid_acc, valid_loss, outPath):    \n",
    "    ### Save history\n",
    "    History1_loss = train_loss\n",
    "    History1_acc = train_acc\n",
    "    History1_val_loss = valid_loss\n",
    "    History1_val_acc = valid_acc\n",
    "\n",
    "    thefile1 = open(outPath + 'History1_loss.txt', 'w')\n",
    "    for item in History1_loss:\n",
    "        thefile1.write(\"%s\\n\" % item)\n",
    "    thefile1.close()\n",
    "\n",
    "    thefile2 = open(outPath + 'History1_acc.txt', 'w')\n",
    "    for item in History1_acc:\n",
    "        thefile2.write(\"%s\\n\" % item)\n",
    "    thefile2.close()\n",
    "\n",
    "    thefile3 = open(outPath + 'History1_val_loss.txt', 'w')\n",
    "    for item in History1_val_loss:\n",
    "        thefile3.write(\"%s\\n\" % item)\n",
    "    thefile3.close()\n",
    "\n",
    "    thefile4 = open(outPath + 'History1_val_acc.txt', 'w')\n",
    "    for item in History1_val_acc:\n",
    "        thefile4.write(\"%s\\n\" % item)\n",
    "    thefile4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train residual unet + Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Path Setting ##############\n",
    "outPath = r\"../tmp_results/predictions/\"\n",
    "timestr = strftime(\"U\"+str(p_size_1)+\"GAN_%Y-%m-%d %H-%M-%S\", gmtime())\n",
    "outPath = outPath + timestr + '_' + str(scale)+ \"/\"\n",
    "check_and_create(outPath)\n",
    "print(outPath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gan = GAN4MapGen(\"dc\", batch_size = 16)\n",
    "train_acc, train_loss, valid_acc, valid_loss = gan.train(x_train_sim, y_train_sim, x_test_sim, y_test_sim, \n",
    "                                                         outPath, epochs=50, sample_interval=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gan = GAN4MapGen(\"wgangp\", batch_size = 16)\n",
    "train_acc, train_loss, valid_acc, valid_loss = gan.train(x_train_sim, y_train_sim, x_test_sim, y_test_sim, \n",
    "                                                         outPath, epochs=50, sample_interval=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gan = GAN4MapGen(\"srgan\", batch_size = 2)\n",
    "train_acc, train_loss, valid_acc, valid_loss = gan.train(x_train_sim, y_train_sim, x_test_sim, y_test_sim, \n",
    "                                                         outPath, epochs=50, sample_interval=500, patience = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN4MapGen(\"p2p\", batch_size = 16)\n",
    "train_acc, train_loss, valid_acc, valid_loss = gan.train(x_train_sim, y_train_sim, x_test_sim, y_test_sim, \n",
    "                                                         outPath, epochs=50, sample_interval=1000, patience = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist_local(train_acc, train_loss, valid_acc, valid_loss, outPath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
