{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from data_helper import predict_15k, save_hist, save_model\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Add, Lambda\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def lambda_output(input_shape):\n",
    "    return input_shape[:2]\n",
    "\n",
    "def minb_disc(x):\n",
    "    diffs = K.expand_dims(x, 3) - K.expand_dims(K.permute_dimensions(x, [1, 2, 0]), 0)\n",
    "    abs_diffs = K.sum(K.abs(diffs), 2)\n",
    "    x = K.sum(K.exp(-abs_diffs), 2)\n",
    "\n",
    "    return x\n",
    "\n",
    "def generate_patch_gan_loss(last_disc_conv_layer, patch_dim, input_layer, nb_patches):\n",
    "\n",
    "    # generate a list of inputs for the different patches to the network\n",
    "    list_input = [Input(shape=patch_dim, name=\"patch_gan_input_%s\" % i) for i in range(nb_patches)]\n",
    "\n",
    "    # get an activation\n",
    "    x_flat = Flatten()(last_disc_conv_layer)\n",
    "    x = Dense(2, activation='softmax', name=\"disc_dense\")(x_flat)\n",
    "\n",
    "    patch_gan = Model(inputs=[input_layer], outputs=[x, x_flat], name=\"patch_gan\")\n",
    "\n",
    "    # generate individual losses for each patch\n",
    "    x = [patch_gan(patch)[0] for patch in list_input]\n",
    "    x_mbd = [patch_gan(patch)[1] for patch in list_input]\n",
    "\n",
    "    # merge layers if have multiple patches (aka perceptual loss)\n",
    "    if len(x) > 1:\n",
    "        #x = merge(x, mode=\"concat\", name=\"merged_features\")\n",
    "        x = Concatenate(name=\"merged_features\")(x)\n",
    "    else:\n",
    "        x = x[0]\n",
    "\n",
    "    # merge mbd if needed\n",
    "    # mbd = mini batch discrimination\n",
    "    # https://arxiv.org/pdf/1606.03498.pdf\n",
    "    if len(x_mbd) > 1:\n",
    "        #x_mbd = merge(x_mbd, mode=\"concat\", name=\"merged_feature_mbd\")\n",
    "        x_mbd = Concatenate(name=\"merged_feature_mbd\")(x_mbd)\n",
    "    else:\n",
    "        x_mbd = x_mbd[0]\n",
    "\n",
    "    num_kernels = 100\n",
    "    dim_per_kernel = 5\n",
    "\n",
    "    M = Dense(num_kernels * dim_per_kernel, use_bias=False, activation=None)\n",
    "    MBD = Lambda(minb_disc, output_shape=lambda_output)\n",
    "\n",
    "    x_mbd = M(x_mbd)\n",
    "    x_mbd = Reshape((num_kernels, dim_per_kernel))(x_mbd)\n",
    "    x_mbd = MBD(x_mbd)\n",
    "    \n",
    "    #x = merge([x, x_mbd], mode='concat')\n",
    "    x = Concatenate()([x, x_mbd])\n",
    "\n",
    "    x_out = Dense(2, activation=\"softmax\", name=\"disc_output\")(x)\n",
    "\n",
    "    discriminator = Model(inputs=list_input, outputs=[x_out], name='discriminator_nn')\n",
    "    return discriminator\n",
    "\n",
    "def res_block(x, nb_filters, strides):\n",
    "    res_path = BatchNormalization()(x)\n",
    "    res_path = Activation(activation='relu')(res_path)\n",
    "    \n",
    "    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same', strides=strides[0])(res_path)\n",
    "    res_path = BatchNormalization()(res_path)\n",
    "    res_path = Activation(activation='relu')(res_path)\n",
    "    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same', strides=strides[1])(res_path)\n",
    "\n",
    "    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1), strides=strides[0])(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    res_path = Add()([shortcut, res_path])\n",
    "    return res_path\n",
    "\n",
    "def decoder(x, from_encoder):\n",
    "    main_path = UpSampling2D(size=(2, 2))(x)\n",
    "    main_path = Concatenate(axis=3)([main_path, from_encoder[2]])\n",
    "    main_path = res_block(main_path, [128, 128], [(1, 1), (1, 1)])\n",
    "\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path) \n",
    "    main_path = Concatenate(axis=3)([main_path, from_encoder[1]])\n",
    "    main_path = res_block(main_path, [64, 64], [(1, 1), (1, 1)])\n",
    "\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    main_path = Concatenate(axis=3)([main_path, from_encoder[0]])\n",
    "    main_path = res_block(main_path, [32, 32], [(1, 1), (1, 1)])\n",
    "\n",
    "    return main_path\n",
    "\n",
    "def encoder(x):\n",
    "    to_decoder = []\n",
    "\n",
    "    main_path = Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n",
    "    main_path = BatchNormalization()(main_path)\n",
    "    main_path = Activation(activation='relu')(main_path)\n",
    "    main_path = Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1, 1))(main_path)\n",
    "\n",
    "    shortcut = Conv2D(filters=32, kernel_size=(1, 1), strides=(1, 1))(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    main_path = Add()([shortcut, main_path])\n",
    "    # first branching to decoder\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    main_path = res_block(main_path, [64, 64], [(2, 2), (1, 1)])\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    main_path = res_block(main_path, [128, 128], [(2, 2), (1, 1)])\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    return to_decoder\n",
    "\n",
    "\n",
    "def build_res_unet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    to_decoder = encoder(inputs)\n",
    "\n",
    "    path = res_block(to_decoder[2], [256, 256], [(2, 2), (1, 1)]) # 3x\n",
    "    \n",
    "    path = res_block(path, [256, 256], [(1, 1), (1, 1)]) # Yu.add - in 2018-12-02 16-09-04_15 only once\n",
    "\n",
    "    path = decoder(path, from_encoder=to_decoder)\n",
    "    \n",
    "    path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path) \n",
    "\n",
    "    return Model(input=inputs, output=path)\n",
    "\n",
    "class EL_GAN(): # Based on pix2pix\n",
    "    def __init__(self):\n",
    "\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'mapgen'\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN) better version\n",
    "        self.patch_size = 32\n",
    "        self.nb_patches = int((self.img_rows / self.patch_size) * (self.img_cols / self.patch_size))\n",
    "        self.patch_gan_dim = (self.patch_size, self.patch_size, self.channels)\n",
    "        \n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        self.df = 64\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        #optimizer = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # An old version of Pix2pix\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        #self.generator = self.build_generator() # Old generator from \n",
    "        self.generator = self.build_res_unet_generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        img_A = Input(shape=self.img_shape) # Target\n",
    "        img_B = Input(shape=self.img_shape) # Input\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        fake_A = self.generator(img_B)\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        #valid = self.discriminator([fake_A, img_B])\n",
    "        valid = self.discriminator([fake_A])\n",
    "\n",
    "        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "        \n",
    "        # Original Pix2Pix - low weight for discriminator\n",
    "        self.combined.compile(loss=['mse', 'mae'],\n",
    "                              loss_weights=[1, 100],\n",
    "                              optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    def build_res_unet_generator(self):\n",
    "        \"\"\"Residual U-Net Generator\"\"\"\n",
    "        \n",
    "        inputs = Input(shape=self.img_shape)\n",
    "        to_decoder = encoder(inputs)\n",
    "        path = res_block(to_decoder[2], [256, 256], [(2, 2), (1, 1)]) # 3x\n",
    "        path = res_block(path, [256, 256], [(1, 1), (1, 1)])\n",
    "        path = decoder(path, from_encoder=to_decoder)\n",
    "        path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path) \n",
    "\n",
    "        return Model(input=inputs, output=path)\n",
    "        \n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, self.gf*8)\n",
    "        u2 = deconv2d(u1, d5, self.gf*8)\n",
    "        u3 = deconv2d(u2, d4, self.gf*8)\n",
    "        u4 = deconv2d(u3, d3, self.gf*4)\n",
    "        u5 = deconv2d(u4, d2, self.gf*2)\n",
    "        u6 = deconv2d(u5, d1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "    \n",
    "    def build_PatchGanDiscriminator(self):\n",
    "        \"\"\"\n",
    "        Creates the generator according to the specs in the paper below.\n",
    "        [https://arxiv.org/pdf/1611.07004v1.pdf][5. Appendix]\n",
    "\n",
    "        PatchGAN only penalizes structure at the scale of patches. This\n",
    "        discriminator tries to classify if each N x N patch in an\n",
    "        image is real or fake. We run this discriminator convolutationally\n",
    "        across the image, averaging all responses to provide\n",
    "        the ultimate output of D.\n",
    "\n",
    "        The discriminator has two parts. First part is the actual discriminator\n",
    "        seconds part we make it a PatchGAN by running each image patch through the model\n",
    "        and then we average the responses\n",
    "\n",
    "        Discriminator does the following:\n",
    "        1. Runs many pieces of the image through the network\n",
    "        2. Calculates the cost for each patch\n",
    "        3. Returns the avg of the costs as the output of the network\n",
    "\n",
    "        :param patch_dim: (channels, width, height) T\n",
    "        :param nb_patches:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # -------------------------------\n",
    "        # DISCRIMINATOR\n",
    "        # C64-C128-C256-C512-C512-C512 (for 256x256)\n",
    "        # otherwise, it scales from 64\n",
    "        # 1 layer block = Conv - BN - LeakyRelu\n",
    "        # -------------------------------\n",
    "        \n",
    "        output_img_dim = self.img_shape\n",
    "        patch_dim = self.patch_gan_dim\n",
    "        input_layer = Input(shape=patch_dim)\n",
    "        \n",
    "        # We have to build the discriminator dinamically because\n",
    "        # the size of the disc patches is dynamic\n",
    "        num_filters_start = self.gf\n",
    "        nb_conv = int(np.floor(np.log(output_img_dim[1]) / np.log(2)))\n",
    "        filters_list = [num_filters_start * min(8, (2 ** i)) for i in range(nb_conv)]\n",
    "        \n",
    "        # CONV 1\n",
    "        # Do first conv bc it is different from the rest\n",
    "        # paper skips batch norm for first layer\n",
    "        disc_out = Conv2D(filters=64, kernel_size=(4, 4), padding='same', strides=(2, 2), name='disc_conv_1')(input_layer)\n",
    "        disc_out = LeakyReLU(alpha=0.2)(disc_out)\n",
    "        \n",
    "        # CONV 2 - CONV N\n",
    "        # do the rest of the convs based on the sizes from the filters\n",
    "        for i, filter_size in enumerate(filters_list[1:]):\n",
    "            name = 'disc_conv_{}'.format(i+2)\n",
    "\n",
    "            disc_out = Conv2D(filters=filter_size, kernel_size=(4, 4), padding='same', strides=(2, 2), name=name)(disc_out)\n",
    "            disc_out = BatchNormalization(name=name + '_bn')(disc_out)\n",
    "            disc_out = LeakyReLU(alpha=0.2)(disc_out)\n",
    "        \n",
    "        # ------------------------\n",
    "        # BUILD PATCH GAN\n",
    "        # this is where we evaluate the loss over each sublayer of the input\n",
    "        # ------------------------\n",
    "        patch_gan_discriminator = generate_patch_gan_loss(last_disc_conv_layer=disc_out,\n",
    "                                                          patch_dim=patch_dim,\n",
    "                                                          input_layer=input_layer,\n",
    "                                                          nb_patches=nb_patches)\n",
    "        return patch_gan_discriminator\n",
    "    \n",
    "    def build_2head_discriminator(self):\n",
    "        \n",
    "        def d_layer(layer_input, filters, f_size=3, bn=True): # Chnaged here for the order of bn and activation\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            conv = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')\n",
    "            d = conv(layer_input)\n",
    "            e = conv(layer_input2)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Activation(activation='relu')(d)\n",
    "            #d = LeakyReLU(alpha=0.2)(d)\n",
    "            return d\n",
    "        \n",
    "        def d_layers(img_A):\n",
    "            d1 = d_layer(img_A, self.df, bn=False)\n",
    "            d2 = d_layer(d1, self.df*2)\n",
    "            d3 = d_layer(d2, self.df*4)\n",
    "            d4 = d_layer(d3, self.df*8)\n",
    "            d5 = Flatten()(d4)\n",
    "            d6 = Dense(128, activation='softmax')(d5)\n",
    "            \n",
    "            return Model(img_A, d6)\n",
    "        \n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "        \n",
    "        encoded_a = d_layers(img_A)\n",
    "        encoded_b = d_layers(img_B)\n",
    "        \n",
    "        # We can then concatenate the two vectors:\n",
    "        #merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=-1)\n",
    "        \n",
    "        return Model([img_A, img_B], validity)\n",
    "        \n",
    "    \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=3, bn=True): # Chnaged here for the order of bn and activation\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Activation(activation='relu')(d)\n",
    "            #d = LeakyReLU(alpha=0.2)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        #img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        ## Concatenate image and conditioning image by channels to produce input\n",
    "        #combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        #d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        \n",
    "        d1 = d_layer(img_A, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A], validity)\n",
    "    \n",
    "    def train_generator_only(self, x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath):\n",
    "        \n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        data_gen_args = dict(rotation_range=180.)\n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        \n",
    "        seed = 1\n",
    "        BATCH_SIZE = 16\n",
    "        result_generator = zip(image_datagen.flow(x_train_sim, batch_size=BATCH_SIZE, seed=seed), \n",
    "                               mask_datagen.flow(y_train_sim, batch_size=BATCH_SIZE, seed=seed))\n",
    "        \n",
    "        History1 = History()\n",
    "        hist1 = self.generator.fit_generator( result_generator,\n",
    "                                              epochs = 100,\n",
    "                                              steps_per_epoch=2000,\n",
    "                                              verbose=1,\n",
    "                                              shuffle=True,\n",
    "                                              callbacks=[History1, \n",
    "                                                         EarlyStopping(patience=5), \n",
    "                                                         ReduceLROnPlateau(patience = 3, verbose = 0),\n",
    "                                                         ModelCheckpoint(outPath + \"weights.hdf5\", \n",
    "                                                                         save_best_only = True, \n",
    "                                                                         save_weights_only = False)],\n",
    "                                              validation_data=(x_test_sim, y_test_sim))\n",
    "        save_hist(History1, outPath)\n",
    "        \n",
    "    \n",
    "    def train(self, x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        \n",
    "        total_samples = len(x_train_sim)\n",
    "        ids = np.arange(total_samples)\n",
    "        np.random.shuffle(ids)\n",
    "        n_batches = int(total_samples / batch_size)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(load_batch(x_train_sim, y_train_sim, batch_size)):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Condition on B and generate a translated version\n",
    "                fake_A = self.generator.predict(imgs_B)\n",
    "                \n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                #d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                #d_loss_fake = self.discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs_A], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([fake_A], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                # Train the generators\n",
    "                self.discriminator.trainable = False\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "                self.discriminator.trainable = True\n",
    "                \n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "                # Plot the progress\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    \n",
    "                    valid_test = np.ones((len(x_test_sim),) + self.disc_patch)\n",
    "                    t_loss = self.combined.evaluate([y_test_sim, x_test_sim], [valid_test, y_test_sim], verbose=0)\n",
    "                    \n",
    "                    print (\"[Epoch %d/%d-%d/%d] [D loss&acc: %.3f, %.3f%%] [G loss&accA&accB: %.3f, %.3f%%, %.3f%%] [Test loss&acc: %.3f, %.3f%%, %.3f%%] time: %s\" % (epoch, epochs,\n",
    "                                                                                batch_i, n_batches,\n",
    "                                                                                d_loss[0], 100*d_loss[1],\n",
    "                                                                                g_loss[2], 100*g_loss[3], 100*g_loss[4],\n",
    "                                                                                t_loss[2], 100*t_loss[3], 100*t_loss[4],\n",
    "                                                                                elapsed_time))                 \n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(outPath, epoch, batch_i)\n",
    "\n",
    "\n",
    "    def sample_images(self, outPath, epoch, batch_i, examples = [0, 77, 34]):\n",
    "        \n",
    "        r, c = 3, 3\n",
    "        p_size_1 = 128\n",
    "        \n",
    "        imgs_A = y_test_sim[examples]\n",
    "        imgs_B = x_test_sim[examples]\n",
    "        \n",
    "        fake_A = gan.generator.predict(imgs_B)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Input', 'Generated', 'Target']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                gen = np.reshape(gen_imgs[cnt], (p_size_1,p_size_1))\n",
    "                axs[i,j].imshow(gen)\n",
    "                \n",
    "                #axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(outPath + \"%d_%d.png\" % (epoch, batch_i),\n",
    "                   format='png', transparent=True, dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape of the trains (32289, 128, 128, 1)\n",
      "Input Shape of the tests (3587, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Order the image dimension acc. to TensorFlow (batc_hsize, rows, cols, channels)\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "scale = 15\n",
    "p_size_1 = 128 # Compared with 256, which larger may generate round corners\n",
    "trainPath = r\"../tmp_data/data_feng/geb\" + str(scale) +  \"/\"\n",
    "\n",
    "# save image patch arrays\n",
    "x_train_sim = np.load(trainPath + \"x_train_sim.npy\")\n",
    "y_train_sim = np.load(trainPath + \"y_train_sim.npy\")\n",
    "x_test_sim = np.load(trainPath + \"x_test_sim.npy\")\n",
    "y_test_sim = np.load(trainPath + \"y_test_sim.npy\")\n",
    "\n",
    "input_shape1 = (None, None, 1) #x_train_sim[0].shape\n",
    "print('Input Shape of the trains', x_train_sim.shape)\n",
    "print('Input Shape of the tests', x_test_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper import readImg, readImgInv, imagePatches, removeBlackImg, removeCorrespondence, check_and_create\n",
    "\n",
    "from time import gmtime, strftime\n",
    "timestr = strftime(\"%Y-%m-%d %H-%M-%S\", gmtime())\n",
    "\n",
    "############ Path Setting ##############\n",
    "outPath = r\"../tmp_results/predictions/\"\n",
    "outPath = outPath + timestr + '_' + str(scale)+ \"/\"\n",
    "check_and_create(outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(x_train_sim, y_train_sim, batch_size):\n",
    "    total_samples = len(x_train_sim)\n",
    "    ids = np.arange(total_samples)\n",
    "    np.random.shuffle(ids)\n",
    "    n_batches = int(total_samples / batch_size)\n",
    "    for i in range(n_batches-1):\n",
    "        batch_idx = ids[i*batch_size:(i+1)*batch_size]\n",
    "        imgs_A = x_train_sim[batch_idx]\n",
    "        imgs_B = y_train_sim[batch_idx]\n",
    "        yield imgs_B, imgs_A     \n",
    "        \n",
    "def load_data(x_test_sim, y_test_sim, batch_size=1):\n",
    "    return x_test_sim  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:212: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/26-0/1009] [D loss&acc: 3.540, 13.916%] [G loss&accA&accB: 0.534, 12.744%, 30.219%] [Test loss&acc: 0.337, 0.000%, 72.292%] time: 0:00:09.724422\n",
      "[Epoch 0/26-200/1009] [D loss&acc: 0.335, 13.843%] [G loss&accA&accB: 0.010, 10.742%, 98.986%] [Test loss&acc: 0.011, 0.000%, 98.964%] time: 0:01:28.663304\n",
      "[Epoch 0/26-400/1009] [D loss&acc: 0.327, 12.402%] [G loss&accA&accB: 0.010, 12.695%, 98.998%] [Test loss&acc: 0.010, 0.000%, 98.973%] time: 0:02:47.241379\n",
      "[Epoch 0/26-600/1009] [D loss&acc: 0.318, 10.498%] [G loss&accA&accB: 0.013, 12.842%, 98.676%] [Test loss&acc: 0.010, 0.000%, 98.978%] time: 0:04:05.856131\n",
      "[Epoch 0/26-800/1009] [D loss&acc: 0.307, 8.960%] [G loss&accA&accB: 0.011, 8.545%, 98.922%] [Test loss&acc: 0.010, 0.000%, 98.982%] time: 0:05:24.487994\n",
      "[Epoch 0/26-1000/1009] [D loss&acc: 0.301, 20.703%] [G loss&accA&accB: 0.007, 4.297%, 99.266%] [Test loss&acc: 0.010, 0.000%, 98.988%] time: 0:06:43.126355\n",
      "[Epoch 1/26-0/1009] [D loss&acc: 0.308, 9.961%] [G loss&accA&accB: 0.011, 8.105%, 98.914%] [Test loss&acc: 0.010, 0.000%, 98.981%] time: 0:06:56.278927\n",
      "[Epoch 1/26-200/1009] [D loss&acc: 0.300, 10.498%] [G loss&accA&accB: 0.007, 11.328%, 99.297%] [Test loss&acc: 0.010, 0.000%, 98.985%] time: 0:08:15.185325\n",
      "[Epoch 1/26-400/1009] [D loss&acc: 0.288, 39.941%] [G loss&accA&accB: 0.008, 1.758%, 99.194%] [Test loss&acc: 0.010, 0.000%, 98.995%] time: 0:09:33.883477\n",
      "[Epoch 1/26-600/1009] [D loss&acc: 0.301, 33.057%] [G loss&accA&accB: 0.008, 34.521%, 99.239%] [Test loss&acc: 0.010, 0.000%, 98.988%] time: 0:10:52.602406\n",
      "[Epoch 1/26-800/1009] [D loss&acc: 0.290, 13.403%] [G loss&accA&accB: 0.009, 6.738%, 99.113%] [Test loss&acc: 0.010, 0.000%, 99.000%] time: 0:12:11.227439\n",
      "[Epoch 1/26-1000/1009] [D loss&acc: 0.291, 11.230%] [G loss&accA&accB: 0.011, 3.418%, 98.915%] [Test loss&acc: 0.010, 0.000%, 99.003%] time: 0:13:29.983612\n",
      "[Epoch 2/26-0/1009] [D loss&acc: 0.293, 30.518%] [G loss&accA&accB: 0.006, 3.125%, 99.441%] [Test loss&acc: 0.010, 0.000%, 99.000%] time: 0:13:43.159250\n",
      "[Epoch 2/26-200/1009] [D loss&acc: 0.288, 16.675%] [G loss&accA&accB: 0.008, 5.908%, 99.208%] [Test loss&acc: 0.010, 0.000%, 99.007%] time: 0:15:01.876161\n",
      "[Epoch 2/26-400/1009] [D loss&acc: 0.298, 7.300%] [G loss&accA&accB: 0.009, 5.029%, 99.142%] [Test loss&acc: 0.010, 0.000%, 99.013%] time: 0:16:20.515514\n",
      "[Epoch 2/26-600/1009] [D loss&acc: 0.304, 8.325%] [G loss&accA&accB: 0.006, 1.562%, 99.403%] [Test loss&acc: 0.010, 25.852%, 99.015%] time: 0:17:39.208278\n",
      "[Epoch 2/26-800/1009] [D loss&acc: 0.280, 16.431%] [G loss&accA&accB: 0.007, 14.404%, 99.315%] [Test loss&acc: 0.010, 0.000%, 99.022%] time: 0:18:57.916003\n",
      "[Epoch 2/26-1000/1009] [D loss&acc: 0.328, 3.516%] [G loss&accA&accB: 0.031, 3.174%, 96.883%] [Test loss&acc: 0.010, 5.364%, 99.037%] time: 0:20:16.625821\n",
      "[Epoch 3/26-0/1009] [D loss&acc: 0.326, 2.808%] [G loss&accA&accB: 0.009, 1.855%, 99.132%] [Test loss&acc: 0.010, 5.535%, 99.039%] time: 0:20:29.800923\n",
      "[Epoch 3/26-200/1009] [D loss&acc: 0.318, 2.539%] [G loss&accA&accB: 0.007, 2.393%, 99.318%] [Test loss&acc: 0.010, 10.938%, 99.031%] time: 0:21:48.439629\n",
      "[Epoch 3/26-400/1009] [D loss&acc: 0.304, 6.958%] [G loss&accA&accB: 0.009, 1.562%, 99.117%] [Test loss&acc: 0.010, 8.329%, 99.046%] time: 0:23:07.074973\n",
      "[Epoch 3/26-600/1009] [D loss&acc: 0.298, 8.203%] [G loss&accA&accB: 0.010, 6.592%, 99.007%] [Test loss&acc: 0.009, 2.522%, 99.070%] time: 0:24:25.650367\n",
      "[Epoch 3/26-800/1009] [D loss&acc: 0.309, 12.842%] [G loss&accA&accB: 0.012, 10.156%, 98.817%] [Test loss&acc: 0.038, 4.907%, 96.195%] time: 0:25:44.239086\n",
      "[Epoch 3/26-1000/1009] [D loss&acc: 0.288, 13.037%] [G loss&accA&accB: 0.006, 13.232%, 99.420%] [Test loss&acc: 0.010, 0.673%, 99.018%] time: 0:27:03.115573\n",
      "[Epoch 4/26-0/1009] [D loss&acc: 0.290, 13.086%] [G loss&accA&accB: 0.010, 13.232%, 99.023%] [Test loss&acc: 0.010, 1.090%, 99.024%] time: 0:27:16.278815\n",
      "[Epoch 4/26-200/1009] [D loss&acc: 0.287, 18.726%] [G loss&accA&accB: 0.007, 9.033%, 99.261%] [Test loss&acc: 0.009, 0.803%, 99.087%] time: 0:28:34.834805\n",
      "[Epoch 4/26-400/1009] [D loss&acc: 0.301, 10.474%] [G loss&accA&accB: 0.010, 23.535%, 98.992%] [Test loss&acc: 0.009, 0.000%, 99.098%] time: 0:29:53.434390\n",
      "[Epoch 4/26-600/1009] [D loss&acc: 0.317, 5.176%] [G loss&accA&accB: 0.010, 4.004%, 98.996%] [Test loss&acc: 0.009, 31.790%, 99.103%] time: 0:31:11.958440\n",
      "[Epoch 4/26-800/1009] [D loss&acc: 0.286, 20.850%] [G loss&accA&accB: 0.011, 2.197%, 98.942%] [Test loss&acc: 0.009, 14.448%, 99.111%] time: 0:32:30.511455\n",
      "[Epoch 4/26-1000/1009] [D loss&acc: 0.286, 19.263%] [G loss&accA&accB: 0.006, 9.570%, 99.398%] [Test loss&acc: 0.008, 20.362%, 99.168%] time: 0:33:49.060642\n",
      "[Epoch 5/26-0/1009] [D loss&acc: 0.286, 7.666%] [G loss&accA&accB: 0.005, 6.104%, 99.483%] [Test loss&acc: 0.008, 20.884%, 99.167%] time: 0:34:02.225546\n",
      "[Epoch 5/26-200/1009] [D loss&acc: 0.321, 6.177%] [G loss&accA&accB: 0.010, 6.201%, 98.971%] [Test loss&acc: 0.009, 0.000%, 99.127%] time: 0:35:20.735091\n",
      "[Epoch 5/26-400/1009] [D loss&acc: 0.293, 10.645%] [G loss&accA&accB: 0.009, 8.740%, 99.092%] [Test loss&acc: 0.008, 7.195%, 99.154%] time: 0:36:39.127974\n",
      "[Epoch 5/26-600/1009] [D loss&acc: 0.288, 17.090%] [G loss&accA&accB: 0.008, 5.762%, 99.219%] [Test loss&acc: 0.009, 7.084%, 99.131%] time: 0:37:57.487015\n",
      "[Epoch 5/26-800/1009] [D loss&acc: 0.294, 7.031%] [G loss&accA&accB: 0.005, 1.465%, 99.496%] [Test loss&acc: 0.008, 27.953%, 99.187%] time: 0:39:15.917390\n",
      "[Epoch 5/26-1000/1009] [D loss&acc: 0.286, 9.619%] [G loss&accA&accB: 0.006, 3.174%, 99.420%] [Test loss&acc: 0.008, 32.254%, 99.215%] time: 0:40:34.224183\n",
      "[Epoch 6/26-0/1009] [D loss&acc: 0.286, 7.593%] [G loss&accA&accB: 0.006, 4.883%, 99.362%] [Test loss&acc: 0.008, 32.103%, 99.222%] time: 0:40:47.371457\n",
      "[Epoch 6/26-200/1009] [D loss&acc: 0.288, 9.888%] [G loss&accA&accB: 0.006, 11.572%, 99.417%] [Test loss&acc: 0.008, 20.687%, 99.213%] time: 0:42:05.695565\n",
      "[Epoch 6/26-400/1009] [D loss&acc: 0.284, 21.436%] [G loss&accA&accB: 0.007, 15.771%, 99.342%] [Test loss&acc: 0.008, 20.804%, 99.226%] time: 0:43:24.017715\n",
      "[Epoch 6/26-600/1009] [D loss&acc: 0.308, 3.540%] [G loss&accA&accB: 0.007, 1.318%, 99.334%] [Test loss&acc: 0.007, 3.616%, 99.253%] time: 0:44:42.426744\n",
      "[Epoch 6/26-800/1009] [D loss&acc: 0.291, 10.181%] [G loss&accA&accB: 0.006, 3.662%, 99.397%] [Test loss&acc: 0.008, 5.355%, 99.223%] time: 0:46:00.774097\n",
      "[Epoch 6/26-1000/1009] [D loss&acc: 0.285, 7.544%] [G loss&accA&accB: 0.006, 5.078%, 99.367%] [Test loss&acc: 0.008, 1.089%, 99.244%] time: 0:47:19.000484\n",
      "[Epoch 7/26-0/1009] [D loss&acc: 0.287, 15.649%] [G loss&accA&accB: 0.006, 8.008%, 99.406%] [Test loss&acc: 0.007, 3.053%, 99.257%] time: 0:47:32.172477\n",
      "[Epoch 7/26-200/1009] [D loss&acc: 0.279, 11.279%] [G loss&accA&accB: 0.007, 8.643%, 99.320%] [Test loss&acc: 0.008, 3.776%, 99.238%] time: 0:48:50.341174\n",
      "[Epoch 7/26-400/1009] [D loss&acc: 0.277, 16.943%] [G loss&accA&accB: 0.008, 11.963%, 99.231%] [Test loss&acc: 0.007, 14.910%, 99.262%] time: 0:50:09.074403\n",
      "[Epoch 7/26-600/1009] [D loss&acc: 0.287, 8.716%] [G loss&accA&accB: 0.008, 4.688%, 99.178%] [Test loss&acc: 0.008, 24.306%, 99.240%] time: 0:51:27.332287\n",
      "[Epoch 7/26-800/1009] [D loss&acc: 0.278, 10.620%] [G loss&accA&accB: 0.008, 2.490%, 99.239%] [Test loss&acc: 0.007, 26.228%, 99.266%] time: 0:52:45.475194\n",
      "[Epoch 7/26-1000/1009] [D loss&acc: 0.291, 7.690%] [G loss&accA&accB: 0.007, 3.369%, 99.332%] [Test loss&acc: 0.007, 28.444%, 99.255%] time: 0:54:03.658761\n",
      "[Epoch 8/26-0/1009] [D loss&acc: 0.286, 9.985%] [G loss&accA&accB: 0.008, 14.209%, 99.233%] [Test loss&acc: 0.007, 23.585%, 99.268%] time: 0:54:16.787466\n",
      "[Epoch 8/26-200/1009] [D loss&acc: 0.284, 8.618%] [G loss&accA&accB: 0.008, 3.418%, 99.155%] [Test loss&acc: 0.008, 3.780%, 99.236%] time: 0:55:34.920954\n",
      "[Epoch 8/26-400/1009] [D loss&acc: 0.282, 7.520%] [G loss&accA&accB: 0.007, 7.520%, 99.298%] [Test loss&acc: 0.007, 26.405%, 99.275%] time: 0:56:53.042876\n",
      "[Epoch 8/26-600/1009] [D loss&acc: 0.302, 22.241%] [G loss&accA&accB: 0.007, 38.770%, 99.327%] [Test loss&acc: 0.007, 18.320%, 99.265%] time: 0:58:11.238825\n",
      "[Epoch 8/26-800/1009] [D loss&acc: 0.286, 8.276%] [G loss&accA&accB: 0.008, 8.643%, 99.250%] [Test loss&acc: 0.007, 19.153%, 99.261%] time: 0:59:29.293655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/26-1000/1009] [D loss&acc: 0.273, 15.186%] [G loss&accA&accB: 0.005, 7.812%, 99.461%] [Test loss&acc: 0.007, 16.392%, 99.269%] time: 1:00:47.467417\n",
      "[Epoch 9/26-0/1009] [D loss&acc: 0.349, 8.057%] [G loss&accA&accB: 0.005, 7.227%, 99.451%] [Test loss&acc: 0.007, 0.000%, 99.286%] time: 1:01:00.623644\n",
      "[Epoch 9/26-200/1009] [D loss&acc: 0.289, 9.302%] [G loss&accA&accB: 0.006, 5.664%, 99.441%] [Test loss&acc: 0.008, 19.784%, 99.241%] time: 1:02:18.691182\n",
      "[Epoch 9/26-400/1009] [D loss&acc: 0.271, 31.104%] [G loss&accA&accB: 0.006, 2.344%, 99.365%] [Test loss&acc: 0.007, 17.223%, 99.268%] time: 1:03:36.757830\n",
      "[Epoch 9/26-600/1009] [D loss&acc: 0.275, 16.797%] [G loss&accA&accB: 0.009, 6.152%, 99.102%] [Test loss&acc: 0.007, 26.203%, 99.278%] time: 1:04:54.764006\n",
      "[Epoch 9/26-800/1009] [D loss&acc: 0.272, 14.575%] [G loss&accA&accB: 0.006, 5.225%, 99.451%] [Test loss&acc: 0.007, 27.903%, 99.292%] time: 1:06:12.778400\n",
      "[Epoch 9/26-1000/1009] [D loss&acc: 0.274, 15.283%] [G loss&accA&accB: 0.008, 5.566%, 99.205%] [Test loss&acc: 0.007, 31.372%, 99.283%] time: 1:07:30.735088\n",
      "[Epoch 10/26-0/1009] [D loss&acc: 0.275, 19.946%] [G loss&accA&accB: 0.006, 3.760%, 99.398%] [Test loss&acc: 0.007, 30.658%, 99.273%] time: 1:07:43.860636\n",
      "[Epoch 10/26-200/1009] [D loss&acc: 0.269, 13.940%] [G loss&accA&accB: 0.005, 6.445%, 99.544%] [Test loss&acc: 0.007, 24.449%, 99.280%] time: 1:09:01.762336\n",
      "[Epoch 10/26-400/1009] [D loss&acc: 0.276, 9.277%] [G loss&accA&accB: 0.010, 9.766%, 99.018%] [Test loss&acc: 0.007, 18.916%, 99.291%] time: 1:10:19.799656\n",
      "[Epoch 10/26-600/1009] [D loss&acc: 0.267, 34.155%] [G loss&accA&accB: 0.005, 4.199%, 99.472%] [Test loss&acc: 0.007, 15.314%, 99.283%] time: 1:11:37.659491\n",
      "[Epoch 10/26-800/1009] [D loss&acc: 0.291, 20.044%] [G loss&accA&accB: 0.007, 31.445%, 99.302%] [Test loss&acc: 0.007, 24.138%, 99.297%] time: 1:12:55.570885\n",
      "[Epoch 10/26-1000/1009] [D loss&acc: 0.273, 14.282%] [G loss&accA&accB: 0.005, 11.865%, 99.514%] [Test loss&acc: 0.007, 28.856%, 99.300%] time: 1:14:13.309448\n",
      "[Epoch 11/26-0/1009] [D loss&acc: 0.276, 19.507%] [G loss&accA&accB: 0.004, 6.152%, 99.583%] [Test loss&acc: 0.007, 28.088%, 99.283%] time: 1:14:26.465741\n",
      "[Epoch 11/26-200/1009] [D loss&acc: 0.271, 28.638%] [G loss&accA&accB: 0.008, 24.072%, 99.249%] [Test loss&acc: 0.007, 31.781%, 99.291%] time: 1:15:44.352271\n",
      "[Epoch 11/26-400/1009] [D loss&acc: 0.273, 22.510%] [G loss&accA&accB: 0.005, 5.225%, 99.549%] [Test loss&acc: 0.007, 36.602%, 99.276%] time: 1:17:02.319275\n",
      "[Epoch 11/26-600/1009] [D loss&acc: 0.283, 17.212%] [G loss&accA&accB: 0.007, 2.832%, 99.273%] [Test loss&acc: 0.007, 26.615%, 99.295%] time: 1:18:20.804681\n",
      "[Epoch 11/26-800/1009] [D loss&acc: 0.286, 10.278%] [G loss&accA&accB: 0.009, 9.814%, 99.052%] [Test loss&acc: 0.007, 34.307%, 99.276%] time: 1:19:38.610031\n",
      "[Epoch 11/26-1000/1009] [D loss&acc: 0.289, 30.225%] [G loss&accA&accB: 0.009, 49.268%, 99.130%] [Test loss&acc: 0.007, 24.658%, 99.301%] time: 1:20:56.347685\n",
      "[Epoch 12/26-0/1009] [D loss&acc: 0.277, 16.821%] [G loss&accA&accB: 0.008, 8.057%, 99.194%] [Test loss&acc: 0.007, 24.599%, 99.299%] time: 1:21:09.411046\n",
      "[Epoch 12/26-200/1009] [D loss&acc: 0.305, 7.764%] [G loss&accA&accB: 0.005, 6.592%, 99.550%] [Test loss&acc: 0.007, 18.534%, 99.304%] time: 1:22:27.179088\n",
      "[Epoch 12/26-400/1009] [D loss&acc: 0.271, 22.949%] [G loss&accA&accB: 0.007, 13.330%, 99.346%] [Test loss&acc: 0.007, 14.779%, 99.298%] time: 1:23:45.018185\n",
      "[Epoch 12/26-600/1009] [D loss&acc: 0.265, 35.010%] [G loss&accA&accB: 0.005, 10.059%, 99.483%] [Test loss&acc: 0.007, 17.668%, 99.295%] time: 1:25:02.925323\n",
      "[Epoch 12/26-800/1009] [D loss&acc: 0.262, 41.333%] [G loss&accA&accB: 0.006, 5.371%, 99.388%] [Test loss&acc: 0.007, 14.899%, 99.303%] time: 1:26:20.832507\n",
      "[Epoch 12/26-1000/1009] [D loss&acc: 0.266, 31.372%] [G loss&accA&accB: 0.006, 45.605%, 99.423%] [Test loss&acc: 0.007, 16.763%, 99.305%] time: 1:27:38.529635\n",
      "[Epoch 13/26-0/1009] [D loss&acc: 0.289, 14.111%] [G loss&accA&accB: 0.008, 20.801%, 99.219%] [Test loss&acc: 0.007, 1.542%, 99.291%] time: 1:27:51.606958\n",
      "[Epoch 13/26-200/1009] [D loss&acc: 0.262, 31.128%] [G loss&accA&accB: 0.006, 14.893%, 99.436%] [Test loss&acc: 0.007, 13.222%, 99.292%] time: 1:29:09.425727\n",
      "[Epoch 13/26-400/1009] [D loss&acc: 0.265, 24.902%] [G loss&accA&accB: 0.005, 12.598%, 99.451%] [Test loss&acc: 0.007, 9.954%, 99.287%] time: 1:30:27.250611\n",
      "[Epoch 13/26-600/1009] [D loss&acc: 0.261, 28.223%] [G loss&accA&accB: 0.006, 22.266%, 99.367%] [Test loss&acc: 0.007, 12.131%, 99.310%] time: 1:31:44.986614\n",
      "[Epoch 13/26-800/1009] [D loss&acc: 0.262, 31.250%] [G loss&accA&accB: 0.005, 41.602%, 99.507%] [Test loss&acc: 0.007, 10.383%, 99.316%] time: 1:33:02.720484\n",
      "[Epoch 13/26-1000/1009] [D loss&acc: 0.263, 34.473%] [G loss&accA&accB: 0.004, 25.781%, 99.644%] [Test loss&acc: 0.007, 7.134%, 99.297%] time: 1:34:20.438063\n",
      "[Epoch 14/26-0/1009] [D loss&acc: 0.268, 36.279%] [G loss&accA&accB: 0.005, 8.447%, 99.516%] [Test loss&acc: 0.007, 6.970%, 99.290%] time: 1:34:33.613971\n",
      "[Epoch 14/26-200/1009] [D loss&acc: 0.271, 26.660%] [G loss&accA&accB: 0.007, 56.787%, 99.291%] [Test loss&acc: 0.007, 11.229%, 99.311%] time: 1:35:51.250206\n",
      "[Epoch 14/26-400/1009] [D loss&acc: 0.263, 21.045%] [G loss&accA&accB: 0.005, 51.318%, 99.494%] [Test loss&acc: 0.007, 8.485%, 99.299%] time: 1:37:08.978852\n",
      "[Epoch 14/26-600/1009] [D loss&acc: 0.261, 24.390%] [G loss&accA&accB: 0.005, 14.600%, 99.459%] [Test loss&acc: 0.007, 5.982%, 99.304%] time: 1:38:26.831537\n",
      "[Epoch 14/26-800/1009] [D loss&acc: 0.254, 47.681%] [G loss&accA&accB: 0.008, 19.531%, 99.188%] [Test loss&acc: 0.007, 6.481%, 99.310%] time: 1:39:44.632623\n",
      "[Epoch 14/26-1000/1009] [D loss&acc: 0.262, 29.126%] [G loss&accA&accB: 0.006, 21.387%, 99.405%] [Test loss&acc: 0.007, 7.556%, 99.304%] time: 1:41:02.285060\n",
      "[Epoch 15/26-0/1009] [D loss&acc: 0.256, 44.360%] [G loss&accA&accB: 0.004, 6.396%, 99.639%] [Test loss&acc: 0.007, 7.291%, 99.311%] time: 1:41:15.418905\n",
      "[Epoch 15/26-200/1009] [D loss&acc: 0.262, 42.822%] [G loss&accA&accB: 0.003, 8.936%, 99.732%] [Test loss&acc: 0.007, 1.804%, 99.306%] time: 1:42:33.053043\n",
      "[Epoch 15/26-400/1009] [D loss&acc: 0.264, 28.833%] [G loss&accA&accB: 0.004, 38.184%, 99.580%] [Test loss&acc: 0.007, 0.264%, 99.309%] time: 1:43:50.703917\n",
      "[Epoch 15/26-600/1009] [D loss&acc: 0.258, 44.385%] [G loss&accA&accB: 0.006, 12.256%, 99.379%] [Test loss&acc: 0.007, 0.055%, 99.298%] time: 1:45:08.391307\n",
      "[Epoch 15/26-800/1009] [D loss&acc: 0.255, 45.483%] [G loss&accA&accB: 0.008, 36.328%, 99.228%] [Test loss&acc: 0.007, 0.006%, 99.298%] time: 1:46:26.009135\n",
      "[Epoch 15/26-1000/1009] [D loss&acc: 0.263, 41.553%] [G loss&accA&accB: 0.009, 80.908%, 99.115%] [Test loss&acc: 0.007, 0.001%, 99.305%] time: 1:47:43.505913\n",
      "[Epoch 16/26-0/1009] [D loss&acc: 0.269, 27.783%] [G loss&accA&accB: 0.005, 18.164%, 99.470%] [Test loss&acc: 0.007, 0.008%, 99.311%] time: 1:47:56.622934\n",
      "[Epoch 16/26-200/1009] [D loss&acc: 0.258, 49.023%] [G loss&accA&accB: 0.004, 7.959%, 99.607%] [Test loss&acc: 0.007, 0.000%, 99.300%] time: 1:49:14.249400\n",
      "[Epoch 16/26-400/1009] [D loss&acc: 0.263, 43.213%] [G loss&accA&accB: 0.004, 3.418%, 99.602%] [Test loss&acc: 0.007, 0.000%, 99.291%] time: 1:50:31.900114\n",
      "[Epoch 16/26-600/1009] [D loss&acc: 0.254, 44.458%] [G loss&accA&accB: 0.005, 15.479%, 99.528%] [Test loss&acc: 0.007, 0.000%, 99.300%] time: 1:51:49.442217\n",
      "[Epoch 16/26-800/1009] [D loss&acc: 0.257, 42.139%] [G loss&accA&accB: 0.005, 10.938%, 99.542%] [Test loss&acc: 0.007, 0.000%, 99.300%] time: 1:53:06.997040\n",
      "[Epoch 16/26-1000/1009] [D loss&acc: 0.257, 33.496%] [G loss&accA&accB: 0.008, 39.746%, 99.228%] [Test loss&acc: 0.007, 0.000%, 99.303%] time: 1:54:25.463867\n",
      "[Epoch 17/26-0/1009] [D loss&acc: 0.255, 39.722%] [G loss&accA&accB: 0.005, 29.443%, 99.547%] [Test loss&acc: 0.007, 0.000%, 99.304%] time: 1:54:38.587549\n",
      "[Epoch 17/26-200/1009] [D loss&acc: 0.257, 42.529%] [G loss&accA&accB: 0.005, 38.818%, 99.472%] [Test loss&acc: 0.007, 0.000%, 99.312%] time: 1:55:56.151582\n",
      "[Epoch 17/26-400/1009] [D loss&acc: 0.258, 41.284%] [G loss&accA&accB: 0.004, 38.818%, 99.625%] [Test loss&acc: 0.007, 0.000%, 99.311%] time: 1:57:13.685076\n",
      "[Epoch 17/26-600/1009] [D loss&acc: 0.257, 31.177%] [G loss&accA&accB: 0.004, 9.424%, 99.581%] [Test loss&acc: 0.007, 0.000%, 99.309%] time: 1:58:31.251729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/26-800/1009] [D loss&acc: 0.255, 43.848%] [G loss&accA&accB: 0.007, 34.717%, 99.289%] [Test loss&acc: 0.007, 0.000%, 99.319%] time: 1:59:48.816172\n",
      "[Epoch 17/26-1000/1009] [D loss&acc: 0.258, 43.140%] [G loss&accA&accB: 0.008, 69.287%, 99.173%] [Test loss&acc: 0.007, 0.000%, 99.291%] time: 2:01:06.413863\n",
      "[Epoch 18/26-0/1009] [D loss&acc: 0.264, 32.446%] [G loss&accA&accB: 0.006, 73.193%, 99.386%] [Test loss&acc: 0.007, 0.000%, 99.294%] time: 2:01:19.538225\n",
      "[Epoch 18/26-200/1009] [D loss&acc: 0.255, 48.364%] [G loss&accA&accB: 0.005, 27.295%, 99.499%] [Test loss&acc: 0.007, 0.000%, 99.301%] time: 2:02:37.079671\n",
      "[Epoch 18/26-400/1009] [D loss&acc: 0.257, 42.285%] [G loss&accA&accB: 0.004, 12.305%, 99.554%] [Test loss&acc: 0.007, 0.000%, 99.314%] time: 2:03:54.595000\n",
      "[Epoch 18/26-600/1009] [D loss&acc: 0.257, 45.483%] [G loss&accA&accB: 0.043, 25.928%, 95.725%] [Test loss&acc: 0.025, 0.036%, 97.514%] time: 2:05:12.115232\n",
      "[Epoch 18/26-800/1009] [D loss&acc: 0.257, 46.313%] [G loss&accA&accB: 0.007, 26.221%, 99.268%] [Test loss&acc: 0.008, 0.000%, 99.243%] time: 2:06:29.448221\n",
      "[Epoch 18/26-1000/1009] [D loss&acc: 0.259, 40.576%] [G loss&accA&accB: 0.008, 13.428%, 99.191%] [Test loss&acc: 0.010, 0.000%, 99.046%] time: 2:07:46.738913\n",
      "[Epoch 19/26-0/1009] [D loss&acc: 0.255, 46.387%] [G loss&accA&accB: 0.004, 27.344%, 99.595%] [Test loss&acc: 0.009, 0.000%, 99.098%] time: 2:07:59.881170\n",
      "[Epoch 19/26-200/1009] [D loss&acc: 0.252, 46.924%] [G loss&accA&accB: 0.004, 4.297%, 99.555%] [Test loss&acc: 0.008, 0.000%, 99.249%] time: 2:09:17.097266\n",
      "[Epoch 19/26-400/1009] [D loss&acc: 0.258, 36.987%] [G loss&accA&accB: 0.004, 65.430%, 99.598%] [Test loss&acc: 0.007, 0.000%, 99.285%] time: 2:10:34.361391\n",
      "[Epoch 19/26-600/1009] [D loss&acc: 0.255, 42.407%] [G loss&accA&accB: 0.006, 35.791%, 99.442%] [Test loss&acc: 0.007, 0.000%, 99.303%] time: 2:11:51.634789\n",
      "[Epoch 19/26-800/1009] [D loss&acc: 0.260, 42.554%] [G loss&accA&accB: 0.006, 7.227%, 99.401%] [Test loss&acc: 0.007, 0.000%, 99.307%] time: 2:13:08.887608\n",
      "[Epoch 19/26-1000/1009] [D loss&acc: 0.266, 30.981%] [G loss&accA&accB: 0.005, 71.387%, 99.456%] [Test loss&acc: 0.007, 0.000%, 99.311%] time: 2:14:26.138088\n",
      "[Epoch 20/26-0/1009] [D loss&acc: 0.250, 53.882%] [G loss&accA&accB: 0.005, 34.619%, 99.523%] [Test loss&acc: 0.007, 0.000%, 99.310%] time: 2:14:39.254720\n",
      "[Epoch 20/26-200/1009] [D loss&acc: 0.257, 40.649%] [G loss&accA&accB: 0.005, 48.779%, 99.512%] [Test loss&acc: 0.007, 0.000%, 99.310%] time: 2:15:56.543950\n",
      "[Epoch 20/26-400/1009] [D loss&acc: 0.255, 41.846%] [G loss&accA&accB: 0.005, 64.307%, 99.453%] [Test loss&acc: 0.007, 0.000%, 99.314%] time: 2:17:13.828951\n",
      "[Epoch 20/26-600/1009] [D loss&acc: 0.256, 41.357%] [G loss&accA&accB: 0.003, 18.555%, 99.704%] [Test loss&acc: 0.007, 0.006%, 99.312%] time: 2:18:31.098355\n",
      "[Epoch 20/26-800/1009] [D loss&acc: 0.257, 42.334%] [G loss&accA&accB: 0.006, 26.904%, 99.375%] [Test loss&acc: 0.007, 0.002%, 99.317%] time: 2:19:48.400937\n",
      "[Epoch 20/26-1000/1009] [D loss&acc: 0.261, 23.169%] [G loss&accA&accB: 0.007, 67.871%, 99.315%] [Test loss&acc: 0.007, 0.016%, 99.316%] time: 2:21:05.713200\n",
      "[Epoch 21/26-0/1009] [D loss&acc: 0.256, 38.599%] [G loss&accA&accB: 0.005, 11.377%, 99.515%] [Test loss&acc: 0.007, 0.036%, 99.320%] time: 2:21:18.840341\n",
      "[Epoch 21/26-200/1009] [D loss&acc: 0.249, 58.472%] [G loss&accA&accB: 0.004, 11.035%, 99.552%] [Test loss&acc: 0.007, 0.031%, 99.254%] time: 2:22:36.189755\n",
      "[Epoch 21/26-400/1009] [D loss&acc: 0.254, 46.069%] [G loss&accA&accB: 0.004, 6.348%, 99.640%] [Test loss&acc: 0.007, 0.067%, 99.317%] time: 2:23:53.598365\n",
      "[Epoch 21/26-600/1009] [D loss&acc: 0.260, 34.351%] [G loss&accA&accB: 0.006, 17.529%, 99.411%] [Test loss&acc: 0.007, 0.097%, 99.313%] time: 2:25:10.934033\n",
      "[Epoch 21/26-800/1009] [D loss&acc: 0.253, 42.749%] [G loss&accA&accB: 0.005, 13.525%, 99.543%] [Test loss&acc: 0.007, 0.030%, 99.316%] time: 2:26:28.267285\n",
      "[Epoch 21/26-1000/1009] [D loss&acc: 0.254, 36.572%] [G loss&accA&accB: 0.006, 19.971%, 99.431%] [Test loss&acc: 0.007, 0.011%, 99.315%] time: 2:27:45.575614\n",
      "[Epoch 22/26-0/1009] [D loss&acc: 0.257, 39.062%] [G loss&accA&accB: 0.014, 72.900%, 98.575%] [Test loss&acc: 0.007, 0.022%, 99.315%] time: 2:27:58.654901\n",
      "[Epoch 22/26-200/1009] [D loss&acc: 0.254, 45.605%] [G loss&accA&accB: 0.003, 22.559%, 99.660%] [Test loss&acc: 0.007, 0.000%, 99.319%] time: 2:29:15.881091\n",
      "[Epoch 22/26-400/1009] [D loss&acc: 0.253, 49.438%] [G loss&accA&accB: 0.005, 16.943%, 99.516%] [Test loss&acc: 0.007, 0.045%, 99.316%] time: 2:30:33.039866\n",
      "[Epoch 22/26-600/1009] [D loss&acc: 0.251, 52.979%] [G loss&accA&accB: 0.003, 45.361%, 99.716%] [Test loss&acc: 0.007, 0.051%, 99.318%] time: 2:31:50.235218\n",
      "[Epoch 22/26-800/1009] [D loss&acc: 0.253, 47.095%] [G loss&accA&accB: 0.005, 32.129%, 99.523%] [Test loss&acc: 0.007, 0.026%, 99.320%] time: 2:33:07.512370\n",
      "[Epoch 22/26-1000/1009] [D loss&acc: 0.253, 45.581%] [G loss&accA&accB: 0.008, 41.113%, 99.244%] [Test loss&acc: 0.007, 0.029%, 99.318%] time: 2:34:24.730347\n",
      "[Epoch 23/26-0/1009] [D loss&acc: 0.258, 31.470%] [G loss&accA&accB: 0.007, 60.791%, 99.340%] [Test loss&acc: 0.007, 0.038%, 99.317%] time: 2:34:37.804940\n",
      "[Epoch 23/26-200/1009] [D loss&acc: 0.257, 36.304%] [G loss&accA&accB: 0.008, 33.691%, 99.207%] [Test loss&acc: 0.007, 0.054%, 99.315%] time: 2:35:55.061041\n",
      "[Epoch 23/26-400/1009] [D loss&acc: 0.250, 59.668%] [G loss&accA&accB: 0.003, 4.395%, 99.724%] [Test loss&acc: 0.007, 0.058%, 99.301%] time: 2:37:13.334096\n",
      "[Epoch 23/26-600/1009] [D loss&acc: 0.256, 38.965%] [G loss&accA&accB: 0.004, 51.025%, 99.613%] [Test loss&acc: 0.007, 0.040%, 99.311%] time: 2:38:30.594325\n",
      "[Epoch 23/26-800/1009] [D loss&acc: 0.251, 51.074%] [G loss&accA&accB: 0.006, 32.520%, 99.424%] [Test loss&acc: 0.007, 0.024%, 99.300%] time: 2:39:47.828841\n",
      "[Epoch 23/26-1000/1009] [D loss&acc: 0.255, 47.070%] [G loss&accA&accB: 0.006, 5.322%, 99.405%] [Test loss&acc: 0.007, 0.085%, 99.298%] time: 2:41:05.013216\n",
      "[Epoch 24/26-0/1009] [D loss&acc: 0.256, 38.965%] [G loss&accA&accB: 0.006, 69.678%, 99.417%] [Test loss&acc: 0.007, 0.088%, 99.314%] time: 2:41:18.137003\n",
      "[Epoch 24/26-200/1009] [D loss&acc: 0.249, 51.953%] [G loss&accA&accB: 0.005, 64.600%, 99.476%] [Test loss&acc: 0.007, 0.074%, 99.294%] time: 2:42:35.368392\n",
      "[Epoch 24/26-400/1009] [D loss&acc: 0.256, 41.040%] [G loss&accA&accB: 0.003, 9.424%, 99.738%] [Test loss&acc: 0.007, 0.124%, 99.262%] time: 2:43:52.606188\n",
      "[Epoch 24/26-600/1009] [D loss&acc: 0.255, 45.239%] [G loss&accA&accB: 0.005, 14.111%, 99.483%] [Test loss&acc: 0.007, 0.101%, 99.295%] time: 2:45:09.892795\n",
      "[Epoch 24/26-800/1009] [D loss&acc: 0.272, 16.211%] [G loss&accA&accB: 0.004, 84.033%, 99.558%] [Test loss&acc: 0.007, 0.318%, 99.315%] time: 2:46:27.114134\n",
      "[Epoch 24/26-1000/1009] [D loss&acc: 0.255, 45.850%] [G loss&accA&accB: 0.005, 12.598%, 99.477%] [Test loss&acc: 0.007, 0.173%, 99.318%] time: 2:47:44.300570\n",
      "[Epoch 25/26-0/1009] [D loss&acc: 0.253, 44.897%] [G loss&accA&accB: 0.004, 21.777%, 99.631%] [Test loss&acc: 0.007, 0.155%, 99.311%] time: 2:47:57.325122\n",
      "[Epoch 25/26-200/1009] [D loss&acc: 0.253, 42.896%] [G loss&accA&accB: 0.002, 15.723%, 99.782%] [Test loss&acc: 0.007, 0.071%, 99.303%] time: 2:49:14.503027\n",
      "[Epoch 25/26-400/1009] [D loss&acc: 0.253, 43.872%] [G loss&accA&accB: 0.006, 12.158%, 99.441%] [Test loss&acc: 0.007, 0.200%, 99.315%] time: 2:50:31.658577\n",
      "[Epoch 25/26-600/1009] [D loss&acc: 0.256, 28.540%] [G loss&accA&accB: 0.004, 46.387%, 99.587%] [Test loss&acc: 0.007, 0.259%, 99.310%] time: 2:51:48.856954\n",
      "[Epoch 25/26-800/1009] [D loss&acc: 0.253, 42.188%] [G loss&accA&accB: 0.004, 50.830%, 99.568%] [Test loss&acc: 0.007, 0.206%, 99.313%] time: 2:53:05.958536\n",
      "[Epoch 25/26-1000/1009] [D loss&acc: 0.253, 32.886%] [G loss&accA&accB: 0.003, 31.152%, 99.653%] [Test loss&acc: 0.007, 0.257%, 99.309%] time: 2:54:22.971526\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = EL_GAN() # 24 Epochs\n",
    "    gan.train(x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath, epochs=26, batch_size=32, sample_interval=200)\n",
    "    #gan.train_generator_only(x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    def IoUcheck(img_input, img_output):\n",
    "\n",
    "        logic_and = np.sum(np.logical_and(img_output, img_input))\n",
    "        logic_or = np.sum(np.logical_or(img_output, img_input))\n",
    "\n",
    "        return logic_and/logic_or\n",
    "    \n",
    "    def rescaleImg(image_arr):\n",
    "    \n",
    "        if image_arr.shape[0] % 8 != 0:\n",
    "            n = image_arr.shape[0] % 8\n",
    "            new_x = image_arr.shape[0] - n\n",
    "        else:\n",
    "            new_x = image_arr.shape[0]\n",
    "\n",
    "        if image_arr.shape[1] % 8 != 0:\n",
    "            n = image_arr.shape[1] % 8\n",
    "            new_y = image_arr.shape[1] - n\n",
    "        else:\n",
    "            new_y = image_arr.shape[1]\n",
    "\n",
    "        image_arr = image_arr[:new_x, :new_y]\n",
    "\n",
    "        return image_arr\n",
    "    \n",
    "    def update_model_to_any_size(old_model):\n",
    "    \n",
    "        old_model.layers.pop(0)\n",
    "        \n",
    "        newInput = Input(shape=(None, None, 1)) # New image input\n",
    "        newOutputs = old_model(newInput)\n",
    "        newModel = Model(newInput, newOutputs)\n",
    "        #newModel.summary()\n",
    "\n",
    "        return newModel\n",
    "    \n",
    "    def evaluate(image_arrA, image_arrB):\n",
    "        \n",
    "        Accuracy = accuracy_score(image_arrB.flatten().astype(bool), \n",
    "                                  image_arrA.flatten().astype(bool))\n",
    "\n",
    "        IntOverUnion = IoUcheck(image_arrB.flatten().astype(bool), \n",
    "                                image_arrA.flatten().astype(bool))\n",
    "\n",
    "        print('accuracy:', Accuracy)\n",
    "        print('IoU:', IntOverUnion)\n",
    "        return Accuracy, IntOverUnion\n",
    "        \n",
    "    def model_predict(newModel, input_image, num_runs):\n",
    "        m,n = input_image.shape\n",
    "        \n",
    "        for i in range(num_runs):\n",
    "            input_image = np.reshape(input_image, (1, m, n, 1))\n",
    "            conc2 = newModel.predict([input_image])\n",
    "            input_image = np.reshape(conc2,(m, n))\n",
    "\n",
    "        return input_image\n",
    "    \n",
    "    def save_prediction(output_image, fn_input, subfix):\n",
    "        fig = plt.figure(figsize=(output_image.shape[1] / 1000, output_image.shape[0] / 1000), dpi=100, frameon=False)\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "\n",
    "        plt.imshow(output_image, cmap='gray')\n",
    "        #plt.imshow(output_image)\n",
    "        fig.savefig(outPath + fn_input[:-4] + subfix, dpi=1000)\n",
    "\n",
    "    def predict_15k_examples(testPath, fn_input, fn_target, nr = 1):\n",
    "    \n",
    "        image_arrA = readImg(testPath + fn_input)\n",
    "        image_arrB = readImg(testPath + fn_target)\n",
    "\n",
    "        print(\"15k\", 'Example: ')\n",
    "        acc_orig, iou_orig = evaluate(image_arrA, image_arrB)\n",
    "\n",
    "        image_arr = readImg(testPath + fn_input)\n",
    "        image_arr = rescaleImg(image_arr)\n",
    "\n",
    "        image_tar = readImg(testPath + fn_target)\n",
    "        image_tar = rescaleImg(image_tar)\n",
    "\n",
    "        newModel = update_model_to_any_size(gan.generator)\n",
    "        output_image = model_predict(newModel, image_arr, num_runs = nr)\n",
    "\n",
    "        print(\"- 15k\", 'Prediction: ')\n",
    "        acc_pred, iou_pred = evaluate(output_image > 0.5, image_tar)\n",
    "\n",
    "        save_prediction(output_image, fn_input, '_' + str(nr) + '_out.png')\n",
    "\n",
    "        return [[acc_orig, iou_orig], [acc_pred, iou_pred]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15k Example: \n",
      "accuracy: 0.9764130991339968\n",
      "IoU: 0.885579034522481\n",
      "- 15k Prediction: \n",
      "accuracy: 0.9901607789855073\n",
      "IoU: 0.9516218824228029\n",
      "15k Example: \n",
      "accuracy: 0.982896331738437\n",
      "IoU: 0.9261015173858516\n",
      "- 15k Prediction: \n",
      "accuracy: 0.9937415994623656\n",
      "IoU: 0.9725750046015093\n",
      "15k Example: \n",
      "accuracy: 0.9764130991339968\n",
      "IoU: 0.885579034522481\n",
      "- 15k Prediction: \n",
      "accuracy: 0.9907797403381643\n",
      "IoU: 0.9545446088008187\n",
      "15k Example: \n",
      "accuracy: 0.982896331738437\n",
      "IoU: 0.9261015173858516\n",
      "- 15k Prediction: \n",
      "accuracy: 0.9933377274607114\n",
      "IoU: 0.9708221310315551\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHcAAABhCAYAAADstj4MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAAz9JREFUeJztnNuO6yAMRUN0/v9n+9wyL+UIIe7Yqdns9TLSNJNEWdgx4I7z3l8Ek/vXN0D0oFxgKBcYygWGcoGhXGAoFxjKBYZygaFcYCgXGMoFhnKBoVxg/v36BmZxzjX3KuPtTOec6v1I471fvmHoyA1CrYl9ag9928jtZUWsROSXzuG9Vx908HKfoiQxFRgfFwRriYZOy5J470XSqXMu+7qQOn8MI/dL+mBHI2n2eM2i7wi5T1TNuajruVZOshRHyJ1ldSDE79Igr3ROjUHndm1t7ZnnWmEm5XOeuwlxERWjHVhHp+XSw9V6L5cEa10PWu5qBbz69y3CHFcLaLnpw0ujJFfs9Dzs2cq4dI+tc88CK9d7f933vRRtsXxr69M9bFtQhRWd2kj/fD7Vc7xer67UOyJ2daWpVHxNnWvnqVBtUT73+5TZd2otLfc+z9a1JKZCW6fl1gN6suqNP7MSMNum5RKlB5tLl5rFTI6QcsMAyF2PBVWFJ5f3Ru6hNui0gJArsTGgLT89fy59c1coISe2tUgf07nO232sJbaXm1LqdLiushypRYnRSNQeLHAF1cjUR4L3+63SRSHB9pE7suigUWzdt9342F5ui96Iqi0xSqXXp/uo4eROboz//9l6L+eqXqvAyU3pjRbLkmaBk1taY+79GyTsVgMClHqEc1iteFeAi9wcEpE5uu1ngSPk9oCYmin3y+gSo/a6sASU+0VyH9aKaOiCahQrUqQ4Rq50kVP7mqYVjpF7XXpVrJXqOOWId+7Kfqx2s50mR0Ruqe1FM+IsLIpAR268EVDbEJBszfm10JjtI7fVeFbrMJRsALfI1k3ppc962mbSiLXWJ3V8U/oIqbyZ3aPa8VYGRcz2aTlltPF85/8y1wJObm5xoWfrr/YtgNo1Ahaq4xTItDzSC4UWrTGQcnvomQKtNM1ZAC4t9xBPk9J3bvqtBWupdoQj5ca0InOHCC2x7TyXtDk+cpGhXGAoFxjKBYZygaFcYCgXGMoFhnKBoVxgKBcYygWGcoGhXGAoFxjKBYZygaFcYCgXGMoFhnKBoVxgKBcYygWGcoGhXGAoFxjKBYZygaFcYCgXGMoFhnKB+QOEGZQQuLGbBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19f2a0f390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIUAAABaCAYAAACWspXGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAA3lJREFUeJztnEty6yAUBUUqy8ks+19GlpPwRryiOID4SgJ1j2zZAixacPnIxlp7APh83F0AeB5IAQJSgIAUICAFCEgBAlKAgBQgIAUISAECUoCAFCAgBQhIAcLn3QVoxRgja/7+NgBjTPK9MWZ6+fy8Rubbkpa1tirjZaUIqdkXkpMnPNZSkavvUdlGCld51tqhLUGNQH45/NdXtEwj2UYKR6xSUu+vKEOKmFy541eynRQtxC58eKykSwgrNvV+FqPyQYpCcl1BSyWkzol1UTli3+2VAykeyN0xiFk4Urb+xcv9jrsv8t28dkhaQkqct0sTsqwUJSOL2lbwTJrRw92nsqwUJcwYkqZGFu7YlbOms9hailpKY5Szc2Pnpz4vlScnYyqPVpAiQevcRa7SVgEpOsjdma137ajupycdpLgJF3+UBq9XTtkjxUBSC2M11M5o5tJpBSkm0iOJ34L8/v4eHx/x/VAzWgykWICUED5nS/w1LC1Fqj++a65gVH53Lfn/z2/VoZMxxpbuSfA/eyO1ax+v2bi7qvx3sHT34ZPbcZUS4i1rGbUsLUVPhTpRdlirGM3SUoTUxBKxCH3EPMMObCVFjNbNN2/uWraX4jjG3vVPkGX2QtxWUtQEmLHvl26m6e1mnh7HbCVFyNlurDM5ZhOT7wl7TV8zT+FIXVi3Yllzfs+il59vL6NlWbqlaG2Gr262z8r5hDjFZ4uWovQuzxEGai7NVFBXu40ufB3rNkp/w2yBtpAipFWQs4vdku6sZ1udmDMEWXpBzL2O/ReEe99DT7ozu4TaBb9XLoj5d0zpUHJkuql8zobEs2ntVpcONFOUiDHyoeBY+mef9bQkxBSDuOKuzT3rkXs6fBatMcfyLUXLnZ+bMOoN/nITYikxSnaPpeKIGbOjS7cUuVXOkNhdE9v7OGJom1uZjTGjxehJc2kpYhUQBlff399yjuPv70+GdqNnG2NlLjnWw1mge8YWQ9LjKPsPqZZt9rE0R2CtPb6+vo6fn59haYbpe1QVfBspjiMeX/RW7Ig++65pbJdv7TzFslLAPJaOKWAOSAECUoCAFCAgBQhIAQJSgIAUICAFCEgBAlKAgBQgIAUISAECUoCAFCAgBQhIAQJSgIAUICAFCEgBAlKAgBQgIAUISAECUoCAFCAgBQhIAQJSgIAUICAFCP8AnW3e4mNwVwIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19ed5fecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHcAAABhCAYAAADstj4MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAAxlJREFUeJztnMuSpSAQBWFi/v+Xmc11giBAHlIKyclNL9pWwqSggLJ9CMEJJn++boCwQ3LBSC4YyQUjuWAkF4zkgpFcMJILRnLBSC4YyQUjuWAkF8zfrxswive+elYZH2d6703bM5sQwuMGoyP3Erqa2LfO0LeN3FaeiJ0R+aV7hBDMOx1e7luUJKYC4+suwVai0cPyTEIIU4ZT7312uph1/xhF7o/0xfZG0uj1lknfEXLfyJpzUdfyrJzkWRwhd5SnHSGeSy95pXtadDq/a2lryzp3FUaGfK1zNyFOomKsA+voYbn0cq3m5ZJgq+eh5T7NgJ/+fY1rjWsFWm768tIoySU7LS97NDMutbF271GwcmORT1/8G1uFFmwrt2XtWpPSGoE9YmtLnhoz173byo2H0FTiCsu7WhveGAm2letc/QW9mfXGv1uhczkHXOeWXmxuY94ymclxrXevDpB7nhKqG97c3utpw12nswIhd8bBgLX89P654VunQgk5sT0Za+M+b/O1K7G93JRSpYNz90umlBnlOV8lfBc4uXfZqsVmxCqZcY7t5fZsOqyQbL3J9nJrtEbWXVTPGl7frqPGyR08GP//szYv57LeVcHJTWmNlpUljYKTO7LHTBTrHHD7MaZUI5zDom74a3CRm2NGZI4c+33NEXJbIA7Nkvujd4vRel94BpL7o/cc9u76VUSjE6peVpEyi2PkWiY5q3aKY+Q6Zyd4lew45Yg598l5bOsO14oJ1hGRWyp7sYy4FTZF0JE7ozD9ji8+7uoBG7nxSU/pd3SQ3+e2lM2UCtlXmCudm/N9LnpYjknlPflCYXbNlRW4Ybm38Hzn/zJXAyc394lmy9Hf3VcAd8+4WCE7TkEOyz21ULRojUHKbaGlzPVJ0dwK4IblFuJlUjrnpl8trDbU9nCk3JhaZO4QoSW2XeeKOsdHLhnJBSO5YCQXjOSCkVwwkgtGcsFILhjJBSO5YCQXjOSCkVwwkgtGcsFILhjJBSO5YCQXjOSCkVwwkgtGcsFILhjJBSO5YCQXjOSCkVwwkgtGcsFILph/GdV7SuQW1AcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19ed3af2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIUAAABaCAYAAACWspXGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAA1JJREFUeJztnNlyhSAQBSWV//9l8mTK4rAzqGD3010iGG1gBvA67/0BcOXn6ROA94EUICAFCEgBAlKAgBQgIAUISAECUoCAFCAgBQhIAQJSgIAUIPw+fQK9OOdkzf+6DcA5l3zvnJt+fte6LOvtKct731TxslKEtOwLyckTftZzI1ffo7KNFOfN896b9gQtAl3P4/r6jp7Jkm2kOIndlNT7O84hRUyu3Od3sp0UPcQufPhZzZAQ3tjU+1lY1YMUleSGgp6bkDomNkTliP3tqBxI8UKejkHcwpGyv1683P/x9EV+ms+mpDWkxPm6NCHLSlGTWbT2giVprNPdt7KsFDXMSElTmcX52Z2zprPYWopWamOU0rGx41Pf18qTkzFVRy9IkaB37iJ301YBKQbItczeVms1/IyUgxQPccYftcHrnVP2SGFIamGshdYZzVw5vSDFRCwkCcsJmdFjIMVLaZ0TKS3xt7C0FKkL99RcgVV9Ty35/9e3aurknPO1exKu332R1rWPz2zcXVX+J1h6+LiS23GVEuIraxmtLC2FRUS/w1qFNUtLEdISS8QidKsUcnW2kiJGb47/5aFleymOw7bVW8kyUs7shbitpGgJMGN/X7uZZnSYeXsmtJUUIaXdWCU5ZhOT7w17TT8zT3GSurDnimXL8SOLXtd6R7GWZemeojedvDuALJ3n24LaLXqK2laeIwzUzjJTQV3rNrrwdWzYqP0fZgu0hRQhvYKULnZPubOebT3FnCHI0gti5+vYb0Gc70cYKXfmkNC64PfJBbFri6lNJS3LTdVTSoln0zusLh1opqgRw/Kh4Fj5pe9GehJiCiPuaLW5Zz1yT4fPojfmWL6n6Gn5uQmj0eAvNyGWEqNm91gqjpixyrt0T5Fb5QypbTUWqW1uZXZGndZlLi1F7AaUgqtYC04FlDNuVs2TZ6OUAt0SW6Skx1H3G1KtF3/m70/NnsUMzv17Kelx1K1JjDw0bP3cxuwMoieV/j921Z4C5rFNTwF2IAUISAECUoCAFCAgBQhIAQJSgIAUICAFCEgBAlKAgBQgIAUISAECUoCAFCAgBQhIAQJSgIAUICAFCEgBAlKAgBQgIAUISAECUoCAFCAgBQhIAQJSgIAUIPwBCz/LU1wWaKgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19f4428080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testPath = r\"../tmp_data/Data/Testing/\"\n",
    "all_records = []\n",
    "    \n",
    "records = predict_15k_examples(testPath, r\"FTest1_input_inv.png\", r\"FTest1_output_inv.png\", nr = 1)\n",
    "all_records.extend(records)\n",
    "    \n",
    "records = predict_15k_examples(testPath, r\"FTest2_input_inv.png\", r\"FTest2_output_inv.png\", nr = 1)\n",
    "all_records.extend(records)\n",
    "\n",
    "records = predict_15k_examples(testPath, r\"FTest1_input_inv.png\", r\"FTest1_output_inv.png\", nr = 10)\n",
    "all_records.extend(records)\n",
    "    \n",
    "records = predict_15k_examples(testPath, r\"FTest2_input_inv.png\", r\"FTest2_output_inv.png\", nr = 10)\n",
    "all_records.extend(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input vs Target (Test1)</th>\n",
       "      <th>Input vs Target (Test1)</th>\n",
       "      <th>Prediction vs Target (Test1 - 1)</th>\n",
       "      <th>Prediction vs Target (Test1 - 10)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.976413</td>\n",
       "      <td>0.976413</td>\n",
       "      <td>0.990161</td>\n",
       "      <td>0.990780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IoU</th>\n",
       "      <td>0.885579</td>\n",
       "      <td>0.885579</td>\n",
       "      <td>0.951622</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Input vs Target (Test1)  Input vs Target (Test1)  \\\n",
       "Metrics                                                      \n",
       "Accuracy                 0.976413                 0.976413   \n",
       "IoU                      0.885579                 0.885579   \n",
       "\n",
       "          Prediction vs Target (Test1 - 1)  Prediction vs Target (Test1 - 10)  \n",
       "Metrics                                                                        \n",
       "Accuracy                          0.990161                           0.990780  \n",
       "IoU                               0.951622                           0.954545  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(np.transpose(all_records))\n",
    "df.columns = [\"Input vs Target (Test1)\", \"Prediction vs Target (Test1 - 1)\", \n",
    "              \"Input vs Target (Test2)\", \"Prediction vs Target (Test2 - 1)\",\n",
    "              \"Input vs Target (Test1)\", \"Prediction vs Target (Test1 - 10)\", \n",
    "              \"Input vs Target (Test2)\", \"Prediction vs Target (Test2 - 10)\"]\n",
    "\n",
    "df = df.rename({0: \"Accuracy\", 1: 'IoU'})\n",
    "df.index.name = 'Metrics'\n",
    "\n",
    "df[[\"Input vs Target (Test1)\", \"Prediction vs Target (Test1 - 1)\", \"Prediction vs Target (Test1 - 10)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input vs Target (Test2)</th>\n",
       "      <th>Input vs Target (Test2)</th>\n",
       "      <th>Prediction vs Target (Test2 - 1)</th>\n",
       "      <th>Prediction vs Target (Test2 - 10)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.982896</td>\n",
       "      <td>0.982896</td>\n",
       "      <td>0.993742</td>\n",
       "      <td>0.993338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IoU</th>\n",
       "      <td>0.926102</td>\n",
       "      <td>0.926102</td>\n",
       "      <td>0.972575</td>\n",
       "      <td>0.970822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Input vs Target (Test2)  Input vs Target (Test2)  \\\n",
       "Metrics                                                      \n",
       "Accuracy                 0.982896                 0.982896   \n",
       "IoU                      0.926102                 0.926102   \n",
       "\n",
       "          Prediction vs Target (Test2 - 1)  Prediction vs Target (Test2 - 10)  \n",
       "Metrics                                                                        \n",
       "Accuracy                          0.993742                           0.993338  \n",
       "IoU                               0.972575                           0.970822  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Input vs Target (Test2)\", \"Prediction vs Target (Test2 - 1)\", \"Prediction vs Target (Test2 - 10)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "activation_1 (Activation)       (None, 128, 128, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 32) 9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 32) 0           batch_normalization_2[0][0]      \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   18496       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 128)  73856       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 128)  8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           batch_normalization_8[0][0]      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 256)  295168      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 256)  33024       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 256)  590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 256)  0           batch_normalization_11[0][0]     \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 256)  590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 256)  65792       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 256)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 256)  1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 256)  590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           batch_normalization_14[0][0]     \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 384)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 384)  1536        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 384)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 128)  442496      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 128)  49280       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 128)  0           batch_normalization_17[0][0]     \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 192)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 192)  768         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 192)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 64)   110656      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 64)   12352       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 64)   0           batch_normalization_20[0][0]     \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 96) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128, 128, 96) 384         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 96) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 32) 27680       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 32) 128         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 32) 3104        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 32) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128, 128, 32) 128         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 32) 9248        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 128, 128, 32) 0           batch_normalization_23[0][0]     \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 1)  33          add_8[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,312,289\n",
      "Trainable params: 3,306,209\n",
      "Non-trainable params: 6,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 1)           4609      \n",
      "=================================================================\n",
      "Total params: 1,558,017\n",
      "Trainable params: 1,556,225\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
