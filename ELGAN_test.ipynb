{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from data_helper import predict_15k, save_hist, save_model\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "#from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Add, Lambda\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def lambda_output(input_shape):\n",
    "    return input_shape[:2]\n",
    "\n",
    "def minb_disc(x):\n",
    "    diffs = K.expand_dims(x, 3) - K.expand_dims(K.permute_dimensions(x, [1, 2, 0]), 0)\n",
    "    abs_diffs = K.sum(K.abs(diffs), 2)\n",
    "    x = K.sum(K.exp(-abs_diffs), 2)\n",
    "\n",
    "    return x\n",
    "\n",
    "def generate_patch_gan_loss(last_disc_conv_layer, patch_dim, input_layer, nb_patches):\n",
    "\n",
    "    # generate a list of inputs for the different patches to the network\n",
    "    list_input = [Input(shape=patch_dim, name=\"patch_gan_input_%s\" % i) for i in range(nb_patches)]\n",
    "\n",
    "    # get an activation\n",
    "    x_flat = Flatten()(last_disc_conv_layer)\n",
    "    x = Dense(2, activation='softmax', name=\"disc_dense\")(x_flat)\n",
    "\n",
    "    patch_gan = Model(inputs=[input_layer], outputs=[x, x_flat], name=\"patch_gan\")\n",
    "\n",
    "    # generate individual losses for each patch\n",
    "    x = [patch_gan(patch)[0] for patch in list_input]\n",
    "    x_mbd = [patch_gan(patch)[1] for patch in list_input]\n",
    "\n",
    "    # merge layers if have multiple patches (aka perceptual loss)\n",
    "    if len(x) > 1:\n",
    "        #x = merge(x, mode=\"concat\", name=\"merged_features\")\n",
    "        x = Concatenate(name=\"merged_features\")(x)\n",
    "    else:\n",
    "        x = x[0]\n",
    "\n",
    "    # merge mbd if needed\n",
    "    # mbd = mini batch discrimination\n",
    "    # https://arxiv.org/pdf/1606.03498.pdf\n",
    "    if len(x_mbd) > 1:\n",
    "        #x_mbd = merge(x_mbd, mode=\"concat\", name=\"merged_feature_mbd\")\n",
    "        x_mbd = Concatenate(name=\"merged_feature_mbd\")(x_mbd)\n",
    "    else:\n",
    "        x_mbd = x_mbd[0]\n",
    "\n",
    "    num_kernels = 100\n",
    "    dim_per_kernel = 5\n",
    "\n",
    "    M = Dense(num_kernels * dim_per_kernel, use_bias=False, activation=None)\n",
    "    MBD = Lambda(minb_disc, output_shape=lambda_output)\n",
    "\n",
    "    x_mbd = M(x_mbd)\n",
    "    x_mbd = Reshape((num_kernels, dim_per_kernel))(x_mbd)\n",
    "    x_mbd = MBD(x_mbd)\n",
    "    \n",
    "    #x = merge([x, x_mbd], mode='concat')\n",
    "    x = Concatenate()([x, x_mbd])\n",
    "\n",
    "    x_out = Dense(2, activation=\"softmax\", name=\"disc_output\")(x)\n",
    "\n",
    "    discriminator = Model(inputs=list_input, outputs=[x_out], name='discriminator_nn')\n",
    "    return discriminator\n",
    "\n",
    "def res_block(x, nb_filters, strides):\n",
    "    res_path = BatchNormalization()(x)\n",
    "    res_path = Activation(activation='relu')(res_path)\n",
    "    \n",
    "    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same', strides=strides[0])(res_path)\n",
    "    res_path = BatchNormalization()(res_path)\n",
    "    res_path = Activation(activation='relu')(res_path)\n",
    "    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same', strides=strides[1])(res_path)\n",
    "\n",
    "    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1), strides=strides[0])(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    res_path = Add()([shortcut, res_path])\n",
    "    return res_path\n",
    "\n",
    "def decoder(x, from_encoder):\n",
    "    main_path = UpSampling2D(size=(2, 2))(x)\n",
    "    main_path = Concatenate(axis=3)([main_path, from_encoder[2]])\n",
    "    main_path = res_block(main_path, [128, 128], [(1, 1), (1, 1)])\n",
    "\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path) \n",
    "    main_path = Concatenate(axis=3)([main_path, from_encoder[1]])\n",
    "    main_path = res_block(main_path, [64, 64], [(1, 1), (1, 1)])\n",
    "\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    main_path = Concatenate(axis=3)([main_path, from_encoder[0]])\n",
    "    main_path = res_block(main_path, [32, 32], [(1, 1), (1, 1)])\n",
    "\n",
    "    return main_path\n",
    "\n",
    "def encoder(x):\n",
    "    to_decoder = []\n",
    "\n",
    "    main_path = Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n",
    "    main_path = BatchNormalization()(main_path)\n",
    "    main_path = Activation(activation='relu')(main_path)\n",
    "    main_path = Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1, 1))(main_path)\n",
    "\n",
    "    shortcut = Conv2D(filters=32, kernel_size=(1, 1), strides=(1, 1))(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    main_path = Add()([shortcut, main_path])\n",
    "    # first branching to decoder\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    main_path = res_block(main_path, [64, 64], [(2, 2), (1, 1)])\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    main_path = res_block(main_path, [128, 128], [(2, 2), (1, 1)])\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    return to_decoder\n",
    "\n",
    "\n",
    "def build_res_unet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    to_decoder = encoder(inputs)\n",
    "\n",
    "    path = res_block(to_decoder[2], [256, 256], [(2, 2), (1, 1)]) # 3x\n",
    "    \n",
    "    path = res_block(path, [256, 256], [(1, 1), (1, 1)]) # Yu.add - in 2018-12-02 16-09-04_15 only once\n",
    "\n",
    "    path = decoder(path, from_encoder=to_decoder)\n",
    "    \n",
    "    path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path) \n",
    "\n",
    "    return Model(input=inputs, output=path)\n",
    "\n",
    "class EL_GAN(): # Based on pix2pix\n",
    "    def __init__(self):\n",
    "\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'mapgen'\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN) better version\n",
    "        self.patch_size = 32\n",
    "        self.nb_patches = int((self.img_rows / self.patch_size) * (self.img_cols / self.patch_size))\n",
    "        self.patch_gan_dim = (self.patch_size, self.patch_size, self.channels)\n",
    "        \n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        self.df = 64\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        #optimizer = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # An old version of Pix2pix\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        #self.generator = self.build_generator() # Old generator from \n",
    "        self.generator = self.build_res_unet_generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        img_A = Input(shape=self.img_shape) # Target\n",
    "        img_B = Input(shape=self.img_shape) # Input\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        fake_A = self.generator(img_B)\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        #valid = self.discriminator([fake_A, img_B])\n",
    "        valid = self.discriminator([fake_A])\n",
    "\n",
    "        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "        \n",
    "        # Original Pix2Pix - low weight for discriminator\n",
    "        self.combined.compile(loss=['mse', 'mae'],\n",
    "                              loss_weights=[1, 100],\n",
    "                              optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    def build_res_unet_generator(self):\n",
    "        \"\"\"Residual U-Net Generator\"\"\"\n",
    "        \n",
    "        inputs = Input(shape=self.img_shape)\n",
    "        to_decoder = encoder(inputs)\n",
    "        path = res_block(to_decoder[2], [256, 256], [(2, 2), (1, 1)]) # 3x\n",
    "        path = res_block(path, [256, 256], [(1, 1), (1, 1)])\n",
    "        path = decoder(path, from_encoder=to_decoder)\n",
    "        path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path) \n",
    "\n",
    "        return Model(input=inputs, output=path)\n",
    "        \n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, self.gf*8)\n",
    "        u2 = deconv2d(u1, d5, self.gf*8)\n",
    "        u3 = deconv2d(u2, d4, self.gf*8)\n",
    "        u4 = deconv2d(u3, d3, self.gf*4)\n",
    "        u5 = deconv2d(u4, d2, self.gf*2)\n",
    "        u6 = deconv2d(u5, d1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "    \n",
    "    def build_PatchGanDiscriminator(self):\n",
    "        \"\"\"\n",
    "        Creates the generator according to the specs in the paper below.\n",
    "        [https://arxiv.org/pdf/1611.07004v1.pdf][5. Appendix]\n",
    "\n",
    "        PatchGAN only penalizes structure at the scale of patches. This\n",
    "        discriminator tries to classify if each N x N patch in an\n",
    "        image is real or fake. We run this discriminator convolutationally\n",
    "        across the image, averaging all responses to provide\n",
    "        the ultimate output of D.\n",
    "\n",
    "        The discriminator has two parts. First part is the actual discriminator\n",
    "        seconds part we make it a PatchGAN by running each image patch through the model\n",
    "        and then we average the responses\n",
    "\n",
    "        Discriminator does the following:\n",
    "        1. Runs many pieces of the image through the network\n",
    "        2. Calculates the cost for each patch\n",
    "        3. Returns the avg of the costs as the output of the network\n",
    "\n",
    "        :param patch_dim: (channels, width, height) T\n",
    "        :param nb_patches:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # -------------------------------\n",
    "        # DISCRIMINATOR\n",
    "        # C64-C128-C256-C512-C512-C512 (for 256x256)\n",
    "        # otherwise, it scales from 64\n",
    "        # 1 layer block = Conv - BN - LeakyRelu\n",
    "        # -------------------------------\n",
    "        \n",
    "        output_img_dim = self.img_shape\n",
    "        patch_dim = self.patch_gan_dim\n",
    "        input_layer = Input(shape=patch_dim)\n",
    "        \n",
    "        # We have to build the discriminator dinamically because\n",
    "        # the size of the disc patches is dynamic\n",
    "        num_filters_start = self.gf\n",
    "        nb_conv = int(np.floor(np.log(output_img_dim[1]) / np.log(2)))\n",
    "        filters_list = [num_filters_start * min(8, (2 ** i)) for i in range(nb_conv)]\n",
    "        \n",
    "        # CONV 1\n",
    "        # Do first conv bc it is different from the rest\n",
    "        # paper skips batch norm for first layer\n",
    "        disc_out = Conv2D(filters=64, kernel_size=(4, 4), padding='same', strides=(2, 2), name='disc_conv_1')(input_layer)\n",
    "        disc_out = LeakyReLU(alpha=0.2)(disc_out)\n",
    "        \n",
    "        # CONV 2 - CONV N\n",
    "        # do the rest of the convs based on the sizes from the filters\n",
    "        for i, filter_size in enumerate(filters_list[1:]):\n",
    "            name = 'disc_conv_{}'.format(i+2)\n",
    "\n",
    "            disc_out = Conv2D(filters=filter_size, kernel_size=(4, 4), padding='same', strides=(2, 2), name=name)(disc_out)\n",
    "            disc_out = BatchNormalization(name=name + '_bn')(disc_out)\n",
    "            disc_out = LeakyReLU(alpha=0.2)(disc_out)\n",
    "        \n",
    "        # ------------------------\n",
    "        # BUILD PATCH GAN\n",
    "        # this is where we evaluate the loss over each sublayer of the input\n",
    "        # ------------------------\n",
    "        patch_gan_discriminator = generate_patch_gan_loss(last_disc_conv_layer=disc_out,\n",
    "                                                          patch_dim=patch_dim,\n",
    "                                                          input_layer=input_layer,\n",
    "                                                          nb_patches=nb_patches)\n",
    "        return patch_gan_discriminator\n",
    "    \n",
    "    def build_2head_discriminator(self):\n",
    "        \n",
    "        def d_layer(layer_input, filters, f_size=3, bn=True): # Chnaged here for the order of bn and activation\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            conv = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')\n",
    "            d = conv(layer_input)\n",
    "            e = conv(layer_input2)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Activation(activation='relu')(d)\n",
    "            #d = LeakyReLU(alpha=0.2)(d)\n",
    "            return d\n",
    "        \n",
    "        def d_layers(img_A):\n",
    "            d1 = d_layer(img_A, self.df, bn=False)\n",
    "            d2 = d_layer(d1, self.df*2)\n",
    "            d3 = d_layer(d2, self.df*4)\n",
    "            d4 = d_layer(d3, self.df*8)\n",
    "            d5 = Flatten()(d4)\n",
    "            d6 = Dense(128, activation='softmax')(d5)\n",
    "            \n",
    "            return Model(img_A, d6)\n",
    "        \n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "        \n",
    "        encoded_a = d_layers(img_A)\n",
    "        encoded_b = d_layers(img_B)\n",
    "        \n",
    "        # We can then concatenate the two vectors:\n",
    "        #merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=-1)\n",
    "        \n",
    "        return Model([img_A, img_B], validity)\n",
    "        \n",
    "    \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=3, bn=True): # Chnaged here for the order of bn and activation\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Activation(activation='relu')(d)\n",
    "            #d = LeakyReLU(alpha=0.2)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        #img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        ## Concatenate image and conditioning image by channels to produce input\n",
    "        #combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        #d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        \n",
    "        d1 = d_layer(img_A, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A], validity)\n",
    "    \n",
    "    def train_generator_only(self, x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath):\n",
    "        \n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        data_gen_args = dict(rotation_range=180.)\n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        \n",
    "        seed = 1\n",
    "        BATCH_SIZE = 16\n",
    "        result_generator = zip(image_datagen.flow(x_train_sim, batch_size=BATCH_SIZE, seed=seed), \n",
    "                               mask_datagen.flow(y_train_sim, batch_size=BATCH_SIZE, seed=seed))\n",
    "        \n",
    "        History1 = History()\n",
    "        hist1 = self.generator.fit_generator( result_generator,\n",
    "                                              epochs = 100,\n",
    "                                              steps_per_epoch=2000,\n",
    "                                              verbose=1,\n",
    "                                              shuffle=True,\n",
    "                                              callbacks=[History1, \n",
    "                                                         EarlyStopping(patience=5), \n",
    "                                                         ReduceLROnPlateau(patience = 3, verbose = 0),\n",
    "                                                         ModelCheckpoint(outPath + \"weights.hdf5\", \n",
    "                                                                         save_best_only = True, \n",
    "                                                                         save_weights_only = False)],\n",
    "                                              validation_data=(x_test_sim, y_test_sim))\n",
    "        save_hist(History1, outPath)\n",
    "        \n",
    "    \n",
    "    def train(self, x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        \n",
    "        total_samples = len(x_train_sim)\n",
    "        ids = np.arange(total_samples)\n",
    "        np.random.shuffle(ids)\n",
    "        n_batches = int(total_samples / batch_size)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(load_batch(x_train_sim, y_train_sim, batch_size)):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Condition on B and generate a translated version\n",
    "                fake_A = self.generator.predict(imgs_B)\n",
    "                \n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                #d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                #d_loss_fake = self.discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs_A], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([fake_A], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                # Train the generators\n",
    "                self.discriminator.trainable = False\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "                self.discriminator.trainable = True\n",
    "                \n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "                # Plot the progress\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    \n",
    "                    valid_test = np.ones((len(x_test_sim),) + self.disc_patch)\n",
    "                    t_loss = self.combined.evaluate([y_test_sim, x_test_sim], [valid_test, y_test_sim], verbose=0)\n",
    "                    \n",
    "                    print (\"[Epoch %d/%d-%d/%d] [D loss&acc: %.3f, %.3f%%] [G loss&accA&accB: %.3f, %.3f%%, %.3f%%] [Test loss&acc: %.3f, %.3f%%, %.3f%%] time: %s\" % (epoch, epochs,\n",
    "                                                                                batch_i, n_batches,\n",
    "                                                                                d_loss[0], 100*d_loss[1],\n",
    "                                                                                g_loss[2], 100*g_loss[3], 100*g_loss[4],\n",
    "                                                                                t_loss[2], 100*t_loss[3], 100*t_loss[4],\n",
    "                                                                                elapsed_time))                 \n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(outPath, epoch, batch_i)\n",
    "\n",
    "\n",
    "    def sample_images(self, outPath, epoch, batch_i, examples = [0, 77, 34]):\n",
    "        \n",
    "        r, c = 3, 3\n",
    "        p_size_1 = 128\n",
    "        \n",
    "        imgs_A = y_test_sim[examples]\n",
    "        imgs_B = x_test_sim[examples]\n",
    "        \n",
    "        fake_A = gan.generator.predict(imgs_B)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Input', 'Generated', 'Target']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                gen = np.reshape(gen_imgs[cnt], (p_size_1,p_size_1))\n",
    "                axs[i,j].imshow(gen)\n",
    "                \n",
    "                #axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(outPath + \"%d_%d.png\" % (epoch, batch_i),\n",
    "                   format='png', transparent=True, dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape of the trains (32289, 128, 128, 1)\n",
      "Input Shape of the tests (3587, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Order the image dimension acc. to TensorFlow (batc_hsize, rows, cols, channels)\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "scale = 15\n",
    "p_size_1 = 128 # Compared with 256, which larger may generate round corners\n",
    "trainPath = r\"../tmp_data/data_feng/geb\" + str(scale) +  \"/\"\n",
    "\n",
    "# save image patch arrays\n",
    "x_train_sim = np.load(trainPath + \"x_train_sim.npy\")\n",
    "y_train_sim = np.load(trainPath + \"y_train_sim.npy\")\n",
    "x_test_sim = np.load(trainPath + \"x_test_sim.npy\")\n",
    "y_test_sim = np.load(trainPath + \"y_test_sim.npy\")\n",
    "\n",
    "input_shape1 = (None, None, 1) #x_train_sim[0].shape\n",
    "print('Input Shape of the trains', x_train_sim.shape)\n",
    "print('Input Shape of the tests', x_test_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper import readImg, readImgInv, imagePatches, removeBlackImg, removeCorrespondence, check_and_create\n",
    "\n",
    "from time import gmtime, strftime\n",
    "timestr = strftime(\"%Y-%m-%d %H-%M-%S\", gmtime())\n",
    "\n",
    "############ Path Setting ##############\n",
    "outPath = r\"../tmp_results/predictions/\"\n",
    "outPath = outPath + timestr + '_' + str(scale)+ \"/\"\n",
    "check_and_create(outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(x_train_sim, y_train_sim, batch_size):\n",
    "    total_samples = len(x_train_sim)\n",
    "    ids = np.arange(total_samples)\n",
    "    np.random.shuffle(ids)\n",
    "    n_batches = int(total_samples / batch_size)\n",
    "    for i in range(n_batches-1):\n",
    "        batch_idx = ids[i*batch_size:(i+1)*batch_size]\n",
    "        imgs_A = x_train_sim[batch_idx]\n",
    "        imgs_B = y_train_sim[batch_idx]\n",
    "        yield imgs_B, imgs_A     \n",
    "        \n",
    "def load_data(x_test_sim, y_test_sim, batch_size=1):\n",
    "    return x_test_sim  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:213: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/30-0/1009] [D loss&acc: 1.235, 34.497%] [G loss&accA&accB: 0.558, 45.947%, 30.516%] [Test loss&acc: 0.292, 0.000%, 77.821%] time: 0:00:10.514197\n",
      "[Epoch 0/30-200/1009] [D loss&acc: 0.324, 14.111%] [G loss&accA&accB: 0.009, 8.057%, 99.103%] [Test loss&acc: 0.011, 0.000%, 98.958%] time: 0:01:27.198881\n",
      "[Epoch 0/30-400/1009] [D loss&acc: 0.310, 19.507%] [G loss&accA&accB: 0.005, 3.613%, 99.510%] [Test loss&acc: 0.010, 0.000%, 98.970%] time: 0:02:43.003916\n",
      "[Epoch 0/30-600/1009] [D loss&acc: 0.311, 7.324%] [G loss&accA&accB: 0.009, 8.887%, 99.134%] [Test loss&acc: 0.010, 0.000%, 98.978%] time: 0:03:59.240098\n",
      "[Epoch 0/30-800/1009] [D loss&acc: 0.305, 10.205%] [G loss&accA&accB: 0.011, 8.984%, 98.942%] [Test loss&acc: 0.010, 0.000%, 98.981%] time: 0:05:15.829992\n",
      "[Epoch 0/30-1000/1009] [D loss&acc: 0.291, 40.015%] [G loss&accA&accB: 0.003, 4.639%, 99.681%] [Test loss&acc: 0.010, 0.000%, 98.985%] time: 0:06:32.821859\n",
      "[Epoch 1/30-0/1009] [D loss&acc: 0.288, 31.714%] [G loss&accA&accB: 0.011, 2.539%, 98.934%] [Test loss&acc: 0.010, 0.000%, 98.987%] time: 0:06:45.485261\n",
      "[Epoch 1/30-200/1009] [D loss&acc: 0.293, 9.766%] [G loss&accA&accB: 0.010, 7.812%, 98.971%] [Test loss&acc: 0.010, 0.000%, 98.988%] time: 0:08:02.788664\n",
      "[Epoch 1/30-400/1009] [D loss&acc: 0.288, 32.690%] [G loss&accA&accB: 0.007, 3.125%, 99.313%] [Test loss&acc: 0.010, 0.000%, 98.990%] time: 0:09:19.875691\n",
      "[Epoch 1/30-600/1009] [D loss&acc: 0.295, 8.569%] [G loss&accA&accB: 0.011, 8.984%, 98.877%] [Test loss&acc: 0.010, 0.000%, 98.997%] time: 0:10:36.696702\n",
      "[Epoch 1/30-800/1009] [D loss&acc: 0.351, 6.860%] [G loss&accA&accB: 0.011, 4.688%, 98.904%] [Test loss&acc: 0.010, 0.000%, 98.983%] time: 0:11:53.558146\n",
      "[Epoch 1/30-1000/1009] [D loss&acc: 0.315, 5.444%] [G loss&accA&accB: 0.011, 1.221%, 98.920%] [Test loss&acc: 0.010, 0.000%, 98.997%] time: 0:13:10.636501\n",
      "[Epoch 2/30-0/1009] [D loss&acc: 0.319, 4.419%] [G loss&accA&accB: 0.017, 4.150%, 98.263%] [Test loss&acc: 0.010, 0.000%, 99.002%] time: 0:13:23.321212\n",
      "[Epoch 2/30-200/1009] [D loss&acc: 0.305, 6.763%] [G loss&accA&accB: 0.008, 2.441%, 99.169%] [Test loss&acc: 0.010, 0.000%, 99.009%] time: 0:14:40.693807\n",
      "[Epoch 2/30-400/1009] [D loss&acc: 0.304, 28.027%] [G loss&accA&accB: 0.014, 22.461%, 98.633%] [Test loss&acc: 0.010, 0.000%, 99.007%] time: 0:15:57.548104\n",
      "[Epoch 2/30-600/1009] [D loss&acc: 0.300, 20.508%] [G loss&accA&accB: 0.013, 15.820%, 98.653%] [Test loss&acc: 0.010, 0.000%, 99.011%] time: 0:17:14.798449\n",
      "[Epoch 2/30-800/1009] [D loss&acc: 0.295, 12.305%] [G loss&accA&accB: 0.005, 17.627%, 99.455%] [Test loss&acc: 0.010, 0.000%, 99.018%] time: 0:18:31.759284\n",
      "[Epoch 2/30-1000/1009] [D loss&acc: 0.292, 10.913%] [G loss&accA&accB: 0.011, 7.764%, 98.880%] [Test loss&acc: 0.010, 0.000%, 99.018%] time: 0:19:48.521846\n",
      "[Epoch 3/30-0/1009] [D loss&acc: 0.297, 17.090%] [G loss&accA&accB: 0.007, 13.232%, 99.272%] [Test loss&acc: 0.010, 0.000%, 99.027%] time: 0:20:01.213151\n",
      "[Epoch 3/30-200/1009] [D loss&acc: 0.302, 7.544%] [G loss&accA&accB: 0.007, 4.248%, 99.313%] [Test loss&acc: 0.010, 0.000%, 99.015%] time: 0:21:17.596968\n",
      "[Epoch 3/30-400/1009] [D loss&acc: 0.311, 10.352%] [G loss&accA&accB: 0.009, 14.404%, 99.077%] [Test loss&acc: 0.010, 0.000%, 99.035%] time: 0:22:34.309428\n",
      "[Epoch 3/30-600/1009] [D loss&acc: 0.281, 15.820%] [G loss&accA&accB: 0.013, 5.078%, 98.704%] [Test loss&acc: 0.010, 0.000%, 99.033%] time: 0:23:50.927170\n",
      "[Epoch 3/30-800/1009] [D loss&acc: 0.286, 14.355%] [G loss&accA&accB: 0.012, 4.395%, 98.796%] [Test loss&acc: 0.010, 0.000%, 99.042%] time: 0:25:07.713609\n",
      "[Epoch 3/30-1000/1009] [D loss&acc: 0.308, 11.597%] [G loss&accA&accB: 0.008, 17.920%, 99.188%] [Test loss&acc: 0.010, 0.000%, 99.043%] time: 0:26:24.657511\n",
      "[Epoch 4/30-0/1009] [D loss&acc: 0.311, 10.571%] [G loss&accA&accB: 0.008, 15.723%, 99.157%] [Test loss&acc: 0.010, 0.000%, 99.051%] time: 0:26:37.294070\n",
      "[Epoch 4/30-200/1009] [D loss&acc: 0.295, 35.132%] [G loss&accA&accB: 0.008, 28.027%, 99.250%] [Test loss&acc: 0.010, 0.000%, 99.015%] time: 0:27:53.819574\n",
      "[Epoch 4/30-400/1009] [D loss&acc: 0.282, 18.823%] [G loss&accA&accB: 0.015, 2.295%, 98.482%] [Test loss&acc: 0.009, 0.002%, 99.069%] time: 0:29:10.568898\n",
      "[Epoch 4/30-600/1009] [D loss&acc: 0.281, 19.092%] [G loss&accA&accB: 0.009, 15.918%, 99.059%] [Test loss&acc: 0.009, 0.000%, 99.074%] time: 0:30:26.970973\n",
      "[Epoch 4/30-800/1009] [D loss&acc: 0.276, 34.814%] [G loss&accA&accB: 0.005, 2.637%, 99.525%] [Test loss&acc: 0.009, 0.002%, 99.122%] time: 0:31:43.557814\n",
      "[Epoch 4/30-1000/1009] [D loss&acc: 0.279, 44.141%] [G loss&accA&accB: 0.005, 0.488%, 99.454%] [Test loss&acc: 0.009, 0.000%, 99.152%] time: 0:32:59.933808\n",
      "[Epoch 5/30-0/1009] [D loss&acc: 0.284, 16.650%] [G loss&accA&accB: 0.009, 10.938%, 99.121%] [Test loss&acc: 0.009, 0.000%, 99.147%] time: 0:33:12.645020\n",
      "[Epoch 5/30-200/1009] [D loss&acc: 0.281, 29.517%] [G loss&accA&accB: 0.010, 1.416%, 99.001%] [Test loss&acc: 0.008, 13.574%, 99.156%] time: 0:34:29.245011\n",
      "[Epoch 5/30-400/1009] [D loss&acc: 0.291, 14.453%] [G loss&accA&accB: 0.010, 21.777%, 98.970%] [Test loss&acc: 0.008, 1.891%, 99.151%] time: 0:35:45.516269\n",
      "[Epoch 5/30-600/1009] [D loss&acc: 0.302, 23.340%] [G loss&accA&accB: 0.008, 28.320%, 99.170%] [Test loss&acc: 0.008, 14.858%, 99.194%] time: 0:37:02.305628\n",
      "[Epoch 5/30-800/1009] [D loss&acc: 0.287, 8.936%] [G loss&accA&accB: 0.009, 3.662%, 99.117%] [Test loss&acc: 0.008, 20.233%, 99.161%] time: 0:38:18.550473\n",
      "[Epoch 5/30-1000/1009] [D loss&acc: 0.282, 19.336%] [G loss&accA&accB: 0.008, 4.834%, 99.154%] [Test loss&acc: 0.008, 16.756%, 99.205%] time: 0:39:35.184920\n",
      "[Epoch 6/30-0/1009] [D loss&acc: 0.283, 10.083%] [G loss&accA&accB: 0.008, 6.104%, 99.232%] [Test loss&acc: 0.008, 18.338%, 99.193%] time: 0:39:47.870717\n",
      "[Epoch 6/30-200/1009] [D loss&acc: 0.283, 7.251%] [G loss&accA&accB: 0.006, 8.447%, 99.441%] [Test loss&acc: 0.008, 12.847%, 99.226%] time: 0:41:04.477112\n",
      "[Epoch 6/30-400/1009] [D loss&acc: 0.329, 2.612%] [G loss&accA&accB: 0.005, 2.197%, 99.473%] [Test loss&acc: 0.008, 29.278%, 99.215%] time: 0:42:20.970544\n",
      "[Epoch 6/30-600/1009] [D loss&acc: 0.309, 2.539%] [G loss&accA&accB: 0.006, 2.197%, 99.377%] [Test loss&acc: 0.008, 22.149%, 99.219%] time: 0:43:37.161772\n",
      "[Epoch 6/30-800/1009] [D loss&acc: 0.299, 9.180%] [G loss&accA&accB: 0.008, 2.295%, 99.249%] [Test loss&acc: 0.008, 26.884%, 99.238%] time: 0:44:53.486585\n",
      "[Epoch 6/30-1000/1009] [D loss&acc: 0.288, 16.040%] [G loss&accA&accB: 0.007, 4.541%, 99.350%] [Test loss&acc: 0.008, 31.872%, 99.215%] time: 0:46:09.944333\n",
      "[Epoch 7/30-0/1009] [D loss&acc: 0.291, 10.474%] [G loss&accA&accB: 0.008, 3.955%, 99.235%] [Test loss&acc: 0.008, 30.576%, 99.236%] time: 0:46:22.637555\n",
      "[Epoch 7/30-200/1009] [D loss&acc: 0.286, 9.668%] [G loss&accA&accB: 0.005, 9.375%, 99.507%] [Test loss&acc: 0.008, 34.958%, 99.229%] time: 0:47:38.720070\n",
      "[Epoch 7/30-400/1009] [D loss&acc: 0.296, 7.056%] [G loss&accA&accB: 0.006, 5.127%, 99.415%] [Test loss&acc: 0.007, 0.004%, 99.251%] time: 0:48:55.194871\n",
      "[Epoch 7/30-600/1009] [D loss&acc: 0.279, 21.094%] [G loss&accA&accB: 0.007, 2.734%, 99.307%] [Test loss&acc: 0.007, 2.770%, 99.258%] time: 0:50:11.605410\n",
      "[Epoch 7/30-800/1009] [D loss&acc: 0.283, 23.047%] [G loss&accA&accB: 0.006, 2.637%, 99.404%] [Test loss&acc: 0.008, 15.525%, 99.245%] time: 0:51:27.555299\n",
      "[Epoch 7/30-1000/1009] [D loss&acc: 0.289, 16.357%] [G loss&accA&accB: 0.006, 2.490%, 99.358%] [Test loss&acc: 0.007, 6.712%, 99.264%] time: 0:52:43.544479\n",
      "[Epoch 8/30-0/1009] [D loss&acc: 0.292, 10.547%] [G loss&accA&accB: 0.008, 6.689%, 99.201%] [Test loss&acc: 0.007, 9.952%, 99.257%] time: 0:52:56.174242\n",
      "[Epoch 8/30-200/1009] [D loss&acc: 0.289, 30.762%] [G loss&accA&accB: 0.008, 48.682%, 99.235%] [Test loss&acc: 0.007, 15.963%, 99.270%] time: 0:54:12.214781\n",
      "[Epoch 8/30-400/1009] [D loss&acc: 0.283, 21.826%] [G loss&accA&accB: 0.007, 24.854%, 99.339%] [Test loss&acc: 0.007, 16.202%, 99.252%] time: 0:55:28.273735\n",
      "[Epoch 8/30-600/1009] [D loss&acc: 0.306, 4.639%] [G loss&accA&accB: 0.008, 1.904%, 99.222%] [Test loss&acc: 0.007, 7.166%, 99.273%] time: 0:56:44.287809\n",
      "[Epoch 8/30-800/1009] [D loss&acc: 0.290, 8.447%] [G loss&accA&accB: 0.006, 4.102%, 99.426%] [Test loss&acc: 0.007, 34.487%, 99.270%] time: 0:58:00.455913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/30-1000/1009] [D loss&acc: 0.281, 15.918%] [G loss&accA&accB: 0.008, 4.980%, 99.188%] [Test loss&acc: 0.007, 33.122%, 99.274%] time: 0:59:16.461117\n",
      "[Epoch 9/30-0/1009] [D loss&acc: 0.289, 7.690%] [G loss&accA&accB: 0.007, 5.078%, 99.304%] [Test loss&acc: 0.007, 28.334%, 99.274%] time: 0:59:29.076515\n",
      "[Epoch 9/30-200/1009] [D loss&acc: 0.281, 11.646%] [G loss&accA&accB: 0.005, 4.785%, 99.455%] [Test loss&acc: 0.007, 27.195%, 99.267%] time: 1:00:45.196358\n",
      "[Epoch 9/30-400/1009] [D loss&acc: 0.309, 33.447%] [G loss&accA&accB: 0.005, 54.102%, 99.523%] [Test loss&acc: 0.007, 6.116%, 99.275%] time: 1:02:00.828640\n",
      "[Epoch 9/30-600/1009] [D loss&acc: 0.307, 39.819%] [G loss&accA&accB: 0.007, 79.688%, 99.274%] [Test loss&acc: 0.007, 27.353%, 99.274%] time: 1:03:16.516695\n",
      "[Epoch 9/30-800/1009] [D loss&acc: 0.279, 26.123%] [G loss&accA&accB: 0.004, 4.492%, 99.554%] [Test loss&acc: 0.007, 30.504%, 99.276%] time: 1:04:32.204110\n",
      "[Epoch 9/30-1000/1009] [D loss&acc: 0.298, 20.166%] [G loss&accA&accB: 0.005, 0.928%, 99.497%] [Test loss&acc: 0.007, 8.090%, 99.280%] time: 1:05:47.631897\n",
      "[Epoch 10/30-0/1009] [D loss&acc: 0.304, 6.519%] [G loss&accA&accB: 0.010, 6.885%, 99.038%] [Test loss&acc: 0.007, 12.468%, 99.281%] time: 1:06:00.247096\n",
      "[Epoch 10/30-200/1009] [D loss&acc: 0.283, 11.475%] [G loss&accA&accB: 0.007, 19.531%, 99.306%] [Test loss&acc: 0.007, 24.081%, 99.266%] time: 1:07:15.776538\n",
      "[Epoch 10/30-400/1009] [D loss&acc: 0.274, 29.077%] [G loss&accA&accB: 0.005, 1.416%, 99.473%] [Test loss&acc: 0.007, 35.149%, 99.288%] time: 1:08:31.388151\n",
      "[Epoch 10/30-600/1009] [D loss&acc: 0.276, 26.611%] [G loss&accA&accB: 0.006, 2.051%, 99.415%] [Test loss&acc: 0.007, 37.640%, 99.272%] time: 1:09:47.109435\n",
      "[Epoch 10/30-800/1009] [D loss&acc: 0.278, 31.128%] [G loss&accA&accB: 0.004, 4.785%, 99.577%] [Test loss&acc: 0.007, 7.593%, 99.278%] time: 1:11:02.680678\n",
      "[Epoch 10/30-1000/1009] [D loss&acc: 0.282, 23.828%] [G loss&accA&accB: 0.007, 26.318%, 99.268%] [Test loss&acc: 0.007, 0.975%, 99.284%] time: 1:12:18.285874\n",
      "[Epoch 11/30-0/1009] [D loss&acc: 0.278, 24.634%] [G loss&accA&accB: 0.007, 17.969%, 99.314%] [Test loss&acc: 0.007, 2.440%, 99.286%] time: 1:12:30.987808\n",
      "[Epoch 11/30-200/1009] [D loss&acc: 0.267, 38.818%] [G loss&accA&accB: 0.009, 55.518%, 99.098%] [Test loss&acc: 0.007, 0.014%, 99.286%] time: 1:13:46.967127\n",
      "[Epoch 11/30-400/1009] [D loss&acc: 0.268, 22.192%] [G loss&accA&accB: 0.008, 16.846%, 99.175%] [Test loss&acc: 0.007, 0.013%, 99.289%] time: 1:15:02.761000\n",
      "[Epoch 11/30-600/1009] [D loss&acc: 0.267, 29.492%] [G loss&accA&accB: 0.004, 11.035%, 99.566%] [Test loss&acc: 0.007, 0.036%, 99.288%] time: 1:16:18.908864\n",
      "[Epoch 11/30-800/1009] [D loss&acc: 0.269, 27.441%] [G loss&accA&accB: 0.004, 8.252%, 99.582%] [Test loss&acc: 0.007, 0.057%, 99.284%] time: 1:17:34.394908\n",
      "[Epoch 11/30-1000/1009] [D loss&acc: 0.269, 28.809%] [G loss&accA&accB: 0.009, 7.861%, 99.118%] [Test loss&acc: 0.007, 0.058%, 99.281%] time: 1:18:49.990813\n",
      "[Epoch 12/30-0/1009] [D loss&acc: 0.267, 33.813%] [G loss&accA&accB: 0.006, 27.246%, 99.386%] [Test loss&acc: 0.007, 0.064%, 99.291%] time: 1:19:02.588331\n",
      "[Epoch 12/30-200/1009] [D loss&acc: 0.268, 35.400%] [G loss&accA&accB: 0.006, 7.910%, 99.430%] [Test loss&acc: 0.007, 0.063%, 99.304%] time: 1:20:18.125519\n",
      "[Epoch 12/30-400/1009] [D loss&acc: 0.266, 32.544%] [G loss&accA&accB: 0.004, 3.662%, 99.562%] [Test loss&acc: 0.007, 0.144%, 99.270%] time: 1:21:33.434088\n",
      "[Epoch 12/30-600/1009] [D loss&acc: 0.259, 44.897%] [G loss&accA&accB: 0.004, 38.037%, 99.570%] [Test loss&acc: 0.007, 0.109%, 99.286%] time: 1:22:48.871479\n",
      "[Epoch 12/30-800/1009] [D loss&acc: 0.256, 42.163%] [G loss&accA&accB: 0.006, 13.721%, 99.362%] [Test loss&acc: 0.007, 1.837%, 99.304%] time: 1:24:04.234217\n",
      "[Epoch 12/30-1000/1009] [D loss&acc: 0.261, 28.882%] [G loss&accA&accB: 0.005, 22.900%, 99.483%] [Test loss&acc: 0.007, 1.200%, 99.296%] time: 1:25:19.713486\n",
      "[Epoch 13/30-0/1009] [D loss&acc: 0.263, 25.146%] [G loss&accA&accB: 0.004, 16.260%, 99.563%] [Test loss&acc: 0.007, 1.765%, 99.294%] time: 1:25:32.295179\n",
      "[Epoch 13/30-200/1009] [D loss&acc: 0.270, 24.414%] [G loss&accA&accB: 0.006, 30.859%, 99.377%] [Test loss&acc: 0.007, 0.292%, 99.287%] time: 1:26:47.909725\n",
      "[Epoch 13/30-400/1009] [D loss&acc: 0.272, 21.899%] [G loss&accA&accB: 0.005, 21.680%, 99.471%] [Test loss&acc: 0.007, 8.870%, 99.294%] time: 1:28:03.177339\n",
      "[Epoch 13/30-600/1009] [D loss&acc: 0.264, 34.937%] [G loss&accA&accB: 0.010, 6.689%, 98.958%] [Test loss&acc: 0.007, 0.498%, 99.285%] time: 1:29:18.638079\n",
      "[Epoch 13/30-800/1009] [D loss&acc: 0.262, 47.021%] [G loss&accA&accB: 0.006, 82.178%, 99.357%] [Test loss&acc: 0.007, 2.804%, 99.283%] time: 1:30:34.099584\n",
      "[Epoch 13/30-1000/1009] [D loss&acc: 0.261, 26.416%] [G loss&accA&accB: 0.005, 24.512%, 99.527%] [Test loss&acc: 0.007, 3.826%, 99.284%] time: 1:31:49.417346\n",
      "[Epoch 14/30-0/1009] [D loss&acc: 0.259, 46.411%] [G loss&accA&accB: 0.006, 49.902%, 99.350%] [Test loss&acc: 0.007, 9.918%, 99.293%] time: 1:32:02.032288\n",
      "[Epoch 14/30-200/1009] [D loss&acc: 0.262, 29.614%] [G loss&accA&accB: 0.004, 28.906%, 99.559%] [Test loss&acc: 0.007, 5.455%, 99.305%] time: 1:33:17.324404\n",
      "[Epoch 14/30-400/1009] [D loss&acc: 0.259, 46.558%] [G loss&accA&accB: 0.007, 2.441%, 99.292%] [Test loss&acc: 0.007, 3.861%, 99.287%] time: 1:34:32.726210\n",
      "[Epoch 14/30-600/1009] [D loss&acc: 0.262, 25.220%] [G loss&accA&accB: 0.003, 13.916%, 99.666%] [Test loss&acc: 0.007, 6.430%, 99.300%] time: 1:35:48.193300\n",
      "[Epoch 14/30-800/1009] [D loss&acc: 0.258, 38.184%] [G loss&accA&accB: 0.007, 13.916%, 99.289%] [Test loss&acc: 0.007, 9.209%, 99.285%] time: 1:37:03.666135\n",
      "[Epoch 14/30-1000/1009] [D loss&acc: 0.258, 44.800%] [G loss&accA&accB: 0.005, 3.955%, 99.549%] [Test loss&acc: 0.007, 5.587%, 99.299%] time: 1:38:19.010013\n",
      "[Epoch 15/30-0/1009] [D loss&acc: 0.264, 32.690%] [G loss&accA&accB: 0.004, 6.836%, 99.645%] [Test loss&acc: 0.007, 5.915%, 99.306%] time: 1:38:31.598533\n",
      "[Epoch 15/30-200/1009] [D loss&acc: 0.273, 26.880%] [G loss&accA&accB: 0.008, 32.910%, 99.208%] [Test loss&acc: 0.019, 18.202%, 98.145%] time: 1:39:47.025031\n",
      "[Epoch 15/30-400/1009] [D loss&acc: 0.257, 44.092%] [G loss&accA&accB: 0.006, 5.225%, 99.369%] [Test loss&acc: 0.007, 7.414%, 99.267%] time: 1:41:02.182217\n",
      "[Epoch 15/30-600/1009] [D loss&acc: 0.261, 37.061%] [G loss&accA&accB: 0.005, 20.264%, 99.526%] [Test loss&acc: 0.007, 6.139%, 99.279%] time: 1:42:17.583323\n",
      "[Epoch 15/30-800/1009] [D loss&acc: 0.267, 20.776%] [G loss&accA&accB: 0.005, 20.654%, 99.512%] [Test loss&acc: 0.007, 2.622%, 99.294%] time: 1:43:33.069599\n",
      "[Epoch 15/30-1000/1009] [D loss&acc: 0.261, 43.091%] [G loss&accA&accB: 0.005, 15.820%, 99.456%] [Test loss&acc: 0.007, 1.690%, 99.291%] time: 1:44:48.722461\n",
      "[Epoch 16/30-0/1009] [D loss&acc: 0.245, 58.423%] [G loss&accA&accB: 0.007, 36.377%, 99.263%] [Test loss&acc: 0.007, 3.010%, 99.293%] time: 1:45:01.372440\n",
      "[Epoch 16/30-200/1009] [D loss&acc: 0.261, 22.998%] [G loss&accA&accB: 0.004, 20.947%, 99.624%] [Test loss&acc: 0.007, 0.917%, 99.302%] time: 1:46:16.706628\n",
      "[Epoch 16/30-400/1009] [D loss&acc: 0.260, 38.867%] [G loss&accA&accB: 0.003, 3.223%, 99.677%] [Test loss&acc: 0.007, 0.555%, 99.297%] time: 1:47:32.407574\n",
      "[Epoch 16/30-600/1009] [D loss&acc: 0.265, 35.034%] [G loss&accA&accB: 0.006, 14.648%, 99.433%] [Test loss&acc: 0.007, 0.360%, 99.309%] time: 1:48:48.046299\n",
      "[Epoch 16/30-800/1009] [D loss&acc: 0.257, 42.871%] [G loss&accA&accB: 0.006, 35.938%, 99.388%] [Test loss&acc: 0.007, 0.464%, 99.301%] time: 1:50:03.575001\n",
      "[Epoch 16/30-1000/1009] [D loss&acc: 0.264, 42.896%] [G loss&accA&accB: 0.006, 20.312%, 99.418%] [Test loss&acc: 0.007, 0.399%, 99.297%] time: 1:51:20.028781\n",
      "[Epoch 17/30-0/1009] [D loss&acc: 0.264, 25.903%] [G loss&accA&accB: 0.005, 24.561%, 99.476%] [Test loss&acc: 0.007, 0.596%, 99.308%] time: 1:51:32.683169\n",
      "[Epoch 17/30-200/1009] [D loss&acc: 0.264, 22.510%] [G loss&accA&accB: 0.007, 26.758%, 99.300%] [Test loss&acc: 0.007, 0.339%, 99.304%] time: 1:52:48.001670\n",
      "[Epoch 17/30-400/1009] [D loss&acc: 0.256, 46.729%] [G loss&accA&accB: 0.005, 3.857%, 99.515%] [Test loss&acc: 0.007, 0.189%, 99.310%] time: 1:54:03.493703\n",
      "[Epoch 17/30-600/1009] [D loss&acc: 0.256, 38.184%] [G loss&accA&accB: 0.003, 12.744%, 99.719%] [Test loss&acc: 0.007, 0.210%, 99.295%] time: 1:55:18.915710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/30-800/1009] [D loss&acc: 0.263, 38.843%] [G loss&accA&accB: 0.005, 11.084%, 99.519%] [Test loss&acc: 0.007, 0.309%, 99.300%] time: 1:56:34.199227\n",
      "[Epoch 17/30-1000/1009] [D loss&acc: 0.258, 30.396%] [G loss&accA&accB: 0.004, 13.135%, 99.633%] [Test loss&acc: 0.007, 0.249%, 99.309%] time: 1:57:49.840021\n",
      "[Epoch 18/30-0/1009] [D loss&acc: 0.265, 37.646%] [G loss&accA&accB: 0.004, 17.725%, 99.627%] [Test loss&acc: 0.007, 0.299%, 99.299%] time: 1:58:02.475415\n",
      "[Epoch 18/30-200/1009] [D loss&acc: 0.256, 45.605%] [G loss&accA&accB: 0.006, 11.719%, 99.395%] [Test loss&acc: 0.007, 0.101%, 99.305%] time: 1:59:17.817168\n",
      "[Epoch 18/30-400/1009] [D loss&acc: 0.249, 55.762%] [G loss&accA&accB: 0.006, 18.994%, 99.445%] [Test loss&acc: 0.007, 0.212%, 99.304%] time: 2:00:33.266572\n",
      "[Epoch 18/30-600/1009] [D loss&acc: 0.258, 38.477%] [G loss&accA&accB: 0.008, 50.879%, 99.170%] [Test loss&acc: 0.007, 0.164%, 99.309%] time: 2:01:48.848764\n",
      "[Epoch 18/30-800/1009] [D loss&acc: 0.256, 37.573%] [G loss&accA&accB: 0.003, 13.037%, 99.714%] [Test loss&acc: 0.007, 0.152%, 99.310%] time: 2:03:04.085629\n",
      "[Epoch 18/30-1000/1009] [D loss&acc: 0.262, 15.332%] [G loss&accA&accB: 0.007, 60.254%, 99.281%] [Test loss&acc: 0.007, 0.273%, 99.301%] time: 2:04:19.600205\n",
      "[Epoch 19/30-0/1009] [D loss&acc: 0.260, 33.179%] [G loss&accA&accB: 0.005, 62.842%, 99.466%] [Test loss&acc: 0.007, 0.195%, 99.297%] time: 2:04:32.168223\n",
      "[Epoch 19/30-200/1009] [D loss&acc: 0.256, 33.984%] [G loss&accA&accB: 0.005, 10.547%, 99.494%] [Test loss&acc: 0.007, 0.205%, 99.310%] time: 2:05:47.766136\n",
      "[Epoch 19/30-400/1009] [D loss&acc: 0.260, 40.186%] [G loss&accA&accB: 0.007, 77.197%, 99.322%] [Test loss&acc: 0.007, 0.152%, 99.299%] time: 2:07:03.102041\n",
      "[Epoch 19/30-600/1009] [D loss&acc: 0.256, 36.304%] [G loss&accA&accB: 0.004, 8.203%, 99.619%] [Test loss&acc: 0.007, 0.301%, 99.304%] time: 2:08:18.525270\n",
      "[Epoch 19/30-800/1009] [D loss&acc: 0.254, 45.215%] [G loss&accA&accB: 0.003, 72.412%, 99.675%] [Test loss&acc: 0.007, 0.631%, 99.304%] time: 2:09:33.874784\n",
      "[Epoch 19/30-1000/1009] [D loss&acc: 0.261, 46.387%] [G loss&accA&accB: 0.005, 2.100%, 99.484%] [Test loss&acc: 0.007, 0.518%, 99.297%] time: 2:10:49.279548\n",
      "[Epoch 20/30-0/1009] [D loss&acc: 0.255, 48.389%] [G loss&accA&accB: 0.005, 86.035%, 99.491%] [Test loss&acc: 0.007, 0.415%, 99.301%] time: 2:11:01.811151\n",
      "[Epoch 20/30-200/1009] [D loss&acc: 0.257, 38.916%] [G loss&accA&accB: 0.007, 74.170%, 99.347%] [Test loss&acc: 0.007, 0.271%, 99.301%] time: 2:12:17.068087\n",
      "[Epoch 20/30-400/1009] [D loss&acc: 0.259, 41.602%] [G loss&accA&accB: 0.008, 79.004%, 99.233%] [Test loss&acc: 0.008, 0.508%, 99.207%] time: 2:13:32.337707\n",
      "[Epoch 20/30-600/1009] [D loss&acc: 0.260, 47.314%] [G loss&accA&accB: 0.005, 90.918%, 99.476%] [Test loss&acc: 0.007, 0.289%, 99.292%] time: 2:14:47.455824\n",
      "[Epoch 20/30-800/1009] [D loss&acc: 0.255, 35.596%] [G loss&accA&accB: 0.006, 13.623%, 99.438%] [Test loss&acc: 0.007, 0.333%, 99.292%] time: 2:16:02.619851\n",
      "[Epoch 20/30-1000/1009] [D loss&acc: 0.253, 45.776%] [G loss&accA&accB: 0.004, 34.277%, 99.602%] [Test loss&acc: 0.007, 0.210%, 99.303%] time: 2:17:17.740957\n",
      "[Epoch 21/30-0/1009] [D loss&acc: 0.255, 46.045%] [G loss&accA&accB: 0.004, 4.297%, 99.576%] [Test loss&acc: 0.007, 0.207%, 99.308%] time: 2:17:30.308562\n",
      "[Epoch 21/30-200/1009] [D loss&acc: 0.253, 46.826%] [G loss&accA&accB: 0.003, 58.105%, 99.669%] [Test loss&acc: 0.007, 0.340%, 99.299%] time: 2:18:45.404881\n",
      "[Epoch 21/30-400/1009] [D loss&acc: 0.256, 45.630%] [G loss&accA&accB: 0.005, 78.320%, 99.495%] [Test loss&acc: 0.007, 0.096%, 99.299%] time: 2:20:00.645173\n",
      "[Epoch 21/30-600/1009] [D loss&acc: 0.252, 49.243%] [G loss&accA&accB: 0.002, 60.547%, 99.801%] [Test loss&acc: 0.007, 0.169%, 99.303%] time: 2:21:15.630836\n",
      "[Epoch 21/30-800/1009] [D loss&acc: 0.250, 48.950%] [G loss&accA&accB: 0.004, 9.668%, 99.598%] [Test loss&acc: 0.007, 0.261%, 99.309%] time: 2:22:30.722206\n",
      "[Epoch 21/30-1000/1009] [D loss&acc: 0.255, 39.429%] [G loss&accA&accB: 0.002, 16.650%, 99.763%] [Test loss&acc: 0.007, 0.319%, 99.299%] time: 2:23:45.916370\n",
      "[Epoch 22/30-0/1009] [D loss&acc: 0.254, 41.724%] [G loss&accA&accB: 0.005, 59.570%, 99.488%] [Test loss&acc: 0.007, 0.336%, 99.310%] time: 2:23:58.406616\n",
      "[Epoch 22/30-200/1009] [D loss&acc: 0.257, 34.985%] [G loss&accA&accB: 0.006, 69.629%, 99.426%] [Test loss&acc: 0.007, 0.658%, 99.307%] time: 2:25:13.529533\n",
      "[Epoch 22/30-400/1009] [D loss&acc: 0.253, 47.729%] [G loss&accA&accB: 0.004, 4.443%, 99.650%] [Test loss&acc: 0.007, 0.463%, 99.309%] time: 2:26:28.685388\n",
      "[Epoch 22/30-600/1009] [D loss&acc: 0.255, 44.800%] [G loss&accA&accB: 0.007, 76.807%, 99.327%] [Test loss&acc: 0.007, 0.379%, 99.310%] time: 2:27:43.905680\n",
      "[Epoch 22/30-800/1009] [D loss&acc: 0.256, 32.617%] [G loss&accA&accB: 0.005, 54.346%, 99.534%] [Test loss&acc: 0.007, 0.538%, 99.301%] time: 2:28:59.137164\n",
      "[Epoch 22/30-1000/1009] [D loss&acc: 0.253, 35.889%] [G loss&accA&accB: 0.006, 37.988%, 99.417%] [Test loss&acc: 0.007, 0.176%, 99.311%] time: 2:30:14.123809\n",
      "[Epoch 23/30-0/1009] [D loss&acc: 0.259, 42.114%] [G loss&accA&accB: 0.008, 8.447%, 99.161%] [Test loss&acc: 0.007, 0.205%, 99.312%] time: 2:30:26.685890\n",
      "[Epoch 23/30-200/1009] [D loss&acc: 0.248, 66.846%] [G loss&accA&accB: 0.006, 16.846%, 99.436%] [Test loss&acc: 0.007, 0.433%, 99.310%] time: 2:31:41.937088\n",
      "[Epoch 23/30-400/1009] [D loss&acc: 0.255, 46.436%] [G loss&accA&accB: 0.004, 14.355%, 99.637%] [Test loss&acc: 0.007, 0.396%, 99.308%] time: 2:32:58.232190\n",
      "[Epoch 23/30-600/1009] [D loss&acc: 0.253, 46.704%] [G loss&accA&accB: 0.004, 21.338%, 99.560%] [Test loss&acc: 0.007, 0.329%, 99.308%] time: 2:34:13.400822\n",
      "[Epoch 23/30-800/1009] [D loss&acc: 0.254, 42.822%] [G loss&accA&accB: 0.004, 6.543%, 99.570%] [Test loss&acc: 0.007, 0.548%, 99.316%] time: 2:35:28.567395\n",
      "[Epoch 23/30-1000/1009] [D loss&acc: 0.254, 37.109%] [G loss&accA&accB: 0.007, 41.504%, 99.311%] [Test loss&acc: 0.007, 0.504%, 99.303%] time: 2:36:43.813766\n",
      "[Epoch 24/30-0/1009] [D loss&acc: 0.253, 46.924%] [G loss&accA&accB: 0.005, 75.537%, 99.510%] [Test loss&acc: 0.007, 0.415%, 99.307%] time: 2:36:56.344703\n",
      "[Epoch 24/30-200/1009] [D loss&acc: 0.256, 39.990%] [G loss&accA&accB: 0.004, 17.285%, 99.612%] [Test loss&acc: 0.007, 0.602%, 99.308%] time: 2:38:11.534513\n",
      "[Epoch 24/30-400/1009] [D loss&acc: 0.252, 46.875%] [G loss&accA&accB: 0.003, 14.209%, 99.687%] [Test loss&acc: 0.007, 0.539%, 99.301%] time: 2:39:26.707310\n",
      "[Epoch 24/30-600/1009] [D loss&acc: 0.254, 40.552%] [G loss&accA&accB: 0.011, 47.852%, 98.933%] [Test loss&acc: 0.007, 0.767%, 99.302%] time: 2:40:41.877820\n",
      "[Epoch 24/30-800/1009] [D loss&acc: 0.253, 45.288%] [G loss&accA&accB: 0.005, 13.281%, 99.513%] [Test loss&acc: 0.007, 0.527%, 99.304%] time: 2:41:56.990029\n",
      "[Epoch 24/30-1000/1009] [D loss&acc: 0.248, 55.957%] [G loss&accA&accB: 0.004, 66.650%, 99.586%] [Test loss&acc: 0.007, 0.611%, 99.290%] time: 2:43:12.485376\n",
      "[Epoch 25/30-0/1009] [D loss&acc: 0.255, 38.232%] [G loss&accA&accB: 0.004, 57.080%, 99.565%] [Test loss&acc: 0.007, 0.540%, 99.310%] time: 2:43:25.070678\n",
      "[Epoch 25/30-200/1009] [D loss&acc: 0.253, 45.410%] [G loss&accA&accB: 0.004, 60.547%, 99.576%] [Test loss&acc: 0.007, 0.511%, 99.307%] time: 2:44:40.274197\n",
      "[Epoch 25/30-400/1009] [D loss&acc: 0.256, 30.664%] [G loss&accA&accB: 0.004, 24.658%, 99.604%] [Test loss&acc: 0.007, 0.632%, 99.299%] time: 2:45:55.416304\n",
      "[Epoch 25/30-600/1009] [D loss&acc: 0.259, 47.412%] [G loss&accA&accB: 0.004, 19.385%, 99.598%] [Test loss&acc: 0.007, 1.138%, 99.299%] time: 2:47:10.538317\n",
      "[Epoch 25/30-800/1009] [D loss&acc: 0.254, 42.627%] [G loss&accA&accB: 0.005, 46.338%, 99.504%] [Test loss&acc: 0.007, 0.976%, 99.311%] time: 2:48:25.743940\n",
      "[Epoch 25/30-1000/1009] [D loss&acc: 0.252, 48.730%] [G loss&accA&accB: 0.004, 33.936%, 99.575%] [Test loss&acc: 0.007, 0.913%, 99.309%] time: 2:49:40.888022\n",
      "[Epoch 26/30-0/1009] [D loss&acc: 0.256, 46.899%] [G loss&accA&accB: 0.003, 16.699%, 99.690%] [Test loss&acc: 0.007, 0.893%, 99.299%] time: 2:49:53.461191\n",
      "[Epoch 26/30-200/1009] [D loss&acc: 0.252, 48.975%] [G loss&accA&accB: 0.005, 55.225%, 99.494%] [Test loss&acc: 0.007, 1.060%, 99.307%] time: 2:51:08.461132\n",
      "[Epoch 26/30-400/1009] [D loss&acc: 0.256, 40.039%] [G loss&accA&accB: 0.005, 65.674%, 99.492%] [Test loss&acc: 0.007, 0.996%, 99.311%] time: 2:52:23.630653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/30-600/1009] [D loss&acc: 0.253, 43.799%] [G loss&accA&accB: 0.010, 43.115%, 99.001%] [Test loss&acc: 0.007, 0.847%, 99.310%] time: 2:53:38.856769\n",
      "[Epoch 26/30-800/1009] [D loss&acc: 0.254, 40.479%] [G loss&accA&accB: 0.004, 27.441%, 99.566%] [Test loss&acc: 0.007, 1.073%, 99.309%] time: 2:54:53.927340\n",
      "[Epoch 26/30-1000/1009] [D loss&acc: 0.253, 45.801%] [G loss&accA&accB: 0.005, 51.758%, 99.535%] [Test loss&acc: 0.007, 0.708%, 99.307%] time: 2:56:08.951210\n",
      "[Epoch 27/30-0/1009] [D loss&acc: 0.252, 47.144%] [G loss&accA&accB: 0.004, 46.729%, 99.566%] [Test loss&acc: 0.007, 0.670%, 99.307%] time: 2:56:21.589060\n",
      "[Epoch 27/30-200/1009] [D loss&acc: 0.253, 44.995%] [G loss&accA&accB: 0.004, 15.430%, 99.629%] [Test loss&acc: 0.007, 0.675%, 99.304%] time: 2:57:36.766267\n",
      "[Epoch 27/30-400/1009] [D loss&acc: 0.253, 47.437%] [G loss&accA&accB: 0.005, 71.191%, 99.488%] [Test loss&acc: 0.007, 0.620%, 99.296%] time: 2:58:51.843325\n",
      "[Epoch 27/30-600/1009] [D loss&acc: 0.254, 38.135%] [G loss&accA&accB: 0.009, 19.824%, 99.072%] [Test loss&acc: 0.007, 0.684%, 99.305%] time: 3:00:07.069357\n",
      "[Epoch 27/30-800/1009] [D loss&acc: 0.254, 42.310%] [G loss&accA&accB: 0.004, 20.020%, 99.572%] [Test loss&acc: 0.007, 0.685%, 99.300%] time: 3:01:22.117023\n",
      "[Epoch 27/30-1000/1009] [D loss&acc: 0.256, 42.944%] [G loss&accA&accB: 0.005, 17.480%, 99.548%] [Test loss&acc: 0.007, 0.779%, 99.308%] time: 3:02:37.254688\n",
      "[Epoch 28/30-0/1009] [D loss&acc: 0.256, 36.865%] [G loss&accA&accB: 0.006, 65.234%, 99.383%] [Test loss&acc: 0.007, 0.886%, 99.304%] time: 3:02:49.872674\n",
      "[Epoch 28/30-200/1009] [D loss&acc: 0.255, 37.842%] [G loss&accA&accB: 0.003, 61.426%, 99.669%] [Test loss&acc: 0.007, 0.588%, 99.310%] time: 3:04:04.825594\n",
      "[Epoch 28/30-400/1009] [D loss&acc: 0.258, 40.015%] [G loss&accA&accB: 0.004, 42.285%, 99.614%] [Test loss&acc: 0.007, 0.973%, 99.301%] time: 3:05:19.913886\n",
      "[Epoch 28/30-600/1009] [D loss&acc: 0.253, 42.090%] [G loss&accA&accB: 0.007, 34.375%, 99.308%] [Test loss&acc: 0.007, 0.734%, 99.298%] time: 3:06:35.000618\n",
      "[Epoch 28/30-800/1009] [D loss&acc: 0.253, 39.331%] [G loss&accA&accB: 0.007, 25.830%, 99.259%] [Test loss&acc: 0.007, 0.743%, 99.309%] time: 3:07:50.260735\n",
      "[Epoch 28/30-1000/1009] [D loss&acc: 0.256, 46.094%] [G loss&accA&accB: 0.007, 83.350%, 99.288%] [Test loss&acc: 0.007, 0.838%, 99.301%] time: 3:09:05.386921\n",
      "[Epoch 29/30-0/1009] [D loss&acc: 0.256, 33.911%] [G loss&accA&accB: 0.004, 23.486%, 99.620%] [Test loss&acc: 0.007, 0.686%, 99.309%] time: 3:09:17.883033\n",
      "[Epoch 29/30-200/1009] [D loss&acc: 0.242, 78.296%] [G loss&accA&accB: 0.004, 12.891%, 99.625%] [Test loss&acc: 0.007, 0.571%, 99.309%] time: 3:10:32.980961\n",
      "[Epoch 29/30-400/1009] [D loss&acc: 0.249, 50.073%] [G loss&accA&accB: 0.004, 18.799%, 99.636%] [Test loss&acc: 0.007, 0.400%, 99.307%] time: 3:11:48.255157\n",
      "[Epoch 29/30-600/1009] [D loss&acc: 0.255, 28.809%] [G loss&accA&accB: 0.003, 26.318%, 99.704%] [Test loss&acc: 0.007, 0.763%, 99.286%] time: 3:13:03.297802\n",
      "[Epoch 29/30-800/1009] [D loss&acc: 0.253, 47.217%] [G loss&accA&accB: 0.002, 7.568%, 99.759%] [Test loss&acc: 0.007, 0.663%, 99.307%] time: 3:14:18.329837\n",
      "[Epoch 29/30-1000/1009] [D loss&acc: 0.254, 39.990%] [G loss&accA&accB: 0.005, 17.334%, 99.544%] [Test loss&acc: 0.007, 0.737%, 99.289%] time: 3:15:33.388976\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = EL_GAN() # 24 Epochs\n",
    "    gan.train(x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath, epochs=30, batch_size=32, sample_interval=200)\n",
    "    #gan.train_generator_only(x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    def IoUcheck(img_input, img_output):\n",
    "\n",
    "        logic_and = np.sum(np.logical_and(img_output, img_input))\n",
    "        logic_or = np.sum(np.logical_or(img_output, img_input))\n",
    "\n",
    "        return logic_and/logic_or\n",
    "    \n",
    "    def rescaleImg(image_arr):\n",
    "    \n",
    "        if image_arr.shape[0] % 8 != 0:\n",
    "            n = image_arr.shape[0] % 8\n",
    "            new_x = image_arr.shape[0] - n\n",
    "        else:\n",
    "            new_x = image_arr.shape[0]\n",
    "\n",
    "        if image_arr.shape[1] % 8 != 0:\n",
    "            n = image_arr.shape[1] % 8\n",
    "            new_y = image_arr.shape[1] - n\n",
    "        else:\n",
    "            new_y = image_arr.shape[1]\n",
    "\n",
    "        image_arr = image_arr[:new_x, :new_y]\n",
    "\n",
    "        return image_arr\n",
    "    \n",
    "    def update_model_to_any_size(old_model):\n",
    "    \n",
    "        old_model.layers.pop(0)\n",
    "        \n",
    "        newInput = Input(shape=(None, None, 1)) # New image input\n",
    "        newOutputs = old_model(newInput)\n",
    "        newModel = Model(newInput, newOutputs)\n",
    "        #newModel.summary()\n",
    "\n",
    "        return newModel\n",
    "    \n",
    "    def evaluate(image_arrA, image_arrB):\n",
    "        \n",
    "        Accuracy = accuracy_score(image_arrB.flatten().astype(bool), \n",
    "                                  image_arrA.flatten().astype(bool))\n",
    "\n",
    "        IntOverUnion = IoUcheck(image_arrB.flatten().astype(bool), \n",
    "                                image_arrA.flatten().astype(bool))\n",
    "\n",
    "        print('accuracy:', Accuracy)\n",
    "        print('IoU:', IntOverUnion)\n",
    "        return Accuracy, IntOverUnion\n",
    "        \n",
    "    def model_predict(newModel, input_image, num_runs):\n",
    "        m,n = input_image.shape\n",
    "        \n",
    "        for i in range(num_runs):\n",
    "            input_image = np.reshape(input_image, (1, m, n, 1))\n",
    "            conc2 = newModel.predict([input_image])\n",
    "            input_image = np.reshape(conc2,(m, n))\n",
    "\n",
    "        return input_image\n",
    "    \n",
    "    def save_prediction(output_image, fn_input, subfix):\n",
    "        fig = plt.figure(figsize=(output_image.shape[1] / 1000, output_image.shape[0] / 1000), dpi=100, frameon=False)\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "\n",
    "        plt.imshow(output_image, cmap='gray')\n",
    "        #plt.imshow(output_image)\n",
    "        fig.savefig(outPath + fn_input[:-4] + subfix, dpi=1000)\n",
    "\n",
    "    def predict_15k_examples(testPath, fn_input, fn_target, nr = 1):\n",
    "    \n",
    "        image_arrA = readImg(testPath + fn_input)\n",
    "        image_arrB = readImg(testPath + fn_target)\n",
    "\n",
    "        print(\"15k\", 'Example: ')\n",
    "        acc_orig, iou_orig = evaluate(image_arrA, image_arrB)\n",
    "\n",
    "        image_arr = readImg(testPath + fn_input)\n",
    "        image_arr = rescaleImg(image_arr)\n",
    "\n",
    "        image_tar = readImg(testPath + fn_target)\n",
    "        image_tar = rescaleImg(image_tar)\n",
    "\n",
    "        newModel = update_model_to_any_size(gan.generator)\n",
    "        output_image = model_predict(newModel, image_arr, num_runs = nr)\n",
    "\n",
    "        print(\"- 15k\", 'Prediction: ')\n",
    "        acc_pred, iou_pred = evaluate(output_image > 0.5, image_tar)\n",
    "\n",
    "        save_prediction(output_image, fn_input, '_' + str(nr) + '_out.png')\n",
    "\n",
    "        return [[acc_orig, iou_orig], [acc_pred, iou_pred]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15k Example: \n",
      "accuracy: 0.9764130991339968\n",
      "IoU: 0.885579034522481\n",
      "- 15k Prediction: \n",
      "accuracy: 0.990534420289855\n",
      "IoU: 0.9533386667658933\n",
      "15k Example: \n",
      "accuracy: 0.982896331738437\n",
      "IoU: 0.9261015173858516\n",
      "- 15k Prediction: \n",
      "accuracy: 0.9934314257650951\n",
      "IoU: 0.9712568924077478\n",
      "15k Example: \n",
      "accuracy: 0.9764130991339968\n",
      "IoU: 0.885579034522481\n",
      "- 15k Prediction: \n",
      "accuracy: 0.9893983997584541\n",
      "IoU: 0.9477434237452097\n",
      "15k Example: \n",
      "accuracy: 0.982896331738437\n",
      "IoU: 0.9261015173858516\n",
      "- 15k Prediction: \n",
      "accuracy: 0.9923328939205955\n",
      "IoU: 0.9665652210668696\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHcAAABhCAYAAADstj4MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAA25JREFUeJztnFuO4yAQRWEUKb9ZWDaRrWRjWUgWEuUjYn7iEWIAF49y4HKP1FKrB2PkQ0EZ8FjnnCGY/Pl1A4gelAsM5QJDucBQLjCUCwzlAkO5wFAuMJQLDOUCQ7nAUC4wlAvM6dcNqMVau7tX6W9nWmtV29Mb51xzg6EjdxM6mtij9tCnjVwpLWJ7RH6qDueceqeDl3sUKYmhQL/cJlhLNPSw3BPnXJfh1FobnS561e/DyP0SPtjSSKotr5n0LSH3iKw5FXV794tJ7sUScmvp2RE2eak6NTrdEnIlD6714cauv91uxph4EnUEdtZzy5JFjNEIozcnuscixhKRm6J2nqwlVq9mJEPLbc2AW6/fY3vH1QJabvjwwigJM1Xpw46VqRWfW+RoBVauc87c7/emaJPMjSMzbUJljPnX8NRclvq3WDlJ2dg14bXS+wruse6uULh05yPtsJode1tOjP1cr1e1+/pMG7m5V6GaqJWUlyJ5poK2rRu5KVIPNrYwr5nMxNg2DbbELXY/JlQZjlzeK2lDrtNpASG3x8aAtvyw/thrF3eFAmJiSzJWSZleGfDRQM+52+97G+GxjDZWn+Tej8dDvPHuz8EaHWf6bDkXudvf9oZtyXtr6tr3+20ul4t5vV5dh9ke2fL0ciW0DKs1HSNXvuC+3BXao2RBIyajRJDGalgLcHJrhkZ/bt6LzljWOypwckOk0TKypFrgsuWazFN6iG02YCO39HR/Lul6Pp99G3cQS2TLEnouVIyycQAbuaXMOvTmoNwvpZGrvS7cA8r90nJY7fP5/FfXCMBlyy3USjmdxoyRZeTOmji2sIxcY/oKHmXozTHmeNIZzY2DrUzqTPQvWSJyU+vFmpGs8TF1KdByJVF3Pp+r6w8320eIVh/YYTm30zPrsZlSIJcfa77lGU04lx8LyMkr7eA9PwTTBG7OLT14fvTpiCOBkxt7HUn990DhdSWnFkNGyI5DIIflkq8O0KLVB1KuBOkG/gifp9QCNyxLSB1W94dvv8ysLCnXZy8yZ4jQFNO+55J9lo9cZCgXGMoFhnKBoVxgKBcYygWGcoGhXGAoFxjKBYZygaFcYCgXGMoFhnKBoVxgKBcYygWGcoGhXGAoFxjKBYZygaFcYCgXGMoFhnKBoVxgKBcYygWGcoGhXGD+AlJD6HDGW6XGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3f7f8f2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIUAAABaCAYAAACWspXGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAA3RJREFUeJztnFtu6yAQQKHO/peVVcWiX24thsfwcgw+R6rUONeYhuPxMJBrnXMG4MzPtzsA9wMpQIAUIEAKECAFCJACBEgBAqQAAVKAAClAgBQgQAoQIAUIkAIEr293oBZrrVjzP28DsNZGX1trh/fvfK2e161pyzlXdOFppfAp2ReSksc/VjOQs+9RWUaKY/Ccc10jQYlA536cf78iMvVkGSkOQoMSe31FH2KE5Eodv5LlpKgh9MH7xzSPBH9gY697sm2b2fe9a5tIoST1KKgZ7Ng5x/F931Xtfj6f4mvkQIqbsm3b165tJ86U3flOSP0dsyV6vXnslFRDTJynS+MzrRSamUVpFMxJ03u6e1emlULDiClpbGZxHLuyajqKpaUopWYaqj039r5WnpSMsWvUghQJcpEmNjATJ+/GGKRoIldrSLHve3Da2evx09IOUnyJ1+vV9HgambOwn6Ijzrm/n5JzzvQabGstFc07Els91Z6rKc6NiBhIMQGayJNb4i9h2sfH+/3++8P9D6A0hPfiCNmtd6/fxrld/2cE0659WGuddk/C+b0nUrr2MW2k8MkN+qzyf4MlcwptZfIpaxmlTC1Fy4D6+Qhy/DO1FD4luUQoQ2+ZQq7EUlKEqN188+RHy/JSGNP3rr+DLKmI2COhXkqKkgQz9O+1m2laHzN3z2OWksIntxsrJ8doQvLdYa/pMnUKLbEPVlsFTX3ZqKYPPcJ9b1mmlqK2nH0uEV/1ZeNUP+9WWFuyzF1L6Jvire2m+lj62cfOVbT5zDL3mVrRR5TKR323deSi2NSR4vh9xB3e2u7IqWvpgt8jF8S0OUJNuK7JPWJL+rX9qKU251pySqoRo+eXgkPt595riSSjk+MlIoWGK+7a0qRydMSozTmmjxQ1d36qYNSa/KUKYjExUkW23MahEdXRqSNFapXTR3vXtN69qeukCme9eeQeTWPCA5BLrkJ3cGzaOGKwQmL0zhFyiW6OJaakxuj+D6mabfahNnswerXV6/vzpqTG6NYkWiqIPauare1paCnjTxspYBzLRAroB1KAAClAgBQgQAoQIAUIkAIESAECpAABUoAAKUCAFCBAChAgBQiQAgRIAQKkAAFSgAApQIAUIEAKECAFCJACBEgBAqQAAVKAAClAgBQgQAoQIAUIkAIESAECpADBL3v8162o3vl3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa488fc7240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHcAAABhCAYAAADstj4MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAAxZJREFUeJztnNtuwyAQBU3V//9l+hJXCIG5LQ4MZ14itYljebzLsuA47/0lmPx8+wTEPCQXjOSCkVwwkgtGcsFILhjJBSO5YCQXjOSCkVwwkgtGcsH8fvsEenHOFdcqw+VM59zU87HGez98wujIvYXuJtaKbSO3lhGxFpGfOsb9t9k3HV7uW+RuhFhg+D7v/eWc+3+1Bp2WLfHeXxZbkpxzyeHC6vghitwP8YVtjaTe988s+o6Q+0bVnIu60velJFtxhNxeLG+EUhE146Zzu25trZnnrkJPytc8dxPCIipkdmAdnZZ7x8lecoJnfR9a7mgFPPr5EvccdxZoufHFi6Mk1TGqudip9/SKf2pyjIKVa9HiC+Xv2J/eVq7V3LUm9bYcf/Smspz3bis3TKFxZNVemJnj3dOx38oC28q9rvruz5vfWzNuv5XmcfPc3IVNNeZnFjMp7vnuk1gVVA+82d5rOYdY2hudQYRci+Jqtvz4+Kn0rVWhiNGdDpV93ur3rsT2cmNyOx2uKy/nqSnRkj5bC6XZNwuuoHqrWMkd8y7cVlht2z5yW5oOs4qtFUSm2F5uiZaGxkh3qmXsbjnuCDi5nQvj/6+laUyq6l0VnNyY2mhZWVIvyILKeufiruKxkRsvJJQEPU2XVi2YSmDlhoxG3ugOjm9xhNwadk29T0juh9YW4+y+sAWS+8Fys9oqonHV8girrij1cozcVYqcNzlG7nXZCl41WkOOGHNH1mNrOlyW+5gtOSJyc42J2bsfvz0UoCM37ExNeURy8W4WNnLDlZ7c/1ZInTNBPp/bMwauJtzi+Vx0Wg6xXBhYtYCKwaXl1o3nO//KXAmc3NQjmrmfB4o/V1vhfqP67gGZlls2wtGiNQQpt4baBfwVHk/pBZeWawinSfGYG29GXy3VtnCk3JBSZO4QoTm2neeKMsdHLhnJBSO5YCQXjOSCkVwwkgtGcsFILhjJBSO5YCQXjOSCkVwwkgtGcsFILhjJBSO5YCQXjOSCkVwwkgtGcsFILhjJBSO5YCQXjOSCkVwwkgtGcsFILpg/l1R1SJPb514AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3feda8dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIUAAABaCAYAAACWspXGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAA1BJREFUeJztnNuO4yAQBc1q//+X2SevEIdLc3MMrpJGmiQTjEy53TR4nPf+Agj58+sOwPtAChCQAgSkAAEpQEAKEJACBKQAASlAQAoQkAIEpAABKUBAChD+/roDvTjnZM0/3AbgnMu+ds4t7194rJnH7WnLe9904G2liGnZF1KSJ36vZyB336NyjBT34Hnvp0aCFoHCfoS/PxGZZnKMFDepQcm9fqIPOVJyld5/kuOk6CF14uP3LLeEeGBzr98OUhgp3Qp6Bjv3nVzEyFH6u14JkeKl/DKquI0zZR+euBVXzCl8dkpqISfO16WJ2VYKy8yiNQrWpJk93X0r20phYcWUNDezuN/bbaaR4mgpWumZhlq/m/vcKk9JxtwxekGKArVIkxuYjZP367qQYoharaGHWbefkXaQYhOeLNmzn2Ii3vv/Py3fCZk12M45KppvJLd6OtpWyIqIgRQ/opaQhjURS+SpLfG3sLUU94mLi0q/qhXMDP0r2jUff9fpk3POW/ckhJ99kda1j2MSzdqg7yr/L9j69pHDWpn8ylpGK1tLMaNIdMJaxWy2liKmJZdIZegzp5A7c5QUKXo333z51nK8FNc196p/gyyliDgjoT5KipYEM/X31s00o7eZt+cxR0kRU9uNVZNjNSn53rDX9Jg6hZXcibUuZJUeNurpw4xwP1uWraVoXZG8CVcQn3rYuLbO8SaOLHP3knpSfLTdUh9bz33uu4Y2v1nmDukVfUWpfNWzrXe0WxHpto4U9+8rrvDRdldOXVsX/D65IGbNEXrCdU/uEZfQR/vRS2/OdeSU1CLGzIeCU+3XPhuJJKuT4yMihYUnrtrWpHJ1xOjNObaPFD1XfqlgNJr8lQpiOTFKRbbaxqEV1dGtI0VplTPGetWMXr2l45QKZ7MZaXNrKVIDUEuuUldwbtq4YrBSYszOEWqJbo0jpqTXZfsfUq0nf9UzGXfbKxPGqO/fm5Jel21NYuQCmFnVHG3PwkgZf9tIAes4JlLAPJACBKQAASlAQAoQkAIEpAABKUBAChCQAgSkAAEpQEAKEJACBKQAASlAQAoQkAIEpAABKUBAChCQAgSkAAEpQEAKEJACBKQAASlAQAoQkAIEpAABKUBAChD+AU0wzEiOLYP3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa4139110f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testPath = r\"../tmp_data/Data/Testing/\"\n",
    "all_records = []\n",
    "    \n",
    "records = predict_15k_examples(testPath, r\"FTest1_input_inv.png\", r\"FTest1_output_inv.png\", nr = 1)\n",
    "all_records.extend(records)\n",
    "    \n",
    "records = predict_15k_examples(testPath, r\"FTest2_input_inv.png\", r\"FTest2_output_inv.png\", nr = 1)\n",
    "all_records.extend(records)\n",
    "\n",
    "records = predict_15k_examples(testPath, r\"FTest1_input_inv.png\", r\"FTest1_output_inv.png\", nr = 10)\n",
    "all_records.extend(records)\n",
    "    \n",
    "records = predict_15k_examples(testPath, r\"FTest2_input_inv.png\", r\"FTest2_output_inv.png\", nr = 10)\n",
    "all_records.extend(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input vs Target (Test1)</th>\n",
       "      <th>Input vs Target (Test1)</th>\n",
       "      <th>Prediction vs Target (Test1 - 1)</th>\n",
       "      <th>Prediction vs Target (Test1 - 10)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.976413</td>\n",
       "      <td>0.976413</td>\n",
       "      <td>0.990534</td>\n",
       "      <td>0.989398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IoU</th>\n",
       "      <td>0.885579</td>\n",
       "      <td>0.885579</td>\n",
       "      <td>0.953339</td>\n",
       "      <td>0.947743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Input vs Target (Test1)  Input vs Target (Test1)  \\\n",
       "Metrics                                                      \n",
       "Accuracy                 0.976413                 0.976413   \n",
       "IoU                      0.885579                 0.885579   \n",
       "\n",
       "          Prediction vs Target (Test1 - 1)  Prediction vs Target (Test1 - 10)  \n",
       "Metrics                                                                        \n",
       "Accuracy                          0.990534                           0.989398  \n",
       "IoU                               0.953339                           0.947743  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(np.transpose(all_records))\n",
    "df.columns = [\"Input vs Target (Test1)\", \"Prediction vs Target (Test1 - 1)\", \n",
    "              \"Input vs Target (Test2)\", \"Prediction vs Target (Test2 - 1)\",\n",
    "              \"Input vs Target (Test1)\", \"Prediction vs Target (Test1 - 10)\", \n",
    "              \"Input vs Target (Test2)\", \"Prediction vs Target (Test2 - 10)\"]\n",
    "\n",
    "df = df.rename({0: \"Accuracy\", 1: 'IoU'})\n",
    "df.index.name = 'Metrics'\n",
    "\n",
    "df[[\"Input vs Target (Test1)\", \"Prediction vs Target (Test1 - 1)\", \"Prediction vs Target (Test1 - 10)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input vs Target (Test2)</th>\n",
       "      <th>Input vs Target (Test2)</th>\n",
       "      <th>Prediction vs Target (Test2 - 1)</th>\n",
       "      <th>Prediction vs Target (Test2 - 10)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.982896</td>\n",
       "      <td>0.982896</td>\n",
       "      <td>0.993431</td>\n",
       "      <td>0.992333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IoU</th>\n",
       "      <td>0.926102</td>\n",
       "      <td>0.926102</td>\n",
       "      <td>0.971257</td>\n",
       "      <td>0.966565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Input vs Target (Test2)  Input vs Target (Test2)  \\\n",
       "Metrics                                                      \n",
       "Accuracy                 0.982896                 0.982896   \n",
       "IoU                      0.926102                 0.926102   \n",
       "\n",
       "          Prediction vs Target (Test2 - 1)  Prediction vs Target (Test2 - 10)  \n",
       "Metrics                                                                        \n",
       "Accuracy                          0.993431                           0.992333  \n",
       "IoU                               0.971257                           0.966565  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Input vs Target (Test2)\", \"Prediction vs Target (Test2 - 1)\", \"Prediction vs Target (Test2 - 10)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "activation_1 (Activation)       (None, 128, 128, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 32) 9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 32) 0           batch_normalization_2[0][0]      \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   18496       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 128)  73856       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 128)  8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           batch_normalization_8[0][0]      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 256)  295168      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 256)  33024       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 256)  590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 256)  0           batch_normalization_11[0][0]     \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 256)  590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 256)  65792       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 256)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 256)  1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 256)  590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           batch_normalization_14[0][0]     \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 384)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 384)  1536        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 384)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 128)  442496      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 128)  49280       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 128)  0           batch_normalization_17[0][0]     \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 192)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 192)  768         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 192)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 64)   110656      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 64)   12352       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 64)   0           batch_normalization_20[0][0]     \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 96) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128, 128, 96) 384         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 96) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 32) 27680       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 32) 128         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 32) 3104        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 32) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128, 128, 32) 128         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 32) 9248        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 128, 128, 32) 0           batch_normalization_23[0][0]     \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 1)  33          add_8[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,312,289\n",
      "Trainable params: 3,306,209\n",
      "Non-trainable params: 6,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 1)           4609      \n",
      "=================================================================\n",
      "Total params: 1,558,017\n",
      "Trainable params: 1,556,225\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
