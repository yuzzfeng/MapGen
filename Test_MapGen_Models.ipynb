{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Add, Lambda\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop, Adadelta\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, History\n",
    "\n",
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from mapgenlib.res_unit import build_res_unet\n",
    "from mapgenlib.losses_extend import dice_coef_loss, iou_loss, binary_focal_loss\n",
    "from mapgenlib.read_write import check_and_create, load_data, load_batch, save_hist, save_hist_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN4MapGen(): # Based on u-net, residual u-net and pix2pix\n",
    "    # Reference: https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py\n",
    "    \n",
    "    def __init__(self, img_rows, img_cols):\n",
    "\n",
    "        # Input shape\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        self.clip_value = 0.01\n",
    "        \n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'mapgen'\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN) better version\n",
    "        self.patch_size = 32\n",
    "        self.nb_patches = int((self.img_rows / self.patch_size) * (self.img_cols / self.patch_size))\n",
    "        self.patch_gan_dim = (self.patch_size, self.patch_size, self.channels)\n",
    "        \n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        self.df = 64\n",
    "        optimizer = Adam(0.0004)\n",
    "        \n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        #self.generator = self.build_generator() # Old generator from \n",
    "        self.generator = self.build_res_unet_generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        #img_A = Input(shape=self.img_shape) # Target\n",
    "        img_B = Input(shape=self.img_shape) # Input\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        fake_A = self.generator(img_B)\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        #self.discriminator = self.build_discriminator() # 1.Version\n",
    "        self.discriminator = self.build_discriminator_patchgan()\n",
    "        \n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "        #self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        #valid = self.discriminator([fake_A, img_B])\n",
    "        #self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "        \n",
    "        valid = self.discriminator([fake_A])\n",
    "        self.combined = Model(inputs= img_B, outputs=[valid, fake_A])\n",
    "        \n",
    "        # Original Pix2Pix - low weight for discriminator\n",
    "        self.combined.compile(loss=['mse', 'mae'], #['mse', 'mae'] original\n",
    "                              loss_weights=[1, 100], # [1, 100] original\n",
    "                              optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    def build_res_unet_generator(self):\n",
    "        return build_res_unet(self.img_shape)\n",
    "        \n",
    "        \"\"\"Residual U-Net Generator\"\"\"\n",
    "        \"\"\"\n",
    "        inputs = Input(shape=self.img_shape)\n",
    "        to_decoder = encoder(inputs)\n",
    "        path = res_block(to_decoder[2], [256, 256], [(2, 2), (1, 1)], increase = True) # 3x\n",
    "        path = res_block(path, [256, 256], [(1, 1), (1, 1)]) # Number of block of bottleneck = 1\n",
    "        path = res_block(path, [256, 256], [(1, 1), (1, 1)]) # Try to add one 2019.01.14, achieved best result ever\n",
    "        path = decoder(path, from_encoder=to_decoder)\n",
    "        path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path) \n",
    "        return Model(input=inputs, output=path)\n",
    "        \"\"\"\n",
    "        \n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, self.gf*8)\n",
    "        u2 = deconv2d(u1, d5, self.gf*8)\n",
    "        u3 = deconv2d(u2, d4, self.gf*8)\n",
    "        u4 = deconv2d(u3, d3, self.gf*4)\n",
    "        u5 = deconv2d(u4, d2, self.gf*2)\n",
    "        u6 = deconv2d(u5, d1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "    \n",
    "    def build_discriminator_simple(self):\n",
    "\n",
    "        def d_block(layer_input, filters, strides=1, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        # Input img\n",
    "        d0 = Input(shape=self.hr_shape)\n",
    "\n",
    "        d1 = d_block(d0, self.df, bn=False)\n",
    "        d2 = d_block(d1, self.df, strides=2)\n",
    "        d3 = d_block(d2, self.df*2)\n",
    "        d4 = d_block(d3, self.df*2, strides=2)\n",
    "        d5 = d_block(d4, self.df*4)\n",
    "        d6 = d_block(d5, self.df*4, strides=2)\n",
    "        d7 = d_block(d6, self.df*8)\n",
    "        d8 = d_block(d7, self.df*8, strides=2)\n",
    "\n",
    "        d9 = Dense(self.df*16)(d8)\n",
    "        d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "        validity = Dense(1, activation='sigmoid')(d10)\n",
    "\n",
    "        return Model(d0, validity)\n",
    "    \n",
    "    def build_discriminator_patchgan(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if normalization:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        d1 = d_layer(img, self.df, normalization=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model(img, validity)\n",
    "        \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=3, bn=True): # Chnaged here for the order of bn and activation\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Activation(activation='relu')(d)\n",
    "            #d = LeakyReLU(alpha=0.2)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        \n",
    "        # !!!! This step was deleted because the condition do not help in this case\n",
    "        #img_B = Input(shape=self.img_shape)\n",
    "        ## Concatenate image and conditioning image by channels to produce input\n",
    "        #combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "        #d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        \n",
    "        d1 = d_layer(img_A, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A], validity)\n",
    "    \n",
    "    def train_generator_only(self, x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath):\n",
    "        \n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        gen = self.build_res_unet_generator()\n",
    "        optimizer = Adam(0.0004) # Current best\n",
    "        \n",
    "        # Loss function finished\n",
    "        gen.compile(loss='mse', optimizer=optimizer, metrics=['accuracy']) # mse better than mae\n",
    "\n",
    "        data_gen_args = dict(rotation_range=180.)\n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        \n",
    "        seed = 2\n",
    "        BATCH_SIZE = 16 # Proper for 128x128\n",
    "        result_generator = zip(image_datagen.flow(x_train_sim, batch_size=BATCH_SIZE, seed=seed), \n",
    "                               mask_datagen.flow(y_train_sim, batch_size=BATCH_SIZE, seed=seed))\n",
    "        \n",
    "        History1 = History()\n",
    "        hist1 = gen.fit_generator(result_generator,\n",
    "                                  epochs = 100,\n",
    "                                  steps_per_epoch=2000,\n",
    "                                  verbose=1,\n",
    "                                  shuffle=True,\n",
    "                                  callbacks=[History1, \n",
    "                                             EarlyStopping(patience=4), \n",
    "                                             ReduceLROnPlateau(patience = 3, verbose = 0),\n",
    "                                             ModelCheckpoint(outPath + \"weights.h5\", \n",
    "                                                             save_best_only = True, \n",
    "                                                             save_weights_only = False)],\n",
    "                                  validation_data=(x_test_sim, y_test_sim))\n",
    "        save_hist(History1, outPath)\n",
    "        \n",
    "    \n",
    "    def train(self, x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        \n",
    "        total_samples = len(x_train_sim)\n",
    "        ids = np.arange(total_samples)\n",
    "        np.random.shuffle(ids)\n",
    "        n_batches = int(total_samples / batch_size)\n",
    "        \n",
    "        train_acc = []\n",
    "        train_loss = []\n",
    "        valid_acc = []\n",
    "        valid_loss = []\n",
    "        \n",
    "        patience = 5\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(load_batch(x_train_sim, y_train_sim, batch_size)):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Condition on B and generate a translated version\n",
    "                fake_A = self.generator.predict(imgs_B)\n",
    "                \n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs_A], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([fake_A], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                \n",
    "                ## Clip critic weights\n",
    "                #for l in self.discriminator.layers:\n",
    "                #    weights = l.get_weights()\n",
    "                #    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                #    l.set_weights(weights)\n",
    "\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                # Train the generators\n",
    "                self.discriminator.trainable = False\n",
    "                g_loss = self.combined.train_on_batch(imgs_B, [valid, imgs_A])\n",
    "                self.discriminator.trainable = True\n",
    "                \n",
    "                if batch_i % sample_interval == 0:\n",
    "                    elapsed_time = datetime.datetime.now() - start_time\n",
    "                    print (\"[Epoch %d/%d-%d/%d] [D loss&acc: %.3f, %.3f%%] [G loss&accA&accB: %.3f, %.3f%%, %.3f%%] time: %s\" % (epoch, epochs,\n",
    "                                                                                batch_i, n_batches,\n",
    "                                                                                d_loss[0], 100*d_loss[1],\n",
    "                                                                                100*g_loss[2], 100*g_loss[3], 100*g_loss[4],\n",
    "                                                                                elapsed_time))    \n",
    "                \n",
    "            # Plot the progress\n",
    "            if epoch >= 0:\n",
    "                    \n",
    "                    elapsed_time = datetime.datetime.now() - start_time\n",
    "                    \n",
    "                    valid_test = np.ones((len(x_test_sim),) + self.disc_patch)\n",
    "                    t_loss = self.combined.evaluate(x_test_sim, [valid_test, y_test_sim], verbose=0)\n",
    "                    \n",
    "                    print (\"[Epoch %d/%d-%d/%d] [D loss&acc: %.3f, %.3f%%] [G loss&accA&accB: %.3f, %.3f%%, %.3f%%] [Test loss&acc: %.3f, %.3f%%, %.3f%%] time: %s\" % (epoch, epochs,\n",
    "                                                                                batch_i, n_batches,\n",
    "                                                                                d_loss[0], 100*d_loss[1],\n",
    "                                                                                100*g_loss[2], 100*g_loss[3], 100*g_loss[4],\n",
    "                                                                                100*t_loss[2], 100*t_loss[3], 100*t_loss[4],\n",
    "                                                                                elapsed_time))    \n",
    "                    \n",
    "                    train_loss.append(g_loss[2])\n",
    "                    train_acc.append(g_loss[4])\n",
    "                    valid_loss.append(t_loss[2])\n",
    "                    valid_acc.append(t_loss[4])\n",
    "\n",
    "                    waited = len(valid_loss) - 1 - np.argmin(valid_loss)\n",
    "                    print('waited for', waited, valid_loss)\n",
    "                    \n",
    "                    if waited == 0:\n",
    "                        self.generator.save(outPath + 'model_epoch'+ str(epoch) +'.h5')   \n",
    "                        \n",
    "                    if waited > patience:\n",
    "                        break\n",
    "            \n",
    "        return train_acc, train_loss, valid_acc, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape of the trains (10268, 256, 256, 1)\n",
      "Input Shape of the tests (1140, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Order the image dimension acc. to TensorFlow (batc_hsize, rows, cols, channels)\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "#scale = 25\n",
    "#p_size_1 = 128 # Compared with 256, which larger may generate round corners\n",
    "\n",
    "scale = 10\n",
    "p_size_1 = 256 # Larger inception area\n",
    "\n",
    "trainPath = r\"../tmp_data/data_feng_\"+str(p_size_1)+\"/geb\" + str(scale) +  \"/\"\n",
    "x_train_sim, y_train_sim, x_test_sim, y_test_sim = load_data(trainPath)\n",
    "\n",
    "input_shape1 = (None, None, 1)\n",
    "print('Input Shape of the trains', x_train_sim.shape)\n",
    "print('Input Shape of the tests', x_test_sim.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def load_data(x_test_sim, y_test_sim, batch_size=1):\n",
    "    return x_test_sim  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train residual unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tmp_results/predictions/U256_2019-03-21 14-38-55_10/\n"
     ]
    }
   ],
   "source": [
    "############ Path Setting ##############\n",
    "outPath = r\"../tmp_results/predictions/\"\n",
    "timestr = strftime(\"U\"+str(p_size_1)+\"_%Y-%m-%d %H-%M-%S\", gmtime())\n",
    "outPath = outPath + timestr + '_' + str(scale)+ \"/\"\n",
    "check_and_create(outPath)\n",
    "print(outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/tmp/MapGen/mapgenlib/res_unit.py:96: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  return Model(input=inputs, output=path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 871s 435ms/step - loss: 0.0039 - acc: 0.9762 - val_loss: 0.0044 - val_acc: 0.9952\n",
      "Epoch 2/100\n",
      "1783/2000 [=========================>....] - ETA: 1:31 - loss: 0.0029 - acc: 0.9772"
     ]
    }
   ],
   "source": [
    "gan = GAN4MapGen(p_size_1, p_size_1)\n",
    "gan.train_generator_only(x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train residual unet + PatchGAN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "############ Path Setting ##############\n",
    "outPath = r\"../tmp_results/predictions/\"\n",
    "timestr = strftime(\"U\"+str(p_size_1)+\"GAN_%Y-%m-%d %H-%M-%S\", gmtime())\n",
    "outPath = outPath + timestr + '_' + str(scale)+ \"/\"\n",
    "check_and_create(outPath)\n",
    "print(outPath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gan = GAN4MapGen(128,128)\n",
    "train_acc, train_loss, valid_acc, valid_loss = gan.train(x_train_sim, y_train_sim, x_test_sim, y_test_sim, outPath, epochs=50, batch_size=16, sample_interval=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_hist_local(train_acc, train_loss, valid_acc, valid_loss, outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
