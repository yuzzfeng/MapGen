{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "## Map Generalization for Polygons using Autoencode-like strucutures\n",
    "## Adatped based on Master Thesis of SERCAN CAKIR \"ROAD NETWORK EXTRACTION USING CNN\"\n",
    "## Author: Yu Feng, yuzz.feng@gmail.com\n",
    "## 1. Version Author: SERCAN CAKIR\n",
    "\n",
    "## Changes:\n",
    "## 1. Two conv layers were added before the first down convlusional layer\n",
    "## 2. Output can be any size during the evaluation\n",
    "## 3. Adapt the code to support more images as training examples\n",
    "## 4. Dropouot may make the sharpe corners vanishing, we delete half of them, but we should used some\n",
    "## 5. \n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg') # necessary for linux kernal\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "np.random.seed(7)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History\n",
    "from keras.layers.core import Dropout\n",
    "#from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers import MaxPooling2D, Conv2DTranspose, BatchNormalization, Activation\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Dropout, UpSampling2D, Activation, Concatenate\n",
    "\n",
    "from osgeo import gdal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.util.shape import view_as_windows\n",
    "\n",
    "from data_helper import readImg, readImgInv, imagePatches, removeBlackImg, removeCorrespondence\n",
    "\n",
    "from time import gmtime, strftime\n",
    "timestr = strftime(\"%Y-%m-%d %H-%M-%S\", gmtime())\n",
    "\n",
    "def check_and_create(out_dir):\n",
    "    if os.path.isdir(out_dir) == False:\n",
    "        os.mkdir(out_dir)\n",
    "\n",
    "def prediction_independent(model_ex1, image_arr):\n",
    "    \n",
    "    conc2 = np.reshape(model_ex1.predict(np.reshape(image_arr, (1, image_arr.shape[0], image_arr.shape[1], 1))), \n",
    "                   (image_arr.shape[0], image_arr.shape[1]))\n",
    "    return conc2\n",
    "\n",
    "# cut the image to avoid shape error\n",
    "def cut_image(image_arr):\n",
    "    \n",
    "    print(\"Original:\", image_arr.shape)\n",
    "    \n",
    "    if image_arr.shape[0] % 4 != 0:\n",
    "        n = image_arr.shape[0] % 4\n",
    "        new_x = image_arr.shape[0] - n\n",
    "    else:\n",
    "        new_x = image_arr.shape[0]\n",
    "\n",
    "    if image_arr.shape[1] % 4 != 0:\n",
    "        n = image_arr.shape[1] % 4\n",
    "        new_y = image_arr.shape[1] - n\n",
    "    else:\n",
    "        new_y = image_arr.shape[1]\n",
    "    \n",
    "    image_arr = image_arr[:new_x, :new_y]\n",
    "    print(\"Clipped:\", image_arr.shape)\n",
    "\n",
    "\n",
    "############ Path Setting ##############\n",
    "\n",
    "trainPath = r\"Data/Training_Validation/\"\n",
    "testPath = r\"Data/Testing/\"\n",
    "  \n",
    "tmpPath = r\"../tmp_data/\"\n",
    "\n",
    "outPath = r\"Prediction/\"\n",
    "check_and_create(outPath + timestr)\n",
    "outPath = outPath + timestr + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load a saved model\n",
    "def LoadModel(model_json):\n",
    "    from keras.models import model_from_json\n",
    "    json_file = open(model_json)\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "##### function to calculate evaluation parameters (F1-Score, Precision, Recall) ######\n",
    "def evaluation(model, x_test, y_test, patch_size):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1Score = []\n",
    "    import math\n",
    "    for k in range(len(x_test_sim)):\n",
    "        y_pred = model.predict(x_test_sim[k:k + 1])\n",
    "        y_pred = np.reshape(y_pred, (32 * 32))\n",
    "\n",
    "        y_true = y_test_sim[k:k + 1]\n",
    "        y_true = np.reshape(y_true, (32 * 32))\n",
    "\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        TN = 0\n",
    "\n",
    "        y_pred = np.round(y_pred)\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_true[i] == y_pred[i] == 1:\n",
    "                TP += 1\n",
    "            elif y_pred[i] == y_true[i] == 0:\n",
    "                TN += 1\n",
    "            elif y_pred[i] == 1 and y_true[i] != y_pred[i]:\n",
    "                FP += 1\n",
    "            elif y_pred[i] == 0 and y_true[i] != y_pred[i]:\n",
    "                FN += 1\n",
    "\n",
    "        precision.append(TP / (TP + FP + K.epsilon()))  # completeness\n",
    "        recall.append(TP / (TP + FN))  # correctness\n",
    "        beta = 1\n",
    "        f1Score.append((math.pow(beta, 2) + 1) * TP / ((math.pow(beta, 2) + 1) * TP + math.pow(beta, 2) * FN + FP))\n",
    "        # eval_list = [precision,  recall, f1Score]\n",
    "\n",
    "    avg_precision = sum(precision) / len(precision)\n",
    "    avg_recall = sum(recall) / len(precision)\n",
    "    avg_f1score = sum(f1Score) / len(precision)\n",
    "    avg_eval_param = [avg_precision, avg_recall, avg_f1score]\n",
    "    return avg_eval_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "_EPSILON = 10e-8\n",
    "\n",
    "def IoU(yTrue,yPred):  \n",
    "    \n",
    "    I = tf.multiply(yTrue, yPred, name=\"intersection\")\n",
    "    U = yTrue + yPred - I + _EPSILON\n",
    "    \n",
    "    IoU = tf.reduce_sum(I) / tf.reduce_sum(U)\n",
    "    return -tf.log(IoU + _EPSILON) + binary_crossentropy(yTrue,yPred)\n",
    "    \n",
    "    #IoU = tf.divide(I, U, name='IoU')\n",
    "    #L = -tf.log(IoU + _EPSILON)\n",
    "    #return tf.reduce_mean(L)\n",
    "    \n",
    "    \n",
    "def MSE_CROSS(yTrue,yPred):\n",
    "    return binary_crossentropy(yTrue,yPred) + K.abs(K.sum(yTrue) - K.sum(yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the CNN archÄ±tecture with \"Sequential Model\" (model looks like autoencoder)\n",
    "## Version with batch normalozation - Do not benifit that much\n",
    "\n",
    "def create_model_batch(optimizer, input_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "    droprate = 0.3\n",
    "    \n",
    "    model.add(Conv2D(filters=24, kernel_size=(3, 3),\n",
    "              strides=(1, 1), padding='same',\n",
    "              input_shape=input_shape, kernel_initializer='random_uniform', name=\"flat_conv_a\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Conv2D(filters=24, kernel_size=(3, 3),\n",
    "              strides=(1, 1), padding='same', name=\"flat_conv_b\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    ## Encoding (down-sampling) ###   \n",
    "    model.add(Conv2D(filters=24, kernel_size=(3, 3),\n",
    "                     strides=(2, 2), padding='same',\n",
    "                     name=\"down_conv_1\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_1\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_2\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    ## Encoding (down-sampling) ### \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(2, 2), padding='same',\n",
    "                     name=\"down_conv_2\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_3\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_4\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_5\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_6\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_6a\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_6b\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_6c\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_7\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_8\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    ###############################################################################\n",
    "    model.add(UpSampling2D(size=(2, 2), name='up_samp_1'))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(4, 4),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"up_conv_1\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_9\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_10\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "    ###############################################################################\n",
    "    model.add(UpSampling2D(size=(2, 2), name='up_samp_2'))\n",
    "\n",
    "    model.add(Conv2D(filters=24, kernel_size=(4, 4),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"up_conv_2\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=12, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     name=\"flat_conv_11\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=1, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='sigmoid', name=\"flat_conv_12\"))\n",
    "    # model.add(Activation(our_activation))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    # Compile model with Adam optimizer and binary cross entropy loss function\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=IOULoss, #'binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Building the CNN archÄ±tecture with \"Sequential Model\" \n",
    "##### (model looks like autoencoder)\n",
    "def create_model(optimizer, input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    droprate = 0.1\n",
    "\n",
    "    model.add(Conv2D(filters=24, kernel_size=(3, 3),\n",
    "              strides=(1, 1), padding='same',\n",
    "              activation='relu', input_shape=input_shape, kernel_initializer='random_uniform',\n",
    "              name=\"flat_conv_a\"))\n",
    "    #model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Conv2D(filters=24, kernel_size=(3, 3),\n",
    "              strides=(1, 1), padding='same',\n",
    "              activation='relu',name=\"flat_conv_b\"))\n",
    "    #model.add(Dropout(droprate))\n",
    "    \n",
    "#    model.add(Conv2D(filters=24, kernel_size=(3, 3),\n",
    "#              strides=(1, 1), padding='same',\n",
    "#              activation='relu',name=\"flat_conv_c\"))\n",
    "#    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "#    model.add(Dropout(droprate))\n",
    "    \n",
    "    ## Encoding (down-sampling) ###   \n",
    "    model.add(Conv2D(filters=24, kernel_size=(3, 3),\n",
    "                     strides=(2, 2), padding='same',\n",
    "                     activation='relu', #input_shape=input_shape, kernel_initializer='random_uniform',\n",
    "                     name=\"down_conv_1\"))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_1\"))\n",
    "    #model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_2\"))\n",
    "    #model.add(Dropout(droprate))\n",
    "    ##############################################################################\n",
    "    \n",
    "#    model.add(Conv2D(filters=24, kernel_size=(3, 3),\n",
    "#              strides=(1, 1), padding='same',\n",
    "#              activation='relu',name=\"down_conv_2\"))\n",
    "#    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "#    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(2, 2), padding='same',\n",
    "                     activation='relu', name=\"down_conv_2\"))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_3\"))\n",
    "    #model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_4\"))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_5\"))\n",
    "    #model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_6\"))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_7\"))\n",
    "    #model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_8\"))\n",
    "    model.add(Dropout(droprate))\n",
    "    ###############################################################################\n",
    "    model.add(UpSampling2D(size=(2, 2), name='up_samp_1'))\n",
    "    \n",
    "#    model.add(Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), \n",
    "#                              padding='same', activation='softmax'))\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(4, 4),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"up_conv_1\"))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_9\"))\n",
    "    #model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_10\"))\n",
    "    #model.add(Dropout(droprate))\n",
    "    ###############################################################################\n",
    "    model.add(UpSampling2D(size=(2, 2), name='up_samp_2'))\n",
    "    \n",
    "#    model.add(Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), # Lead the accuracy to 0.78\n",
    "#                              padding='same', activation='softmax'))\n",
    "\n",
    "    model.add(Conv2D(filters=24, kernel_size=(4, 4),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"up_conv_2\"))\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=12, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_11\"))\n",
    "    #model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Conv2D(filters=1, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='sigmoid', name=\"flat_conv_12\"))\n",
    "    # model.add(Activation(our_activation))\n",
    "    #model.add(Dropout(droprate))\n",
    "\n",
    "    # Compile model with Adam optimizer and binary cross entropy loss function\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss = 'binary_crossentropy', #'mean_squared_error', #'binary_crossentropy', #loss=IoU, #'binary_crossentropy'\n",
    "                  metrics=['acc']) #metrics=['acc', IoU])\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "##################################################################################################################################\n",
    "class LearningRateTracker(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.lr_list = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        # lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        lr = K.eval(\n",
    "            optimizer.lr * (1. / (1. + optimizer.decay * K.cast(optimizer.iterations, K.dtype(optimizer.decay)))))\n",
    "        print('\\n LR: {}\\n'.format(lr))\n",
    "        self.lr_list.append(lr)\n",
    "\n",
    "##################################################################################################################################\n",
    "class SaveWeights(keras.callbacks.Callback):  # Saves weights after each 25 epochs\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 49 == 0:\n",
    "            model_json = self.model.to_json()\n",
    "            with open(\"model_\" + str(epoch) + \".json\", \"w\") as json_file:\n",
    "                json_file.write(model_json)\n",
    "            self.model.save_weights(\"weights_model_\" + str(epoch) + \".h5\")\n",
    "            print(\"Saved model-weights to disk\")\n",
    "\n",
    "##################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Building the CNN archÄ±tecture with \"Model\" - skip connections were added\n",
    "def create_model_add_skips(optimizer, input_shape, drop_rate = 0.3):\n",
    "\n",
    "    \n",
    "    i = Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters=24, kernel_size=(3, 3),\n",
    "              strides=(1, 1), padding='same',\n",
    "              activation='relu', input_shape=input_shape, kernel_initializer='random_uniform',\n",
    "              name=\"flat_conv_a\")(i)\n",
    "    first_skip = Conv2D(filters=24, kernel_size=(3, 3),\n",
    "              strides=(1, 1), padding='same',\n",
    "              activation='relu',name=\"flat_conv_b\")(x)\n",
    "    x = Conv2D(filters=24, kernel_size=(3, 3),\n",
    "                     strides=(2, 2), padding='same',\n",
    "                     activation='relu',\n",
    "                     name=\"down_conv_1\")(first_skip)\n",
    "    x = Dropout(drop_rate)(x) ################################################# First Drop\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_1\")(x)\n",
    "    second_skip = Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_2\")(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(2, 2), padding='same',\n",
    "                     activation='relu', name=\"down_conv_2\")(second_skip)\n",
    "    x = Dropout(drop_rate)(x) ################################################# Second Drop\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_3\")(x)\n",
    "    third_skip = Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_4\")(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(2, 2), padding='same',\n",
    "                     activation='relu', name=\"down_conv_3\")(third_skip)\n",
    "    x = Dropout(drop_rate)(x) ################################################# Third Drop\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_5\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_6\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_7\")(x)\n",
    "    x = Dropout(drop_rate)(x) ################################################# 4th Drop\n",
    "    \n",
    "    \n",
    "    x = UpSampling2D(size=(2, 2), name='up_samp_0')(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(4, 4),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"up_conv_0\")(x)\n",
    "    concat0 = Concatenate()([third_skip, x])\n",
    "    x = Conv2D(filters=128, kernel_size=(1, 1),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_8\")(concat0)\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_8b\")(x)\n",
    "    x = Dropout(drop_rate)(x) ################################################# 5th Drop\n",
    "    \n",
    "    \n",
    "    x = UpSampling2D(size=(2, 2), name='up_samp_1')(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(4, 4),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"up_conv_1\")(x)\n",
    "    concat = Concatenate()([second_skip, x])\n",
    "    x = Conv2D(filters=64, kernel_size=(1, 1),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_9\")(concat)\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_10\")(x)\n",
    "    x = Dropout(drop_rate)(x) ################################################# 6th Drop\n",
    "    \n",
    "    \n",
    "    x = UpSampling2D(size=(2, 2), name='up_samp_2')(x)\n",
    "    x = Conv2D(filters=24, kernel_size=(4, 4),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"up_conv_2\")(x)\n",
    "    concat2 = Concatenate()([first_skip, x])\n",
    "    x = Conv2D(filters=12, kernel_size=(1, 1),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_11\")(concat2)\n",
    "    x = Conv2D(filters=12, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_11b\")(x)\n",
    "    x = Dropout(drop_rate)(x) ################################################# 7th Drop\n",
    "    \n",
    "    \n",
    "    o = Conv2D(filters=1, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='sigmoid', name=\"flat_conv_12\")(x)\n",
    "    model = Model(inputs=i, outputs=o)\n",
    "\n",
    "    # Compile model with Adam optimizer and binary cross entropy loss function\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Building the CNN archÄ±tecture with \"Model\" - skip connections were added\n",
    "def create_model_add_skips_2(optimizer, input_shape, drop_rate = 0.1):\n",
    "\n",
    "    \n",
    "    i = Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters=24, kernel_size=(3, 3),\n",
    "              strides=(1, 1), padding='same',\n",
    "              activation='relu', input_shape=input_shape, kernel_initializer='random_uniform',\n",
    "              name=\"flat_conv_a\")(i)\n",
    "    first_skip = Conv2D(filters=24, kernel_size=(3, 3),\n",
    "              strides=(1, 1), padding='same',\n",
    "              activation='relu',name=\"flat_conv_b\")(x)\n",
    "    x = Conv2D(filters=24, kernel_size=(3, 3),\n",
    "                     strides=(2, 2), padding='same',\n",
    "                     activation='relu',\n",
    "                     name=\"down_conv_1\")(first_skip)\n",
    "    #x = Dropout(drop_rate)(x) ################################################# First Drop\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_1\")(x)\n",
    "    second_skip = Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_2\")(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(2, 2), padding='same',\n",
    "                     activation='relu', name=\"down_conv_2\")(second_skip)\n",
    "    #x = Dropout(drop_rate)(x) ################################################# Second Drop\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_3\")(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_4\")(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"xx_conv_3\")(x)\n",
    "    #x = Dropout(drop_rate)(x) ################################################# Third Drop\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_5\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_6\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_7\")(x)\n",
    "    x = Dropout(drop_rate)(x) ################################################# 4th Drop\n",
    "    \n",
    "    \n",
    "\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"xx_conv_0\")(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_8\")(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_8b\")(x)\n",
    "    #x = Dropout(drop_rate)(x) ################################################# 5th Drop\n",
    "    \n",
    "    \n",
    "    x = UpSampling2D(size=(2, 2), name='up_samp_1')(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(4, 4),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"up_conv_1\")(x)\n",
    "    concat = Concatenate()([second_skip, x])\n",
    "    x = Conv2D(filters=64, kernel_size=(1, 1),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_9\")(concat)\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_10\")(x)\n",
    "    #x = Dropout(drop_rate)(x) ################################################# 6th Drop\n",
    "    \n",
    "    \n",
    "    x = UpSampling2D(size=(2, 2), name='up_samp_2')(x)\n",
    "    x = Conv2D(filters=24, kernel_size=(4, 4),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"up_conv_2\")(x)\n",
    "    concat2 = Concatenate()([first_skip, x])\n",
    "    x = Conv2D(filters=12, kernel_size=(1, 1),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_11\")(concat2)\n",
    "    x = Conv2D(filters=12, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='relu', name=\"flat_conv_11b\")(x)\n",
    "    #x = Dropout(drop_rate)(x) ################################################# 7th Drop\n",
    "    \n",
    "    \n",
    "    o = Conv2D(filters=1, kernel_size=(3, 3),\n",
    "                     strides=(1, 1), padding='same',\n",
    "                     activation='sigmoid', name=\"flat_conv_12\")(x)\n",
    "    model = Model(inputs=i, outputs=o)\n",
    "\n",
    "    # Compile model with Adam optimizer and binary cross entropy loss function\n",
    "    #model.compile(optimizer=optimizer,\n",
    "    #              loss = 'binary_crossentropy', #loss=IoU, #'binary_crossentropy'\n",
    "    #              metrics=['acc', IoU])\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles:  16828\n",
      "15828 1000 15828 1000\n",
      "Input Shape of the models (15828, 128, 128, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa07984be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1maqbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa0798dba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Order the image dimension acc. to TensorFlow (batc_hsize, rows, cols, channels)\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "# set the working directory\n",
    "#os.chdir(r'F:\\sercan\\input_images')\n",
    "PATH = os.getcwd()\n",
    "#plt.gray()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "p_size_1 = 128 # Compared with 256, which larger may generate round corners\n",
    "\n",
    "def data_collector(fns_input, fns_output):\n",
    "    \n",
    "    sim_input = []\n",
    "    sim_output = []\n",
    "    \n",
    "    for fn_input, fn_output in zip(fns_input, fns_output):\n",
    "        \n",
    "        # load simulated heat map (TRAJECTORY SIMULATION) and target road for Hannover ####\n",
    "        sim_heatmap_hannover = readImg(fn_input)\n",
    "        sim_road_hannover = readImg(fn_output)\n",
    "        \n",
    "        sim_hm_patches_overlap = imagePatches(sim_heatmap_hannover, p_size_1, p_size_1, int(p_size_1))\n",
    "        sim_road_patches_overlap = imagePatches(sim_road_hannover, p_size_1, p_size_1, int(p_size_1))\n",
    "        sim_road_patches_overlap_new = removeCorrespondence(sim_road_patches_overlap, sim_hm_patches_overlap)\n",
    "        sim_hm_patches_overlap_new = removeCorrespondence(sim_hm_patches_overlap, sim_road_patches_overlap)\n",
    "        sim_road_patches_overlap_new_new = removeBlackImg(sim_road_patches_overlap)\n",
    "        \n",
    "        sim_input += sim_hm_patches_overlap_new\n",
    "        sim_output += sim_road_patches_overlap_new_new\n",
    "    \n",
    "    return sim_input, sim_output\n",
    "\n",
    "fns_input = [trainPath + r\"traininput_inv.png\"]\n",
    "fns_output = [trainPath + r\"trainoutput_inv.png\"]\n",
    "\n",
    "#fns_input = [r\"data/input2.tif\"]#, r\"data/geb1_inp_inv_cut.tif\"]\n",
    "#fns_output = [r\"data/output2.tif\"]#, r\"data/geb1_out_inv_cut.tif\"]\n",
    "\n",
    "sim_hm_patches_32_new, sim_road_patches_32_new_new = data_collector(fns_input, fns_output)\n",
    "print('Number of tiles: ', len(sim_hm_patches_32_new))\n",
    "\n",
    "#### experience 1 - simulated hm\n",
    "index_list_sim = list(range(len(sim_hm_patches_32_new)))\n",
    "random.shuffle(index_list_sim)\n",
    "\n",
    "idx_sim = 1000\n",
    "index_list_test_sim = index_list_sim[-idx_sim:]\n",
    "index_list_test_sim.sort()\n",
    "sim_hm_test = [sim_hm_patches_32_new[i] for i in index_list_test_sim]\n",
    "sim_road_test = [sim_road_patches_32_new_new[i] for i in index_list_test_sim]\n",
    "\n",
    "index_list_train_sim = index_list_sim[:-idx_sim]\n",
    "index_list_train_sim.sort()\n",
    "sim_hm_train = [sim_hm_patches_32_new[i] for i in index_list_train_sim]\n",
    "sim_road_train = [sim_road_patches_32_new_new[i] for i in index_list_train_sim]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#sim_hm_train, sim_hm_test, sim_road_train, sim_road_test = train_test_split(sim_hm_patches_32_new, \n",
    "#                                                                            sim_road_patches_32_new_new,\n",
    "#                                                                            test_size=0.33, random_state=42)\n",
    "\n",
    "print(len(sim_hm_train), len(sim_hm_test), len(sim_road_train), len(sim_road_test))\n",
    "\n",
    "x_train_sim = np.reshape(sim_hm_train, (len(sim_hm_train), p_size_1, p_size_1, 1))\n",
    "y_train_sim = np.reshape(sim_road_train, (len(sim_road_train), p_size_1, p_size_1, 1))\n",
    "x_test_sim = np.reshape(sim_hm_test, (len(sim_hm_test), p_size_1, p_size_1, 1))\n",
    "y_test_sim = np.reshape(sim_road_test, (len(sim_road_test), p_size_1, p_size_1, 1))\n",
    "\n",
    "# save image patch arrays\n",
    "np.save(tmpPath + \"x_train_sim.npy\", x_train_sim)\n",
    "np.save(tmpPath + \"y_train_sim.npy\", y_train_sim)\n",
    "np.save(tmpPath + \"x_test_sim.npy\", x_test_sim)\n",
    "np.save(tmpPath + \"y_test_sim.npy\", y_test_sim)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.reshape(x_test_sim[2], (p_size_1,p_size_1)))\n",
    "plt.figure()\n",
    "plt.imshow(np.reshape(y_test_sim[2], (p_size_1,p_size_1)))\n",
    "\n",
    "input_shape1 = (None, None, 1) #x_train_sim[0].shape\n",
    "print('Input Shape of the models', x_train_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902085747393\n"
     ]
    }
   ],
   "source": [
    "img_input = np.reshape(x_test_sim[2], (p_size_1,p_size_1))\n",
    "img_output = np.reshape(y_test_sim[2], (p_size_1,p_size_1))\n",
    "\n",
    "logic_and = np.sum(np.logical_and(img_output, img_input))\n",
    "logic_or = np.sum(np.logical_or(img_output, img_input))\n",
    "\n",
    "print(logic_and/logic_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flat_conv_a (Conv2D)         (None, None, None, 24)    240       \n",
      "_________________________________________________________________\n",
      "flat_conv_b (Conv2D)         (None, None, None, 24)    5208      \n",
      "_________________________________________________________________\n",
      "down_conv_1 (Conv2D)         (None, None, None, 24)    5208      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, None, 24)    0         \n",
      "_________________________________________________________________\n",
      "flat_conv_1 (Conv2D)         (None, None, None, 64)    13888     \n",
      "_________________________________________________________________\n",
      "flat_conv_2 (Conv2D)         (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "down_conv_2 (Conv2D)         (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "flat_conv_3 (Conv2D)         (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "flat_conv_4 (Conv2D)         (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "flat_conv_5 (Conv2D)         (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "flat_conv_6 (Conv2D)         (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "flat_conv_7 (Conv2D)         (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "flat_conv_8 (Conv2D)         (None, None, None, 128)   295040    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "up_samp_1 (UpSampling2D)     (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "up_conv_1 (Conv2D)           (None, None, None, 64)    131136    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "flat_conv_9 (Conv2D)         (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "flat_conv_10 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_samp_2 (UpSampling2D)     (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "up_conv_2 (Conv2D)           (None, None, None, 24)    24600     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, None, None, 24)    0         \n",
      "_________________________________________________________________\n",
      "flat_conv_11 (Conv2D)        (None, None, None, 12)    2604      \n",
      "_________________________________________________________________\n",
      "flat_conv_12 (Conv2D)        (None, None, None, 1)     109       \n",
      "=================================================================\n",
      "Total params: 2,765,009\n",
      "Trainable params: 2,765,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt1 = keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "#opt1 = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model_ex1 = create_model(opt1, input_shape1)\n",
    "\n",
    "#model_ex1 = create_model_batch(opt1, input_shape1)\n",
    "\n",
    "#model_ex1 = create_model_add_skips(opt1, input_shape1)\n",
    "\n",
    "#model_ex1 = create_model_add_skips_2(opt1, input_shape1)\n",
    "\n",
    "model_ex1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_gen_args = dict(rotation_range=90.)\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "seed = 1\n",
    "BATCH_SIZE = 16\n",
    "result_generator = zip(image_datagen.flow(x_train_sim, batch_size=BATCH_SIZE,seed=seed), \n",
    "                       mask_datagen.flow(y_train_sim, batch_size=BATCH_SIZE,seed=seed))\n",
    "\n",
    "History1 = History()\n",
    "hist1 = model_ex1.fit_generator(result_generator,\n",
    "                      epochs = 50,\n",
    "                      steps_per_epoch=1000,\n",
    "                      verbose=1,\n",
    "                      shuffle=True,\n",
    "                      callbacks=[History1, \n",
    "                                 EarlyStopping(patience=15), \n",
    "                                 ReduceLROnPlateau(patience = 5, verbose = 0),\n",
    "                                 ModelCheckpoint(\"weights.hdf5\", save_best_only = True, save_weights_only = False)],\n",
    "                      validation_data=(x_test_sim, y_test_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15828 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "15828/15828 [==============================] - 83s 5ms/step - loss: 0.0844 - acc: 0.9692 - val_loss: 0.0513 - val_acc: 0.9822\n",
      "Epoch 2/50\n",
      "15828/15828 [==============================] - 83s 5ms/step - loss: 0.0509 - acc: 0.9838 - val_loss: 0.0437 - val_acc: 0.9857\n",
      "Epoch 3/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0463 - acc: 0.9856 - val_loss: 0.0416 - val_acc: 0.9865\n",
      "Epoch 4/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0443 - acc: 0.9861 - val_loss: 0.0559 - val_acc: 0.9846\n",
      "Epoch 5/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0424 - acc: 0.9867 - val_loss: 0.0372 - val_acc: 0.9882\n",
      "Epoch 6/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0408 - acc: 0.9872 - val_loss: 0.0374 - val_acc: 0.9875\n",
      "Epoch 7/50\n",
      "15828/15828 [==============================] - 86s 5ms/step - loss: 0.0392 - acc: 0.9876 - val_loss: 0.0342 - val_acc: 0.9893\n",
      "Epoch 8/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0379 - acc: 0.9880 - val_loss: 0.0326 - val_acc: 0.9898\n",
      "Epoch 9/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0368 - acc: 0.9884 - val_loss: 0.0337 - val_acc: 0.9886\n",
      "Epoch 10/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0358 - acc: 0.9887 - val_loss: 0.0328 - val_acc: 0.9891\n",
      "Epoch 11/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0350 - acc: 0.9890 - val_loss: 0.0302 - val_acc: 0.9905\n",
      "Epoch 12/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0342 - acc: 0.9893 - val_loss: 0.0319 - val_acc: 0.9894\n",
      "Epoch 13/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0334 - acc: 0.9894 - val_loss: 0.0418 - val_acc: 0.9846\n",
      "Epoch 14/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0330 - acc: 0.9897 - val_loss: 0.0287 - val_acc: 0.9908\n",
      "Epoch 15/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0326 - acc: 0.9898 - val_loss: 0.0288 - val_acc: 0.9905\n",
      "Epoch 16/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0320 - acc: 0.9900 - val_loss: 0.0297 - val_acc: 0.9899\n",
      "Epoch 17/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0313 - acc: 0.9901 - val_loss: 0.0277 - val_acc: 0.9912\n",
      "Epoch 18/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0310 - acc: 0.9902 - val_loss: 0.0295 - val_acc: 0.9902\n",
      "Epoch 19/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0305 - acc: 0.9904 - val_loss: 0.0276 - val_acc: 0.9910\n",
      "Epoch 20/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0302 - acc: 0.9905 - val_loss: 0.0275 - val_acc: 0.9911\n",
      "Epoch 21/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0300 - acc: 0.9906 - val_loss: 0.0270 - val_acc: 0.9914\n",
      "Epoch 22/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0295 - acc: 0.9907 - val_loss: 0.0276 - val_acc: 0.9913\n",
      "Epoch 23/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0291 - acc: 0.9908 - val_loss: 0.0280 - val_acc: 0.9910\n",
      "Epoch 24/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0291 - acc: 0.9909 - val_loss: 0.0269 - val_acc: 0.9914\n",
      "Epoch 25/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0287 - acc: 0.9910 - val_loss: 0.0271 - val_acc: 0.9912\n",
      "Epoch 26/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0285 - acc: 0.9911 - val_loss: 0.0292 - val_acc: 0.9905\n",
      "Epoch 27/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.0273 - val_acc: 0.9915\n",
      "Epoch 28/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0280 - acc: 0.9912 - val_loss: 0.0265 - val_acc: 0.9915\n",
      "Epoch 29/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0277 - acc: 0.9913 - val_loss: 0.0273 - val_acc: 0.9916\n",
      "Epoch 30/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0273 - acc: 0.9914 - val_loss: 0.0287 - val_acc: 0.9912\n",
      "Epoch 31/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0271 - acc: 0.9915 - val_loss: 0.0266 - val_acc: 0.9914\n",
      "Epoch 32/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0270 - acc: 0.9916 - val_loss: 0.0276 - val_acc: 0.9914\n",
      "Epoch 33/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0269 - acc: 0.9916 - val_loss: 0.0264 - val_acc: 0.9918\n",
      "Epoch 34/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0249 - acc: 0.9921 - val_loss: 0.0258 - val_acc: 0.9921\n",
      "Epoch 35/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0243 - acc: 0.9922 - val_loss: 0.0259 - val_acc: 0.9921\n",
      "Epoch 36/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0244 - acc: 0.9923 - val_loss: 0.0259 - val_acc: 0.9921\n",
      "Epoch 37/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0242 - acc: 0.9923 - val_loss: 0.0260 - val_acc: 0.9921\n",
      "Epoch 38/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0242 - acc: 0.9923 - val_loss: 0.0260 - val_acc: 0.9921\n",
      "Epoch 39/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0241 - acc: 0.9923 - val_loss: 0.0262 - val_acc: 0.9921\n",
      "Epoch 40/50\n",
      "15828/15828 [==============================] - 85s 5ms/step - loss: 0.0239 - acc: 0.9924 - val_loss: 0.0261 - val_acc: 0.9921\n",
      "Epoch 41/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0239 - acc: 0.9924 - val_loss: 0.0261 - val_acc: 0.9921\n",
      "Epoch 42/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0239 - acc: 0.9924 - val_loss: 0.0261 - val_acc: 0.9921\n",
      "Epoch 43/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0239 - acc: 0.9924 - val_loss: 0.0261 - val_acc: 0.9921\n",
      "Epoch 44/50\n",
      "15828/15828 [==============================] - 84s 5ms/step - loss: 0.0239 - acc: 0.9924 - val_loss: 0.0261 - val_acc: 0.9921\n"
     ]
    }
   ],
   "source": [
    "##### Train the model\n",
    "#covariance1 = Covariance()\n",
    "History1 = History()\n",
    "hist1 = model_ex1.fit(x_train_sim, y_train_sim,\n",
    "                      batch_size=16,\n",
    "                      epochs = 50,\n",
    "                      verbose=1,\n",
    "                      shuffle=True,\n",
    "                      callbacks=[History1, \n",
    "                                 EarlyStopping(patience = 10), \n",
    "                                 ReduceLROnPlateau(patience = 5, verbose = 0),\n",
    "                                 ModelCheckpoint(outPath + \"weights.hdf5\", \n",
    "                                                 save_best_only = True, \n",
    "                                                 save_weights_only = False)],\n",
    "                      validation_data=(x_test_sim, y_test_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "### Save history\n",
    "History1_loss = History1.history['loss']\n",
    "History1_acc = History1.history['acc']\n",
    "History1_val_loss = History1.history['val_loss']\n",
    "History1_val_acc = History1.history['val_acc']\n",
    "\n",
    "\n",
    "thefile1 = open(outPath + 'History1_loss.txt', 'w')\n",
    "for item in History1_loss:\n",
    "    thefile1.write(\"%s\\n\" % item)\n",
    "thefile1.close()\n",
    "\n",
    "thefile2 = open(outPath + 'History1_acc.txt', 'w')\n",
    "for item in History1_acc:\n",
    "    thefile2.write(\"%s\\n\" % item)\n",
    "thefile2.close()\n",
    "\n",
    "thefile3 = open(outPath + 'History1_val_loss.txt', 'w')\n",
    "for item in History1_val_loss:\n",
    "    thefile3.write(\"%s\\n\" % item)\n",
    "thefile3.close()\n",
    "\n",
    "thefile4 = open(outPath + 'History1_val_acc.txt', 'w')\n",
    "for item in History1_val_acc:\n",
    "    thefile4.write(\"%s\\n\" % item)\n",
    "thefile4.close()\n",
    "\n",
    "### Save model\n",
    "model_json1 = model_ex1.to_json()\n",
    "with open(outPath + \"model_ex1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json1)\n",
    "model_ex1.save_weights(outPath + \"weights_model_ex1.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain best model\n",
    "from keras import models\n",
    "\n",
    "_EPSILON = 10e-8\n",
    "\n",
    "def IoU(yTrue,yPred):  \n",
    "    \n",
    "    I = tf.multiply(yTrue, yPred, name=\"intersection\")\n",
    "    U = yTrue + yPred - I + _EPSILON\n",
    "    \n",
    "    IoU = tf.reduce_sum(I) / tf.reduce_sum(U)\n",
    "    return -tf.log(IoU + _EPSILON) + binary_crossentropy(yTrue,yPred)\n",
    "\n",
    "model_ex1 = models.load_model(tmpPath + \"weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff85464e6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff854407e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot history of average covariance - accuracy and loss of the models\n",
    "plt.figure()\n",
    "plt.plot(History1.history['loss'])\n",
    "plt.plot(History1.history['val_loss'])\n",
    "plt.title('loss & val_loss')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.savefig(outPath + \"loss\", dpi=1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(History1.history['acc'])\n",
    "plt.plot(History1.history['val_acc'])\n",
    "plt.title('acc & val_acc')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.savefig(outPath + \"acc\", dpi=1000)\n",
    "\n",
    "#plt.figure()\n",
    "#plt.plot(History1.history['IoU'])\n",
    "#plt.plot(History1.history['val_IoU'])\n",
    "#plt.title('IoU & val_IoU')\n",
    "#plt.legend(['train', 'test'], loc='lower right')\n",
    "#plt.savefig(outPath + \"IoU\", dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-195769e2609b>, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-195769e2609b>\"\u001b[0;36m, line \u001b[0;32m58\u001b[0m\n\u001b[0;31m    testIndependet(r\"FTest1_input_inv.png\", r\"FTest1_output_inv.png\"testPath, outPath)\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#def IoUcheck(yTrue, yPred):\n",
    "#    \n",
    "#    I = np.multiply(yTrue, yPred)\n",
    "#    U = np.subtract(np.add(yTrue, yPred), I)\n",
    "#    return np.sum(I)/np.sum(U)\n",
    "\n",
    "def IoUcheck(img_input, img_output):\n",
    "\n",
    "    logic_and = np.sum(np.logical_and(img_output, img_input))\n",
    "    logic_or = np.sum(np.logical_or(img_output, img_input))\n",
    "\n",
    "    return logic_and/logic_or\n",
    "\n",
    "def testIndependet(fn, target, inpath, outpath, model_ex1):\n",
    "    \n",
    "    image_arr = readImg(inpath + fn)\n",
    "    #print(image_arr.shape)\n",
    "    image_arr = rescaleImg(image_arr)\n",
    "    #print(image_arr.shape)\n",
    "    \n",
    "    image_tar = readImg(inpath + target)\n",
    "    #print(image_tar.shape)\n",
    "    image_tar = rescaleImg(image_tar)\n",
    "    #print(image_tar.shape)\n",
    "    \n",
    "    conc2 = np.reshape(model_ex1.predict(np.reshape(image_arr, (1, image_arr.shape[0], image_arr.shape[1], 1))), \n",
    "                       (image_arr.shape[0], image_arr.shape[1]))\n",
    "    \n",
    "    acc = accuracy_score(image_tar.flatten().astype(bool), (conc2 > 0.5).flatten())\n",
    "    iou = IoUcheck(image_tar.flatten().astype(bool), (conc2 > 0.5).flatten())\n",
    "    print('accuracy:', acc)\n",
    "    print('IoU:', iou)\n",
    "    \n",
    "    fig = plt.figure(figsize=(image_arr.shape[1] / 1000, image_arr.shape[0] / 1000), dpi=100, frameon=False)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    plt.imshow(conc2)\n",
    "    fig.savefig(outpath + fn[:-4] + '_out.png', dpi=1000)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(image_arr.shape[1] / 1000, image_arr.shape[0] / 1000), dpi=100, frameon=False)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    conc2 = conc2 > 0.5\n",
    "    plt.imshow(conc2, cmap='gray')\n",
    "    fig.savefig(outpath + fn[:-4] + '_out_bw.png', dpi=1000)\n",
    "    \n",
    "    return acc, iou\n",
    "    \n",
    "\n",
    "#testIndependet(r\"testexampleinput2.tif\", testPath, outPath)\n",
    "testIndependet(r\"FTest1_input_inv.png\", r\"FTest1_output_inv.png\"testPath, outPath)\n",
    "testIndependet(r\"FTest2_input_inv.png\", r\"FTest2_output_inv.png\"testPath, outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arrA = readImg(testPath + r\"FTest1_input_inv.png\")\n",
    "image_arrB = readImg(testPath + r\"FTest1_output_inv.png\")\n",
    "\n",
    "print('Example A: ')\n",
    "\n",
    "print('accuracy:', accuracy_score(image_arrB.flatten().astype(bool), \n",
    "                     image_arrA.flatten().astype(bool)))\n",
    "\n",
    "print('IoU:',IoUcheck(image_arrB.flatten().astype(bool), \n",
    "                     image_arrA.flatten().astype(bool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arrA = readImg(testPath + r\"FTest2_input_inv.png\")\n",
    "image_arrB = readImg(testPath + r\"FTest2_output_inv.png\")\n",
    "\n",
    "print('Example B: ')\n",
    "\n",
    "print('accuracy:', accuracy_score(image_arrB.flatten().astype(bool), \n",
    "                     image_arrA.flatten().astype(bool)))\n",
    "\n",
    "print('IoU:', IoUcheck(image_arrB.flatten().astype(bool), \n",
    "                     image_arrA.flatten().astype(bool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
